{
  "hash": "485d3211fb812e80edff5bbcd4baf813",
  "result": {
    "markdown": "---\ntitle: 6. Sampling, probability and binomial tests\nsubtitle: Written by Tom Beesley & John Towse\norder: 7\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Week 6 Lecture\n\nWatch Part 1\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=5676177e-7dcc-4c30-9e72-b0b500aa82d6&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\nWatch Part 2\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=a6c7e439-077a-464d-ac43-b0b500aa8285&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\nWatch Part 3\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=c62c74c2-4bb0-4c28-91b0-b0b500aa825d&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\nWatch Part 4\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=350fbb75-e55d-47bf-8c41-b0b500aa8218&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\n\nDownload the lecture slides [here](data/Week_6/PSYC121 wk6_slides_2023.pptx)\n\n## Reading \n\n[Chapter 8](https://modules.lancaster.ac.uk/mod/url/view.php?id=2017199) of Howell\n\n## Pre-lab work\n\n-   Ensure you have watched the above lecture content for Week 6.\n\n-   Complete the short learnr tutorial which will introduce you to running the **binomial tests** in R. [You can find it here](https://ma-rconnect.lancs.ac.uk/PSYC121_2022_W6_prep/){target=\"_blank\"}.\n\n\n## Some basic RMarkdown\n\nWe introduced you to RMarkdown in Week 4. It's like a .R script, only a bit more fancy! Today we'll introduce a couple more features and use this in our tasks below. \n\n1. Make sure you have a Week 6 folder\n\n2. Once in that folder in the files pane, click \"more\" and \"set as working directory\"\n\n3. Then click the new file button and select \"R Markdown\"\n\n![](images/wk6/new_rmd.png) \n\n4. You'll be asked to name this file. Leave the other options as they are and click OK.\n\n5. When the new R Markdown file appears, try \"knitting\" it (the icon at the top with the ball of wool). You should get a nice output of the default R Markdown document.\n\n6. Note that in R Markdown documents you can freely type in text in the main body of the file - you did this last week. But see how you can also create a *\"code chunk\"* within the document. These are places where you put your R code you want to run. \n\n::: {.callout-tip title=\".Rmd and .R differences\"}\nIn a way, R Markdown files function in the opposite way to .R files: \n\n- **.Rmd**: you write normal text in the main part (like you'd do in a word processor), but you create a special \"code chunk\" for your code.\n\n- **.R**: you write code in the main body, and use the \"#\" to write normal text as a comment\n:::\n\n7. Try running the first code chunk (click the green arrow on the right). This will run the code and display the output (in the document and in the console). \n\n\n## Creating an R Markdown for your lab work\n\n1. Delete all of the script except the first title (## R Markdown)\n\n2. Change this title to something more relevant: (e.g., ## Task 1 - Card Sampling task)\n\n3. Knit your document to check it is still working!\n\n## Card sampling task\n\n![](images/wk6/cards.jpg)\n\nIn the first task this week we will look at the sampling of events and we will apply the basic statistical test of the binomial test: `binom.test()`\n\nEach table has a set of cards. These will be 13 red cards and 13 black cards - please check your set to ensure you have the right number of each colour (it doesn't matter what suit the cards are).\n\nWe are going to play a game in which one person chooses a set of these cards and biases the deck towards either red or black. The other members of the table have to try and work out which way the set is biased. To do this, they will draw samples from the deck.\n\n::: {.callout-important icon=true title=\"The Experiment\"}\n\nThink of this as an experiment: there is something real out there in the world in our \"population\" (the cards). As an experimenter we are trying to estimate what is true about the world, and in order to do this we need to take samples. When you can only see the backs of the cards, that data is unobserved. But as we draw samples, we start to understand how the \"world\" is - whether it is biased towards red or black. \n\nSo each time you draw a card, you are observing one data point from the population, and based on the data you collect (your samples) you are going to draw an inference about what is true about the population.\n\n:::\n\n### Set up and instructions:\n\n1.  One person on each table should act as the \"world\" (the person who biases the cards). Congratulations, you are God! This person will determine what is true about the state of things in the world. This means they control what is contained in the deck of cards. \n\n2. For each experiment, this person secretly looks at the cards, and removes some cards to use in the experiment. For example, from the set of 26 cards, they might choose to remove 4 black cards. The deck is now biased towards red (13 red; 9 black).\n\n3. It's important that no one sees what the cards are (the ones you've kept, or the ones removed). Shuffle the cards so they are ready to be sampled. \n\n4.  The remaining people (1 or more) will act as the experimenters. Your job is to draw samples and work out whether you think the deck is biased or not towards either red or black. \n\n5. Now copy the following text and code to your R Markdown document to record your work:\n\n````\n### Experiment 1\n\nNumber of samples:\nTotal red cards found:\nTotal black cards found:\nConclusion: \nThe true bias was: \n\n\n```{{r}}\n\nbinom.test(x, n) # x is the number or red or black; n is the sample size\n\n```\n\n````\n### Running each experiment \n\nDo these steps for each experiment:\n\n1. The \"World\" removes some cards from the full deck (the number and colour of the cards removed is up to them). They shuffle the chosen cards ready to start the \"experiment\".\n\n2. The \"Experimenters\" **pre-register** their sample size. That is, they state how many cards they are going to draw.\n\n3. Draw samples one at a time (each experimenter can take one card, to speed things up). \n\n::: {.callout-important icon=true title=\"Important!\"}\n**Make sure you replace all the cards each time you draw samples.** The world/dealer should also give the pack a quick shuffle.\n:::\n\n4. Do step 3 until you have collect the sample size you chose\n\n5. Once you have all the samples, the experimenters should draw a conclusion based initially on their own \"gut feeling\" about the data. Do you think the deck was biased towards red, black, or was it unbiased?\n\n6. Change the `binom.test()` code to provide a statistical result. Note the \"p value\". Was this result unusual? How likely were the data given the null hypothesis? \n\n7. The \"world\" can then reveal the hidden cards. Was the deck actually biased or not? How does this sit with a) your initial conclusions, and b) the result of the binomial test? \n\n8. Complete your record log in the .Rmd file. Feel free to Write a short statement about what you found in this experiment. \n\nRepeat all of the above steps (1-8) for a new experiment, **making sure that you try different parameters for the experiment**. So vary a) how many cards are removed from the deck, b) the combination of cards removed from the deck, and c) the pre-registered sample size. Feel free to swap the roles around.\n\nOnce you've conducted a few experiments, discuss on your table the results you found. It might be useful to think about the following things:\n\n-   were there times when your intuitions were different to the statistical result? For example, you were sure there was a bias, but in fact the statistics told you this was not that unusual (p was \\> .05)?\n\n-   were there times when the deck was actually biased, but you failed to prove this with your experiment (you failed to see p \\< .05)? Do you remember what this type of error is called?\n\n-   were there times when the deck was *not* biased, but the test result suggested it was (p \\< .05)? Do you remember what type of error this is called?\n\n\n::: {.cell}\n\n:::\n\n\n## Risky and safe decisions\n\nFor the second exercise today we will look at data from the survey on \"risky and safe decisions\". You may remember that you were asked the following question:\n\n::: {.callout-tip icon=false title=\"Gain\"}\nImagine you are on a game-show and you win £300. The presenter gives you have a choice: receive an additional £100 for sure, or take a gamble offering a 50% chance to gain £200 and a 50% chance to gain nothing. Which would you choose?\n\n- receive £100 for sure\n\n- take the gamble of a 50% chance to gain £200 and a 50% chance to gain nothing\n:::\n\nWe then asked you a similar question:\n\n::: {.callout-important icon=false title=\"Loss\"}\nImagine you are on a different game-show and you win £500. Here you are given a choice between either losing £100 from your winnings for sure, or taking a gamble offering a 50% chance to lose nothing and a 50% chance to lose £200. Which would you choose?\n\n- lose £100 for sure\n\n- take the gamble of a 50% chance to lose nothing and a 50% chance to lose £200\n:::\n\nWe've called these \"gain\" and \"loss\", because in the first scenario you're being asked about a chance to gain money, while in the second, it's about a chance to lose money. Note that the **\"expected utility\"** of the choices is equivalent:\n\n::: {.callout-note icon=false appearance=\"simple\"}\n\n\"The expected utility of an act is a weighted average of the utilities of each of its possible outcomes, where the utility of an outcome measures the extent to which that outcome is preferred, or preferable, to the alternatives. The utility of each outcome is weighted according to the probability that the act will lead to that outcome.\" [see here](https://plato.stanford.edu/entries/rationality-normative-utility/)\n:::\n\nThat's to say, on average, you'll end up with +£100 for the two cases in the gain scenario, or -£100 for the two cases in the loss scenario.\n\nBut what do people actually pick? Well people tend to be risk-averse, choosing the safe option overall. But interestingly, the safe option is picked far less when the scenario is presented as a loss. People seem to want to take the risk of potentially not losing anything (but maybe losing more).\n\nLet's look to see if you showed the same pattern!\n\n1. Create a new section of your markdown, giving it a suitable header\n\n2. Create a new code chunk by clicking the \"Code\" menu, then \"Insert Chunk\"\n\n3. You can download the data from [this link](data/Week_6/risky_decisions.csv), then upload it into the server.\n\n4. Add a `read_csv()` command to read the data into the environment. \n\n::: {.callout-important title=\"Reading CSVs\"}\n\n- Remember to set the working directory so R knows where the file is\n- Remember to assign (<-) to a new data object and give this a sensible name\n:::\n\n5. View the data, and see that the columns represent the gain and loss scenarios. The values represent the choices people made. \n\n6. Use the `count()` function to count the number of \"safe\" and \"risky\" choices that were made for our sample\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount(my_data_object_name, gain)\n```\n:::\n\n\n7. We can now tell whether, in our sample, people tended to play it safe or take the risky choice. Did the sample have a meaningful bias towards one type of decision? If they didn't we'd expect it to be a 50/50 split between safe and risky (people might make their choice at random). Use the `binom.test()` to look at whether the result would be expected by chance, noting the p value that is found. \n\n8. Write a sentence or two after your code to explain what this result means.\n\n9. Repeat for the data from the loss column. Was the p value < .05 here? Again, write a sentence or two to explain what this means. \n\n\n\n",
    "supporting": [
      "Week6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}