{
  "hash": "d35c9109a1a62fcb873af28a6ae39497",
  "result": {
    "markdown": "---\ntitle: 7. Week 18 -- Developing the linear model\nsubtitle: Written by Rob Davies\norder: 7\n---\n\n\n::: callout-warning\nThis page is now live for you to use: **Welcome!**\n\n- Here is a link to the sign-in page for [R-Studio Server](https://psy-rstudio.lancaster.ac.uk/auth-sign-in?appUri=%2F)\n:::\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-1_9fa7ac78fca53cb6c7fbe27efde36f06'}\n\n:::\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-2_46a417e2d6facbf61eb452b338a3fba9'}\n\n:::\n\n\n## Week 18: Introduction {#sec-wk18-introduction}\n\nWelcome to your overview of our work together in **PSYC122 Week 18**.\n\n::: callout-tip\n*Putting it all together*\n\n- We will complete four classes in **weeks 16-19**.\n- These classes are designed to help you to revise and to put into practice some of the key ideas and skills you have been developing in the first year research methods modules *PSYC121, PSYC123 and PSYC124*.\n- We will do this in the context of a live research project with potential real world impacts: the **Clearly Understood** project.\n:::\n\n### Our learning goals\n\nIn Week 18, we aim to further develop skills in *analyzing* and in *visualizing* psychological data.\n\nWe will do this in the context of the **Clearly Understood** project: our focus will be on what makes it easy or difficult for people to understand written health information.\n\nIn the Week 18 class, we will aim to answer two research questions:\n\n1. What person attributes predict success in understanding?\n2. Can people accurately evaluate whether they correctly understand written health information?\n\nWe will use linear models to estimate the association between predictors and outcomes.\nWhat is **new**, here, is that we will explore the power and flexibility of the linear model analysis method in two important aspects.\n\n::: callout-tip\n1. We will fit linear models including *multiple* predictors, this is why this form of analysis is also often called *multiple regression*.\n2. We will use linear models to estimate the effects of numeric and categorical or nominal predictor variables.\n:::\n\nWhen we do these analyses, we will need to adapt how we report the results:  \n\n- we need to report information about **the model we specify**, identifying *all* predictors;\n- we will need to decide **if the effects** of one or more predictors **are significant**;\n- we will report the model **fit statistics** (`F, R-squared`) as well as coefficient estimates;\n- and we need to learn to write texts **describing the impact** of predictors.\n\nUsually, in describing the impacts of predictors, we are required to communicate:\n\n- the **direction** of the effect -- do values of the outcome variable *increase* or *decrease* given increasing values of the predictor?\n- the **size** of the effect -- *how much* do values of the outcome variable *increase* or *decrease* given increasing values of the predictor?\n\nThis task of description is enabled by producing plots of the predictions we can make:\n\n- plots to show we expect the outcome to change, given different values of a predictor.\n\n::: callout-tip\nWe will aim to build skills in producing professional-looking plots for our audiences.\n\n- We can produce plots showing the effects of predictors\n- As predictions of change in outcome, given different values of the predictor variables.\n:::\n\n## Lectures {#sec-wk18-lectures}\n\n::: callout-tip\nBefore you go on to the activities in @sec-wk18-lab-activities, **watch** the lectures:\n:::\n\nThe lecture for this week is presented in four short parts.\nYou can view video recordings of the lectures using Panopto, by clicking on the video images shown following.\n\n- Anybody who has the link should be able to view the video.\n\n1. **Overview** (19 minutes): What we are doing in Week 18 -- Exploring the power of linear models, extending their application to use multiple variables to predict people.\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=7ae0e020-8dcc-436e-9d69-afb700ca1a52&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\n2. **Using linear models to predict people** (13 minutes): Coding, thinking about, and reporting linear models with multiple predictors.\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=d2638334-4683-4543-8183-afb700cfbff0&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\n3. **Critical evaluation** (15 minutes): Critically evaluating the results of analyses involving linear models.\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=68e5cba9-ea96-4788-9c21-afb700d3ba29&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\n4. **Everything is some kind of linear model** (13 minutes): Understanding just how general and powerful this method for understanding people can be.\n\n\n```{=html}\n<iframe src=\"https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=0f6ba49d-f54d-41d0-ab30-afb700d84744&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all\" height=\"405\" width=\"720\" style=\"border: 1px solid #464646;\" allowfullscreen allow=\"autoplay\" aria-label=\"Panopto Embedded Video Player\"></iframe>\n```\n\n\n::: callout-tip\nThe slides presented in the videos can be downloaded either as a web page or as a Word document.\n:::\n\n- [The slides](data/week18/122-linear-model-develop.html) exactly as presented (6 MB). \n- [The slides](data/week18/122-linear-model-develop-printable-edit.docx) converted to a Word .docx (1 MB). \n\nYou can download the web page `.html` file and click on it to open it in any browser (e.g., Chrome, Edge or Safari). The slide images are high quality so the file is quite big and may take a few seconds to download.\n\nYou can download the `.docx` file and click on it to open it as a Word document that you can then edit. \nConverting the slides to a .docx distorts some images but the benefit of the conversion is that it makes it easier for you to add your notes.\n\n### The lectures have three main areas of focus {#sec-wk18-lectures-focus}\n\n**1. Working with the linear model with multiple predictors**\n\nWe focus in-depth on how you code linear models, how you identify critical information in the results summaries, and how you report the results: the language and the style you can use in your reports.\n\n::: callout-tip\n- A small change to `lm()` coding releases tremendous power and flexibility in how you use the analysis method.\n:::\n\n**2. Analyses are done in context so when we conduct analyses we *must* use contextual information**\n\nThe power and flexibility of the linear model presents challenges.\nWe must decide *which* predictor variables we specify in our model.\nThis specification requires us to think about our theoretical assumptions and what they require us to include to make sense of the behaviours or the individual differences we observe when we do things like investigating what makes health information easy or difficult to understand.\n\n**3. Developing critical thinking**\n\nAs we develop conceptual understanding and practical skills, we must learn to *reflect critically* on our analyses, and learn to critically evaluate the analyses we read about when we read research reports in the scientific literature.\n\n::: callout-tip\n*Critical analysis* can develop by considering\n\n- validity\n- measurement\n- generalizability\n:::\n\nWe are always working in the broader context of uncertainty:\n\n- uncertainty about the predictions we may make concerning outcomes of interest;\n- uncertainty given the possibility that predicted effects may vary between individuals or groups;\n- uncertainty given the influence of sources of randomness in how specific responses are produced.\n\n::: callout-tip\nTo work with the recordings:\n\n- Watch the video parts right through.\n- Use the printable versions of the slides (provided on Moodle) to make notes.\n- Try out the coding exercises in the how-to guide and the acitivity tasks or questions (@sec-wk18-lab-activities) to learn how to construct visualizations and do analyses.\n:::\n\n## Reading: Links to other classes\n\nWe do not provide further reading for this class but you will find it helpful to revise some of the key ideas you have been learning about PSYC122 and in other modules.\n\n- The lectures in *PSYC123* on: the scientific method; reliability and validity; experimental design, especially between-subjects studies; hypothesis testing; and precise hypotheses.\n- The lecture in *PSYC122* on linear models. \n\n## Pre-lab activities {#sec-wk18-prelab-activities}\n\n### Pre-lab activity 1 {#sec-wk18-prelab-activities-1}\n\nIn weeks 16-19, we will be working together on a research project to investigate how people vary in their response to health advice.\n\nCompleting the project involves collecting responses from *PSYC122* students: **you**.\n\nTo enter your responses, we invite you to complete a short survey.\n\nComplete the survey by clicking on the link [here](https://lancasteruni.eu.qualtrics.com/jfe/form/SV_0qdj8TOZc18LR0q)\n\n::: callout-tip\nIn our week 19 class activity, we will analyze the data we collect here.\n:::\n\nThe survey should take about 20 minutes to complete.\n\nTaking part in the survey is **completely voluntary**.\nYou can stop at any time without completing the survey if you do not want to finish it.\nIf you do not want to do the survey, you can do an alternative activity (see below).\n\nAll responses will be recorded completely anonymously.\n\n### Pre-lab activity alternative option {#sec-wk18-prelab-activities-2}\n\nIf you do not want to complete the survey, we invite you to read the pre-registered research plan for the *PSYC122 health advice* research project.\n\n[Read the project pre-registration](https://osf.io/p6fsc/)\n\n## Lab activities {#sec-wk18-lab-activities}\n\n### Introduction {#sec-wk18-lab-activities-1-introduction}\n\nWe will do our practical lab work to develop your skills in the context of the **Clearly Understood** project.\n\n- Our focus will be on what makes it easy or difficult for people to understand written health information.\n\n::: callout-important\nIn these classes, we will complete a research project to answer the research questions:\n\n1. What person attributes predict success in understanding health information?\n2. Can people accurately evaluate whether they correctly understand written health information?\n:::\n\n### Get ready {#sec-wk18-prelab-activities-ready}\n\n#### Download the data\n\nClick on the link: [122-week18_for_students.zip](data/week18/122-week18_for_students.zip) to download the data files folder. Then upload the contents to the new folder you created in RStudio Server.\n\nThe downloadable .zip folder includes the data files:\n\n- `study-one-general-participants.csv`\n- `study-two-general-participants.csv`\n\nand the R Markdown `.Rmd`:\n\n- `2023-24-PSYC122-w18-how-to.Rmd`\n\nIf you can't upload these files to the server -- this affects some students -- you can use some code to get R to do it for you: uncover the code box below to reveal the code to do this.\n\n:::{.callout-tip collapse=\"true\"}\n## Code\n- You can use the code below to directly download the file you need in this lab activity to the server.\n- Remember that you can copy the code to your clipboard by clicking on the 'clipboard' in the top right corner.\n\n1. Get the `study-one-general-participants.csv` data\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-3_6a59b2d4438686ab03206b86ed7010e0'}\n\n```{.r .cell-code}\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/study-one-general-participants.csv?raw=true\", destfile = \"study-one-general-participants.csv\")\n```\n:::\n\n\n2. Get the `study-two-general-participants.csv` data\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-4_5708709884650e985fe801e9e7031f2d'}\n\n```{.r .cell-code}\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/study-two-general-participants.csv?raw=true\", destfile = \"study-two-general-participants.csv\")\n```\n:::\n\n\n3. Get the `2023-24-PSYC122-w18-how-to.Rmd` how-to guide\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-5_739eafae8265c0690209391489801ba4'}\n\n```{.r .cell-code}\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/2023-24-PSYC122-w18-how-to.Rmd?raw=true\", destfile = \"2023-24-PSYC122-w18-how-to.Rmd\")\n```\n:::\n\n:::\n\n#### Check: What is in the data files? {#sec-wk18-data-summary}\n\nEach of the data files we will work with has a similar structure, as you can see in this extract.\n\n\n::: {.cell hash='Week18_cache/html/headcheck-wide_127d67f2fd52cf6d795c943f59c987cd'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> participant_ID </th>\n   <th style=\"text-align:right;\"> mean.acc </th>\n   <th style=\"text-align:right;\"> mean.self </th>\n   <th style=\"text-align:left;\"> study </th>\n   <th style=\"text-align:right;\"> AGE </th>\n   <th style=\"text-align:right;\"> SHIPLEY </th>\n   <th style=\"text-align:right;\"> HLVA </th>\n   <th style=\"text-align:right;\"> FACTOR3 </th>\n   <th style=\"text-align:right;\"> QRITOTAL </th>\n   <th style=\"text-align:left;\"> GENDER </th>\n   <th style=\"text-align:left;\"> EDUCATION </th>\n   <th style=\"text-align:left;\"> ETHNICITY </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> studytwo.1 </td>\n   <td style=\"text-align:right;\"> 0.4107143 </td>\n   <td style=\"text-align:right;\"> 6.071429 </td>\n   <td style=\"text-align:left;\"> studytwo </td>\n   <td style=\"text-align:right;\"> 26 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:left;\"> Female </td>\n   <td style=\"text-align:left;\"> Higher </td>\n   <td style=\"text-align:left;\"> Asian </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> studytwo.10 </td>\n   <td style=\"text-align:right;\"> 0.6071429 </td>\n   <td style=\"text-align:right;\"> 8.500000 </td>\n   <td style=\"text-align:left;\"> studytwo </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 24 </td>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:right;\"> 58 </td>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> Female </td>\n   <td style=\"text-align:left;\"> Secondary </td>\n   <td style=\"text-align:left;\"> White </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> studytwo.100 </td>\n   <td style=\"text-align:right;\"> 0.8750000 </td>\n   <td style=\"text-align:right;\"> 8.928571 </td>\n   <td style=\"text-align:left;\"> studytwo </td>\n   <td style=\"text-align:right;\"> 66 </td>\n   <td style=\"text-align:right;\"> 40 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> Female </td>\n   <td style=\"text-align:left;\"> Higher </td>\n   <td style=\"text-align:left;\"> White </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> studytwo.101 </td>\n   <td style=\"text-align:right;\"> 0.9642857 </td>\n   <td style=\"text-align:right;\"> 8.500000 </td>\n   <td style=\"text-align:left;\"> studytwo </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 31 </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:left;\"> Female </td>\n   <td style=\"text-align:left;\"> Higher </td>\n   <td style=\"text-align:left;\"> White </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nYou can use the *scroll bar* at the bottom of the data window to view different columns.\n\nYou can see the columns:\n\n- `participant_ID` participant code;\n- `mean.acc` average accuracy of response to questions testing understanding of health guidance (varies between 0-1);\n- `mean.self` average self-rated accuracy of understanding of health guidance (varies between 1-9);\n- `study` variable coding for what study the data were collected in\n- `AGE` age in years;\n- `HLVA` health literacy test score (varies between 1-16);\n- `SHIPLEY` vocabulary knowledge test score (varies between 0-40);\n- `FACTOR3` reading strategy survey score (varies between 0-80);\n- `GENDER` gender code;\n- `EDUCATION` education level code;\n- `ETHNICITY` ethnicity (Office National Statistics categories) code.\n\n::: callout-tip\nIt is always a good idea to view the dataset -- click on the name of the dataset in the R-Studio `Environment` window, and check out the columns, scroll through the rows -- to get a sense of what you are working with.\n:::\n\n### Lab activity 1: Work with the `How-to` guide {#sec-wk18-lab-activities-1}\n\nThe `how-to` guide comprises an .Rmd file:\n\n- `2023-24-PSYC122-w18-how-to.Rmd`\n\nIt is full of advice and example code.\n\nThe code in the `how-to` guide was written to work with the data file:\n\n- `study-one-general-participants.csv`.\n\n::: callout-tip\nWe show you how to do everything you need to do in the lab activity (@sec-wk18-lab-activities-2, next) in the `how-to` guide.\n\n- Start by looking at the `how-to` guide to understand what steps you need to follow in the lab activity.\n:::\n\nWe will take things *step-by-step*.\n\nWe split .Rmd scripts by steps, tasks and questions:\n\n- different steps for different phases of the analysis workflow;\n- different tasks for different things you need to do;\n- different questions to examine different ideas or coding challenges\n\n::: callout-tip\n- Make sure you start at the top of the `.Rmd` file and work your way, in order, through each task.\n- Complete each task before you move on to the next task.\n:::\n\nIn the activity @sec-wk18-lab-activities-2, we are going to work through a sequence of steps and tasks that mirrors the sequence you find in the `how-to` guide.\n\n- There is a little bit of variation, comparing the later steps in the `how-to` guide and the steps in @sec-wk18-lab-activities-2, but that is designed to help you with your learning, in different places, when we think you will most need the support.\n\n::: callout-tip\n- Notice that we are gradually building up our skills: consolidating what we know; revising important learning; and extending ourselves to acquire new skills.\n- Over time, we will refer less and less to what we have learned before.\n:::\n\n**Step 1: Set-up**\n\n1. Empty the R environment -- using `rm(list=ls())`\n2. Load relevant libraries -- using `library()`\n\n**Step 2: Load the data**\n\n3. Read in the data file -- using `read_csv()`\n4. Inspect the data -- using `head()` and `summary()`\n\n**Step 3: Use a linear model to to answer the research questions -- one predictor**\n\n5. Use `lm()` to examine the relation between an outcome variable and one predictor variable\n\n**Step 4: Use a linear model to to answer the research questions -- multiple predictors**\n\n6. Use `lm()` to examine the relation between between an outcome variable and *multiple* predictors\n\n**Step 5: Plot predictions from linear models with multiple predictors**\n\n7. Use `ggpredict()` to plot linear model predictions for one of the predictors\n8. Produce plots that show the predictions for all the predictor variables in a model\n\nIn @sec-wk18-lab-activities-2, you will see that we show you how you can understand what linear model estimates show by examining the predictions from one outcome-predictor relation.\n\n**Step 6: Draw boxplots to examine associations between variables**\n\nThe `how-to` guide shows you how to produce boxplots. \nWe do not include the task in the @sec-wk18-lab-activities-2 tasks sequence but you *will* find it useful to produce boxplots when you are examining the impact of categorical variables (next).\n\n9. Create boxplots to examine the association between a continuous numeric outcome variable like `mean.acc` and a categorical variable like `ETHNICITY`\n\n**Step 7: Estimate the effects of factors as well as numeric variables**\n\nWe refer to categorical or nominal variables like `ETHNICITY` as *factors* in data analysis.\n\n10. Fit a linear model including both numeric variables and categorical variables as predictors\n11. Fit a linear model including both numeric variables and categorical variables as predictors, and then plot the predicted effect of the factor (the categorical variable)\n\n::: callout-tip\nIf you are unsure about what you need to do, look at the advice in `2023-24-PSYC122-w18-how-to.Rmd` on how to do the tasks, with examples on how to write the code.\n:::\n\nYou will see that you can match a task in the activity @sec-wk18-lab-activities-2 to the same task in the `how-to` guide.\nThe `how-to` shows you what function you need and how you should write the function code.\n\nThis process of adapting demonstration code is a process critical to data literacy and to effective problem solving in modern psychological science.\n\n::: callout-warning\nDon't forget: You will need to change the names of the dataset or the variables to complete the tasks in @sec-wk18-lab-activities-2.\n:::\n\n### Lab activity 2 {#sec-wk18-lab-activities-2}\n\n### OK: now let's do it!\n\nIn the following, we will guide you through the tasks and questions step by step.\n<!-- You will learn more if you follow this advice: -->\n\n::: callout-tip\n1. We will not *at first* give you the answers to questions about the data or about the results of analyses.\n2. An answers version of the workbook will be provided after the last lab session (check the answers then in @sec-wk18-lab-activities-answers) so that you can check whether your independent work has been correct.\n:::\n\n#### Questions {#sec-wk18-lab-activities-1-questions}\n\n::: callout-warning\n**Students have told us** that it would be helpful to your learning if we reduce the information in the hints we provide you. **We have done this** in Week 18.\n\nThe motivation for doing this is:\n\n1. It will require you to do more *active* thinking to complete tasks or answer questions;\n2. Thus, you can check to see how your learning is developing -- can you do the tasks, given what you know now?\n3. Plus, psychological research shows that *active* thinking is better for understanding and for learning.\n\nWhere we do give you hints, we will sometimes replace the correct bit of code with a place-holder: `...`\n\n- Your task will therefore be to replace the place-holder `...` with the correct bit of code or the correct dataset or variable name.\n:::\n\n#### Step 1: Set-up\n\nTo begin, we set up our environment in R.\n\n##### Task 1 -- Run code to empty the R environment\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- rm(list=ls()) -->\n<!-- ``` -->\n\n##### Task 2 -- Run code to load relevant libraries\n\nNotice that in Week 18, we need to work with the libraries `ggeffects` and `tidyverse`.\nUse the `library()` function to make these libraries available to you.\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- library(\"ggeffects\") -->\n<!-- library(\"tidyverse\") -->\n<!-- ``` -->\n\n#### Step 2: Load the data\n\n##### Task 3 -- Read in the data file we will be using\n\nThe data file for **Lab Activity 2** is called:\n\n- `study-two-general-participants.csv`\n\nUse the `read_csv()` function to read the data file into R.\n\n<!-- :::{.callout-tip collapse=\"true\"} -->\n<!-- ## Code -->\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- study.two.gen <- read_csv(\"study-two-general-participants.csv\") -->\n<!-- ``` -->\n<!-- ::: -->\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-7_b6c8e7f1d1a87b93f8ce4537be8ff2de'}\n\n```{.r .cell-code}\n... <- read_csv(\"...\")\n```\n:::\n\n:::\n\nWhen you code this, you can choose your own file name, but be sure to give the data object you create a distinct name e.g. `study.two.gen`.\n\n##### Task 4 -- Inspect the data file\n\nUse the `summary()` or `head()` functions to take a look.\n\n<!-- :::{.callout-tip collapse=\"true\"} -->\n<!-- ## Code -->\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- head(study.two.gen) -->\n<!-- summary(study.two.gen) -->\n<!-- ``` -->\n<!-- ::: -->\n\n::: callout-tip\n## Hint\nEven though you have done this before, you will want to do it \nagain, here, and pay particular attention to:\n\n- summary information about the numeric variables;\n- summary information about variables of class: `character`.\n:::\n\n#### Step 3: Use a linear model to to answer the research questions -- one predictor\n\n#### Revise: practice to strengthen skills\n\n::: callout-tip\n- Revise: We start by revising how to use `lm()` with one predictor\n:::\n\nOne of our research questions is:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\nWe can address this question by examining whether someone's rated evaluation of their own understanding matches their performance on a test of that understanding, and by investigating what variables predict variation in mean self-rated accuracy.\n\n- For these data, participants were asked to respond to questions about health information to get `mean.acc` scores\n- and they were then asked to rate their own understanding of the same information (ratings on a scale from 1-9) to get `mean.self` scores.\n- Ratings of accuracy are ordinal data but, here, we choose to examine the average of participants' ratings of their own understanding of health information to keep our analysis fairly simple.\n\nIf you *can* evaluate your own understanding then ratings of understanding *should* be associated with performance on tests of understanding\n\n##### Task 5 -- Estimate the relation between outcome mean self-rated accuracy (`mean.self`) and tested accuracy of understanding (`mean.acc`)\n\nWe can use `lm()` to estimate whether :\n\n1. the *outcome* variable, participants' ratings of the accuracy of their understanding (`mean.self`), can be predicted by \n2. the *predictor* variable, information about the same participants' level of accuracy in direct tests of their understanding (`mean.acc`).\n\nCan you work out how to specify the model?\n\n<!-- without looking at the code example? -->\n\n<!-- Click on the button to see the code example: compare it to the code you wrote. -->\n\n<!-- :::{.callout-tip collapse=\"true\"} -->\n<!-- ## Code -->\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model <- lm(mean.self ~ mean.acc, data = study.two.gen) -->\n<!-- summary(model) -->\n<!-- ``` -->\n<!-- ::: -->\n\nYou can get more advice on how `lm()` code works if you click on the `Hint` box.\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\nIn R analysis code, we normally write linear model analysis code like this: \n\n```{}\nmodel <- lm(outcome ~ predictor, data)\nsummary(model)\n```\n\n<!-- ```{} -->\n<!-- model <- lm(mean.self ~ mean.acc, data = study.two.gen) -->\n<!-- summary(model) -->\n<!-- ``` -->\n\n<!-- - gets us an analysis of whether or how `mean.self` predicts variation in -->\n<!-- outcome `mean.acc`. -->\n::: \n\nIf you first run the model, and then look at the model `summary` you can answer the following questions.\n\n#### Questions: Task 5\n\n>**Q.1.** What is the estimate for the coefficient of the effect of the predictor \n`mean.acc` on the outcome `mean.self` in this model?\n\n<!-- - A.1. 5.5670  -->\n\n>**Q.2.** Is the effect significant?\n\n<!-- - A.2. It is significant, p < .05 -->\n\n>**Q.3.** What are the values for t and p for the significance test for the coefficient?\n\n<!-- - A.3. t = 8.499, p = 9.36e-15 -->\n\n>**Q.4.** What do you conclude is the answer to the research question, given the \nlinear model results?\n\n<!-- - A.4. The model slope estimate suggests that higher levels of tested understanding can predict higher levels of rated understanding so, yes: it does appear\nthat people can evaluate their own understanding. -->\n\n>**Q.5.** What is the F-statistic for the regression? Report F, DF and the p-value.\n\n<!-- - A.5. F-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15 -->\n\n>**Q.6.** Is the regression significant?\n\n<!-- - A.6. Yes: the regression is significant. -->\n\n>**Q.7.** What is the Adjusted R-squared?\n\n<!-- - A.7. Adjusted R-squared:  0.2941 -->\n\n>**Q.8.** Explain in words what this R-squared value indicates?\n\n<!-- - A.8. The R-squared suggests that about 30% of outcome variance can be explained by the model -->\n\n#### Step 4: Use a linear model to to answer the research questions -- multiple predictors\n\n#### Introduce: make some new moves\n\nOne of our research questions is:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\nWe have already looked at this question by asking whether ratings of understanding are predicted by performance on tests of understanding.\n\nBut there is a problem with that analysis -- it leaves open the question: \n\n- What *actually* predicts ratings of understanding?\n\nWe can look at this follow-up question, next.\n\n##### Task 6 -- Examine the relation between outcome mean self-rated accuracy (`mean.self`) and  multiple predictors\n\nHere, the predictors will include *all* of:\n\n- health literacy (`HLVA`); \n- vocabulary (`SHIPLEY`); \n- age in years (`AGE`); \n- reading strategy (`FACTOR3`);\n- as well as average accuracy of the tested understanding of health information (`mean.acc`).\n\nWe use `lm()`, as before, but now when we specify the model we write the code to include all of the *multiple* predictors in the same model at the same time.\n\n- When you do this, specify all of the predictors we list.\n- Specify each variable listed here by using the variable name.\n\nCan you write the code you need to do the linear model analysis?\n\nYou can click on the button to see the hint.\nYou can see example code, for a different model, for Step 4 in the `2023-24-PSYC122-w18-how-to.Rmd`.\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\nYou can include multiple predictor variables in a model by:\n\n- listing the predictors in series;\n- specifying each predictor variable name;\n- entering the names `...` separated by a `+`;\n- one variable at a time `... + ...`;\n- like this:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-8_ad45bf107e3f4610f8ab22a52cb1e058'}\n\n```{.r .cell-code}\nmodel <- lm(outcome ~ ... + ... + ..., \n            data = study.two.gen)\nsummary(model)\n```\n:::\n\n\nYou will need to replace place-holder `...`s with the names of variables as they appear in the dataset.\n<!-- ## Code -->\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc,  -->\n<!--             data = study.two.gen) -->\n<!-- summary(model) -->\n<!-- ``` -->\n:::\n\nIf you look at the model summary you can answer the following questions.\n\n>**Q.9.** What predictors are significant in this model?\n\n<!-- - A.9. Vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`), `AGE`, and performance on tests of accuracy of understanding (`mean.acc`) all appear to significantly predict variation in mean ratings of understanding (`mean.self`). -->\n\n>**Q.10.** What is the estimate for the coefficient of the effect of the predictor `mean.acc` in this model?\n\n<!-- - A.10. 4.763278  -->\n\n>**Q.11.** Is the effect significant?\n\n<!-- - A.11. It is significant, p < .05 -->\n\n>**Q.12.** What are the values for t and p for the significance test for the coefficient?\n\n<!-- - A.12. t = 6.726, p = 2.69e-10 -->\n\n>**Q.13.** What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\n\n<!-- - A.13. Ratings of understanding appear to be predicted by performance on tests of accuracy of understanding, together with variation in age, vocabulary knowledge, health literacy and reading strategy -->\n\n#### Step 5: Understanding linear model predictions by comparing one outcome-predictor relation\n\n#### Consolidate your learning\n\nNext, we focus in on whether (1.) `mean.self` predicts `mean.acc` or, in reverse, whether (2.) `mean.acc` predicts `mean.self`?\n\nWe are talking about two models here:\n\n1. The model `mean.acc ~ mean.self`\n2. The model `mean.self ~ mean.acc`\n\n::: callout-tip\n## Important\n- A comparison between these models teaches us something important about *what* it is that linear models predict.\n:::\n  \nYou will learn something about how linear models work if you look closely at the `Estimate` value in the summary for each model.\n\n- Where we reference model estimates, here, we are looking at the values in the`Estimate` column of the `lm()` model summary.\n- These estimates give us the expected or predicted change in the outcome, given change in the predictor variable named on that row.\n  \nCompare the `Estimate` value in the summary for each model. Then have a think about why these values are *different* even though the variables and the data are the same.\n  \nRemember that:\n\n- `mean.acc` is scaled from 0 to 1 because it represents the average accuracy of the responses made by study participants to questions about health texts.\n- `mean.self` is scaled from 1 to 9 because it represents the average self-rated accuracy of understanding.\n  \n>**Q.14.** Why do you think it appears that the slope coefficient estimate is different if you compare:\n\n1. The model `mean.acc ~ mean.self` versus \n2. The model `mean.self ~ mean.acc`?\n\nYou can fit these two simple models using the verbal description in the **Q.14.** information, plus what you have learned so far.\n\n- Remember to give each model a *different* name.\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\n1. Remember: you write model code with the outcome on the left of the tilde symbol `~` and the predictor (or predictors) on the right of the `~`.\n2. In the model information, we specify two different models.\n\n- The variables and the data are the same.\n- But *which* variable is the outcome, and *which* variable is the predictor, is different in the two models.\n:::\n\n<!-- Click on the `Code` button following, if you want to see the example code. -->\n\n<!-- :::{.callout-tip collapse=\"true\"} -->\n<!-- ## Code -->\n<!-- If we want to compare two models: -->\n\n<!-- 1. The model `mean.acc ~ mean.self` versus  -->\n<!-- 2. The model `mean.self ~ mean.acc` -->\n\n<!-- Then we can specify each model as follows. -->\n\n<!-- **1. The model `mean.acc ~ mean.self`** -->\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model.1 <- lm(mean.acc ~ mean.self, data = study.two.gen) -->\n<!-- summary(model.1) -->\n<!-- ``` -->\n\n<!-- **2. The model `mean.self ~ mean.acc`** -->\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model.2 <- lm(mean.self ~ mean.acc, data = study.two.gen) -->\n<!-- summary(model.2) -->\n<!-- ``` -->\n<!-- ::: -->\n\n**Do that** then compare the `Estimate` of the predictor effect in the two models.\n\n- Reflect on what the comparison shows about the *scale* of predicted effects.\n- Have a think before clicking on the `Hint` button to see our information on the key learning we are talking about here.\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\nWhat does a comparison of the model predictor `Estimate` values show us?\n\n- You may benefit by reflecting on the [lm-intro](https://lu-psy-r.github.io/statistics_for_psychologists/PSYC122/Week17.html)) lecture and practical materials, especially where they concern predictions.\n\nThe lesson to learn here is that:\n \n1. If we have the model, `mean.acc ~ mean.self` then this means that the outcome is `mean.acc`.\n\n- So if we are predicting change in outcome `mean.acc`, which is **scaled 0-1**, \nthen we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\n- Here: the model estimate will show that each unit change in values of the variable `mean.self` predicts an increase of 0.053566 in `mean.acc`.\n\n2. Whereas if we have the model, `mean.self ~ mean.acc` then this means that the outcome is `mean.self`.\n\n- So if we are predicting change in outcome `mean.self`, which is **scaled 1-9**, then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\n- Here: the model estimate will show that unit change in `mean.acc` predicts increase of 5.5670 in `mean.self`.\n\nRemember that:\n\n- `mean.acc` is scaled from 0 to 1 because it represents the average accuracy of the responses made by study participants to questions about health texts. This average *has* to have a minimum of 0 (no responses correct) and a maximum of 1 (all responses correct). The average is calculated by adding up all the correct answers and dividing by the number of questions answered by each participant.\n- `mean.self` is scaled from 1 to 9 bcause it represents the average self-rated accuracy of understanding. Participants are asked to rate on a scale form 1 (not all) to 9 (very well) how well they think they understand a health information text. The average is calculated by adding up all the  ratings and dividing by the number of texts responded to by each participant.\n\nThe **important lesson**, here, is that estimates of predictor effects are scaled in terms of predicted change in the outcome, so whatever scale the outcome measurement is in determines how big or small the predictor coefficient estimates can be.\n:::\n\n<!-- - A.14. Linear models are prediction models. We use them to predict variation in -->\n<!-- outcomes given some set of predictor variables. Predictions will necessarily be *scaled* -->\n<!-- in the same way as the outcome variable.  -->\n\nWe can visualize the predictions from each model to *visualize* the comparison. This will help your learning:\n\n- Look at *how much* the outcome is predicted to change;\n- Look at the values on the y-axis labels.\n\n>**Q.15.** Can you plot the predictions from each model?\n\n<!-- - A.15. Here is the code to plot the predictions from both models. -->\n\nCan you work out how to write the model prediction plotting code without looking at the code example?\n\nClick on the Hint button to see advice on what you need to do. \nYou can see example code, for a different model, for Step 5 in the `2023-24-PSYC122-w18-how-to.Rmd`.\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\n**First** fit the models like this:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-9_019d36e9ace14569d1adf9ac79b71f04'}\n\n```{.r .cell-code}\nmodel.1 <- lm(outcome ~ predictor, data)\n```\n:::\n\n\n- Remember to give each model object distinct names.\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model.1 <- lm(mean.acc ~ mean.self,  -->\n<!--               data = study.two.gen) -->\n<!-- summary(model.1) -->\n\n<!-- model.2 <- lm(mean.self ~ mean.acc,  -->\n<!--             data = study.two.gen) -->\n<!-- summary(model.2) -->\n<!-- ``` -->\n\n**Second** get the predictions like this:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-10_bc7247b637807d49a44982e44ee5cf4d'}\n\n```{.r .cell-code}\nmodel.predictions <- ggpredict(model.1, \"...\")\n```\n:::\n\n\n- Replace `...` with the name of the predictor in `model.1`.\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- dat.1 <- ggpredict(model.1, \"mean.self\") -->\n<!-- dat.2 <- ggpredict(model.2, \"mean.acc\") -->\n<!-- ``` -->\n\n**Third** make the prediction plots like this:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-11_9d7b25bb85bf3d0edefbd07d75fd5d2f'}\n\n```{.r .cell-code}\nplot(model.predictions)\n```\n:::\n\n\n<!-- 1. Predictions from the model `mean.acc ~ mean.self` -->\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- plot(dat.1) -->\n<!-- ``` -->\n\n<!-- 2. Predictions from the model `mean.self ~ mean.acc` -->\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- plot(dat.2) -->\n<!-- ``` -->\n:::\n\n>**Q.16.** Look at the two plots: what do you see?\n\nLook at changes in height of the prediction line, given changes in predictor values.\n\n<!-- - A.16. A side-by-side comparison shows that: -->\n\n<!-- 1. For model `mean.acc ~ mean.self` increases in `mean.self` from about 4 to 9 are  -->\n<!-- associated with a change in `mean.acc` from about .6 to about .85; -->\n<!-- 2. For model `mean.self ~ mean.acc` increases in `mean.acc` from about 0.4 to 1.0 are  -->\n<!-- associated with a change in `mean.self` from about 5 to about 9. -->\n\n#### Step 6: Estimate the effects of factors as well as numeric variables\n\n#### Consolidation: build your skills\n\nWe have not yet included any categorical or nominal variables as predictors but we can, and should: `lm()` can cope with any kind of variable as a predictor.\n\nThere are different ways to do this, here we ask you to use the R default method.\n\n##### Task 7 -- Fit a linear model to examine what variables predict outcome mean self-rated accuracy of `mean.self`\n\nInclude as predictors both numeric variables and categorical variables.\n\nHere, our model includes predictors that are numeric like:\n\n- health literacy (`HLVA`); \n- vocabulary (`SHIPLEY`); \n- `AGE`;\n- reading strategy (`FACTOR3`);\n- accuracy `mean.acc`.\n\nAs well as a categorical or nominal variable like:\n\n- `EDUCATION`.\n\nNote: `EDUCATION` is a categorical or nominal variable *because* participants are classified by what education category (`higher education, further education, secondary school`) they report themselves as having received.\n\nCan you write the code to complete the linear model analysis?\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\nFollow the same procedure for model specification that you have been learning to follow: the inclusion of a nominal variable does not affect how you specify the model.\n:::\n\n<!-- Check first if you can write the code you need to complete the linear model analysis. -->\n\n<!-- Click on the button to see the code example: compare it to the code you wrote. -->\n\n<!-- :::{.callout-tip collapse=\"true\"} -->\n<!-- ## Code -->\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + -->\n<!--                         EDUCATION,  -->\n<!--             data = study.two.gen) -->\n<!-- summary(model) -->\n<!-- ``` -->\n<!-- ::: -->\n\nIf you look at the model summary you can answer the following questions.\n\n>**Q.17.** Can you report the overall model and model fit statistics?\n\n<!-- - A.17.  -->\n\n<!-- > We fitted a linear model with mean self-rated accuracy as the outcome and with the predictors:  -->\n<!-- health literacy (`HLVA`), vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`), `AGE`, -->\n<!-- as well as mean accuracy (`mean.acc`) and education level (`EDUCATION`).  -->\n<!-- The model is significant overall, with F(7, 164) = 24.38, p < .001, and  -->\n<!-- explains 49% of variance (adjusted R2 = 0.489). -->\n\n>**Q.18.** Can you plot the predicted effect of `EDUCATION` given your model?\n\n:::{.callout-tip collapse=\"true\"}\n## Hint\nFollow the same procedure that you have been learning to follow.\n\n1. Fit the model:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-12_4729a7669d37544116d750ec6d999182'}\n\n```{.r .cell-code}\nmodel <- lm(outcome ~ predictors, data)\n```\n:::\n\n\n- Replace `outcome` with the outcome variable required for this analysis.\n- Replace `predictor` with the predictor variable required for this analysis.\n- Replace `data` with the name of the correct data set.\n- Give the model a distinctive name.\n\n2. Get the predictions:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-13_14df0b25f9faad3a97e2a4bbf27bdc6d'}\n\n```{.r .cell-code}\nmodel.predictions <- ggpredict(model, \"EDUCATION\")\n```\n:::\n\n\n- Use the model name you assigned to the analysis you just did.\n- Ask for predictions of the effect on outcomes of the nominal variable.\n\n3. Plot the predictions:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-14_4838d1c68833b844331100e1eb53c540'}\n\n```{.r .cell-code}\nplot(model.predictions)\n```\n:::\n\n:::\n\n<!-- Check first if you can write the code produce the prediction plot. -->\n\n<!-- Click on the button to see the code example: compare it to the code you wrote. -->\n\n<!-- :::{.callout-tip collapse=\"true\"} -->\n<!-- ##Hint and code -->\n<!-- 1. We first fit the model, including `EDUCATION`. -->\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- model <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + -->\n<!--               EDUCATION,  -->\n<!--             data = study.two.gen) -->\n<!-- ``` -->\n\n<!-- 2. We then use the `ggpredict()` function to get the prediction for the effect of `EDUCATION` differences on outcome `mean.self`. -->\n\n<!-- ```{r} -->\n<!-- #| eval: false -->\n<!-- dat <- ggpredict(model, \"EDUCATION\") -->\n<!-- plot(dat) -->\n<!-- ``` -->\n<!-- ::: -->\n\n>**Q.19.** The plot should give you dot-and-whisker representations of the estimated `mean.self` outcome for different levels of `EDUCATION`. What is the difference in the estimated `mean.self` between the groups?\n\nThe effect or prediction plot will show you **dot-and-whisker** representations of predicted outcome `mean.self`. In these plots, the dots represent the estimated `mean.self` while the lines (whiskers) represent confidence intervals.\n\n<!-- - A.19. The difference in the estimated `mean.self` between these groups is small: the groups vary between ratings of about 7, 7.10 and 7.5. -->\n\n>**Q.20.** Compare the difference in the estimated `mean.self` between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\n\n<!-- - A.20. The effect of `EDUCATION` is presented in the summary as two estimates: -->\n\n<!-- - `EDUCATIONHigher    -0.082217` -->\n<!-- - `EDUCATIONSecondary  0.346161` -->\n\n<!-- The reference level for `EDUCATION` is `Further`.  -->\n\n<!-- The estimates therefore show that people with `Higher` education have `mean.self`  -->\n<!-- scores about -.08 lower than `mean.self` for people with `Further` education.  -->\n\n<!-- People with `Secondary` education have `mean.self` scores about .35 higher than  -->\n<!-- `mean.self` for people with `Further` education. -->\n\nWe are learning some new things here so it is useful to explain them in a bit more detail:\n\n1. Categorical variables or **factors** and reference levels.\n\n- If you have a categorical variable like `EDUCATION` then when you use it in an analysis, R will look at the different categories (called `levels`) e.g., here, `higher education, further education, secondary school` and it will pick one level to be the *reference* or baseline level. \n- The *reference* is the the level against which other levels are compared. \n- Here, the reference level is `Further` (education) simply because, unless\nyou tell R otherwise, it picks the level with a category name that begins\nearlier in the alphabet as the reference level.\n\n2. Dot and whisker plots show estimates with confidence intervals.\n\n- Dot and whisker plots are a nice way to present a concise visual summary\nabout the estimates we get from prediction models.\n- Here, the plots show the coefficient estimates from our model (the dots) plus \nconfidence intervals (the lines or \"whiskers\").\n\n3. Confidence intervals are often misunderstood but they are helpful.\n\n- Essentially, a confidence interval tells us about we might expect to see\nusing our analysis procedure (Hoekstra et al., 2014).\n\n> If we were to repeat the experiment over and over, then 95 % of the time the \nconfidence intervals contain the true mean.\n\n::: callout-tip\n## Reading to grow your understanding\n- You can read more about this here:\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E. J. (2014). Robust misinterpretation of confidence intervals. *Psychonomic Bulletin & Review*, 21, 1157-1164.\n:::\n\n#### You have now completed the Week 18 questions.\n\nYou have now extended the power of the linear models that you can deploy to predict people and their behaviour.\n\n::: callout-tip\nModels like the models you have been working with are used by:\n\n- scientists to predict outcomes relevant to important research questions;\n- businesses using *Artificial Intelligence* to predict client or customer outcomes.\n:::\n\n## Answers {#sec-wk18-lab-activities-answers}\n\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week.\n\n::: callout-tip\nThe `.Rmd` script containing all code and all answers for each task and each question will be made available after the final lab session has taken place.\n\n- You can download the script [2023-24-PSYC122-w18-workbook-answers](data/week18/2023-24-PSYC122-w18-workbook-answers) when it is available.\n:::\n\nWe set out answers information the Week 18 **Developing the linear model** questions, below.\n\n- We focus on the **Lab activity 2** questions where we ask you to interpret something or say something.\n- We do not show questions where we have given example or target code in the foregoing lab activity @sec-wk18-lab-activities-2.\n\nYou can see all the code and all the answers in `2023-24-PSYC122-w18-workbook-answers.Rmd`.\n\n### Answers {#sec-wk18-lab-activities-answers-information}\n\n::: callout-tip\nClick on a box to reveal the answer.\n:::\n\n#### Questions {#sec-wk18-lab-activities-2-questions-answers}\n\n>**Q.1.** What is the estimate for the coefficient of the effect of the predictor\n`mean.acc` on the outcome `mean.self` in this model?\n\nThe model is:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-15_1041846da1ba2560592bb59803310e1c'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ mean.acc, data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,\tAdjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n```\n:::\n:::\n\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.1. 5.5670\n:::\n\n>**Q.2.** Is the effect significant?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.2. It is significant, p < .05\n:::\n\n>**Q.3.** What are the values for t and p for the significance test for the coefficient?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.3. t = 8.499, p = 9.36e-15\n:::\n\n>**Q.4.** What do you conclude is the answer to the research question, given the\nlinear model results?\n\nThe research questions is:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.4. The model slope estimate suggests that higher levels of tested understanding can predict higher levels of rated understanding so, yes: it does appear\nthat people can evaluate their own understanding.\n:::\n\n>**Q.5.** What is the F-statistic for the regression? Report F, DF and the p-value.\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.5. F-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n:::\n\n>**Q.6.** Is the regression significant?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.6. Yes: the regression is significant.\n:::\n\n>**Q.7.** What is the Adjusted R-squared?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.7. Adjusted R-squared:  0.2941\n:::\n\n>**Q.8.** Explain in words what this R-squared value indicates?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.8. The R-squared suggests that about 30% of outcome variance can be explained by the model\n:::\n\n>**Q.9.** What predictors are significant in this model?\n\nThe model is:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-16_c31761dfde583a66d2d65db44662a416'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc,\n            data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n    data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.72027 -0.49118 -0.00177  0.55561  2.00134 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.561110   0.700632   0.801   0.4244    \nHLVA         0.041272   0.034833   1.185   0.2378    \nSHIPLEY     -0.046125   0.018701  -2.466   0.0147 *  \nFACTOR3      0.063689   0.010747   5.926 1.74e-08 ***\nAGE          0.025570   0.005472   4.673 6.12e-06 ***\nmean.acc     4.763278   0.708166   6.726 2.69e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8805 on 166 degrees of freedom\nMultiple R-squared:  0.5014,\tAdjusted R-squared:  0.4864 \nF-statistic: 33.39 on 5 and 166 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.9. Vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`), `AGE`, and performance on tests of accuracy of understanding (`mean.acc`) all appear to significantly predict variation in mean ratings of understanding (`mean.self`).\n:::\n\n>**Q.10.** What is the estimate for the coefficient of the effect of the predictor `mean.acc` in this model?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.10. 4.763278\n:::\n\n>**Q.11.** Is the effect significant?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.11. It is significant, p < .05\n:::\n\n>**Q.12.** What are the values for t and p for the significance test for the coefficient?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.12. t = 6.726, p = 2.69e-10\n:::\n\n>**Q.13.** What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.13. Ratings of understanding appear to be predicted by performance on tests of accuracy of understanding, together with variation in age, vocabulary knowledge, health literacy and reading strategy\n:::\n\n>**Q.14.** Why do you think it appears that the slope coefficient estimate is different if you compare:\n\n1. The model `mean.acc ~ mean.self` versus\n2. The model `mean.self ~ mean.acc`?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.14. Linear models are prediction models. We use them to predict variation in outcomes given some set of predictor variables. Predictions will necessarily be *scaled* in the same way as the outcome variable.\n\nSo, to expand on that explanation a bit more, to help understanding -- the answer is:\n\n1. If we have the model, `mean.acc ~ mean.self` then this means that the outcome is `mean.acc`.\n\n- So if we are predicting change in outcome `mean.acc`, which is **scaled 0-1**, then we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\n- Here: the model estimate suggests that each unit change in values of the variable `mean.self` predicts an increase of 0.053566 in `mean.acc`.\n\n2. Whereas if we have the model, `mean.self ~ mean.acc` then this means that the outcome is `mean.self`.\n\n- So if we are predicting change in outcome `mean.self`, which is **scaled 1-9** , then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\n- Here: the model estimate suggests that unit change in `mean.acc` predicts increase of 5.5670 in `mean.self`.\n:::\n\n>**Q.15.** Can you plot the predictions from each model?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.15. Here is the code to plot the predictions from both models.\n:::\n\n:::{.callout-tip collapse=\"true\"}\n## Code\n**First** fit the models.\n\n- Remember to give each model object distinct names.\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-17_02f521ddb69b807ebbbc8b27e68e7ab7'}\n\n```{.r .cell-code}\nmodel.1 <- lm(mean.acc ~ mean.self,\n              data = study.two.gen)\nsummary(model.1)\n\nmodel.2 <- lm(mean.self ~ mean.acc,\n            data = study.two.gen)\nsummary(model.2)\n```\n:::\n\n\n**Second** get the predictions:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-18_341c15ef7408ec2ec8545872b5ac6573'}\n\n```{.r .cell-code}\ndat.1 <- ggpredict(model.1, \"mean.self\")\ndat.2 <- ggpredict(model.2, \"mean.acc\")\n```\n:::\n\n\n**Third** make the prediction plots:\n\n1. Predictions from the model `mean.acc ~ mean.self`\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-19_1b86c9d52b8f2845385df4b555b2907c'}\n\n```{.r .cell-code}\nplot(dat.1)\n```\n:::\n\n\n2. Predictions from the model `mean.self ~ mean.acc`\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-20_fd75f4b804074dae848a726db8785a39'}\n\n```{.r .cell-code}\nplot(dat.2)\n```\n:::\n\n:::\n\n>**Q.16.** Look at the two plots: what do you see?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.16. A side-by-side comparison shows that:\n\n1. For model `mean.acc ~ mean.self` increases in predictor `mean.self` from about 4 to 9 are associated with a change in outcome `mean.acc` from about .6 to about .85;\n2. For model `mean.self ~ mean.acc` increases in predictor `mean.acc` from about 0.4 to 1.0 are associated with a change in outcome `mean.self` from about 5 to about 9.\n:::\n\nAfter you have fitted a linear model to examine what variables predict outcome mean self-rated accuracy of `mean.self`:\n\n- Including as predictors both numeric variables and categorical variables.\n\nThen if you look at the model summary you can answer the following questions.\n\n>**Q.17.** Can you report the overall model and model fit statistics?\n\nThe model is:\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-21_df669cec251132754638746851390867'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc +\n                        EDUCATION,\n            data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + \n    EDUCATION, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70987 -0.50037  0.01988  0.55965  2.01412 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.487753   0.702049   0.695   0.4882    \nHLVA                0.047100   0.034915   1.349   0.1792    \nSHIPLEY            -0.044132   0.018719  -2.358   0.0196 *  \nFACTOR3             0.061918   0.010771   5.749 4.29e-08 ***\nAGE                 0.023997   0.005595   4.289 3.06e-05 ***\nmean.acc            4.912833   0.712381   6.896 1.10e-10 ***\nEDUCATIONHigher    -0.082217   0.146390  -0.562   0.5751    \nEDUCATIONSecondary  0.346161   0.266030   1.301   0.1950    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8783 on 164 degrees of freedom\nMultiple R-squared:  0.5099,\tAdjusted R-squared:  0.489 \nF-statistic: 24.38 on 7 and 164 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.17.\n\n> We fitted a linear model with mean self-rated accuracy as the outcome and with the predictors: health literacy (`HLVA`), vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`), `AGE`, as well as mean accuracy (`mean.acc`) and education level (`EDUCATION`). The model is significant overall, with F(7, 164) = 24.38, p < .001, and explains 49% of variance (adjusted R2 = 0.489).\n:::\n\n>**Q.18.** Can you plot the predicted effect of `EDUCATION` given your model?\n\n:::{.callout-tip collapse=\"true\"}\n## Hint and code\n1. We first fit the model, including `EDUCATION`.\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-22_c8e7bdb0a3b4dd00e4d4724cc46ce382'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + EDUCATION,\n            data = study.two.gen)\n```\n:::\n\n\n2. We then use the `ggpredict()` function to get the prediction for the effect of `EDUCATION` differences on outcome `mean.self`.\n\n\n::: {.cell hash='Week18_cache/html/unnamed-chunk-23_0028621f431389ce53e077270da31700'}\n\n```{.r .cell-code}\ndat <- ggpredict(model, \"EDUCATION\")\nplot(dat)\n```\n:::\n\n:::\n\n>**Q.19.** Q.19. The plot should give you dot-and-whisker representations of the estimated `mean.self` outcome for different levels of `EDUCATION`. What is the difference in the estimated `mean.self` between the groups?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.19. The difference in the estimated `mean.self` between these groups is small: the groups vary between ratings of about 7, 7.10 and 7.5.\n:::\n\n>**Q.20.** Compare the difference in the estimated `mean.self` between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\n\n::: {.callout-note icon=false collapse=\"true\"}\n## Answer\n- A.20. The effect of `EDUCATION` is presented in the summary as two estimates:\n\n- `EDUCATIONHigher    -0.082217`\n- `EDUCATIONSecondary  0.346161`\n\nThe reference level for `EDUCATION` is `Further`.\n\nThe estimates therefore show that people with `Higher` education have `mean.self`\nscores about -.08 lower than `mean.self` for people with `Further` education.\n\nPeople with `Secondary` education have `mean.self` scores about .35 higher than\n`mean.self` for people with `Further` education.\n:::\n\n## Online Q&A {#sec-wk18-lab-Q-and-A}\n\nYou will find, below, a link to the video recording of the Week 18 online Q&A after it has been completed.\n\n\n```{=html}\n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}