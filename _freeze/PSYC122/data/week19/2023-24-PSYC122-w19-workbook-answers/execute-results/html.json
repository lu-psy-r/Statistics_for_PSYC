{
  "hash": "b550fd15d674d019aadb935cff8e05bc",
  "result": {
    "markdown": "---\ntitle: \"2023-24-PSYC122-w19-workbook-answers\"\nauthor: Rob Davies\ndate: \"2024-03-12\"\noutput: word_document\n---\n\n\n\n\n\n# Introduction\n\n\nIn Week 19, we aim to *further develop* skills in working with the linear model.\n\nWe do this to learn how to answer research questions like:\n\n1. What person attributes predict success in understanding?\n2. Can people accurately evaluate whether they correctly understand written \nhealth information?\n\nIn Week 19, we use data contributed by PSYC122 students to figure out our answers to these questions.\n\nWe compare PSYC122 results to the results from a previous study so that we can assess the robustness of our findings.\n\nIn this class, what is new is our focus on critically evaluating -- comparing, reflecting on -- the evidence from more than one relevant study.\n\n- This work simulates the kind of critical evaluation of evidence that psychologists must do in professional research.\n\n## Naming things\n\nI will format dataset names like this: \n\n- `study-two-general-participants.csv`\n\nI will also format variable (data column) names like this: `variable` \n\nI will also format value or other data object (e.g. cell value) names like this: `studyone`\n\nI will format functions and library names like this: e.g. function `ggplot()` or e.g. library `{tidyverse}`.\n\n## The data we will be using\n\n1. Data from a study we conducted on the response of adults from a UK national participant sample:\n\n- `study-two-general-participants.csv`\n\n2. Data comprising the responses of PSYC122 students:\n\n- `2023-24_PSYC122-participants.csv`\n\nNotice that study-two participants and the PSYC122 participants were given similar tests but different health information texts to read and respond to.\n\n\n# Answers\n\n\n## Step 1: Set-up\n\n\nTo begin, we set up our environment in R.\n\n\n### Task 1 -- Run code to empty the R environment\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-1_543858532b0893d449ddb023a7dbbcab'}\n\n```{.r .cell-code}\nrm(list=ls())                            \n```\n:::\n\n\n\n### Task 2 -- Run code to load relevant libraries\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-2_9dfb281b7d55a84fefcbd78a8a61a9cf'}\n\n```{.r .cell-code}\nlibrary(\"ggeffects\")\nlibrary(\"patchwork\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'patchwork' was built under R version 4.1.1\n```\n:::\n\n```{.r .cell-code}\nlibrary(\"tidyverse\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\n\n## Step 2: Load the data\n\n\n### Task 3 -- Read in the data files we will be using\n\nThe data files are called:\n\n- `study-two-general-participants.csv`\n- `2023-24_PSYC122-participants.csv`\n\nUse the `read_csv()` function to read the data files into R:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-3_1f2d541a21304fd3d62ea6dba19a242d'}\n\n```{.r .cell-code}\nstudy.two.gen <- read_csv(\"study-two-general-participants.csv\")  \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nstudy.122 <- read_csv(\"2023-24_PSYC122-participants.csv\")  \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 65 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): ResponseId, GENDER, EDUCATION, ETHNICITY, NATIVE.LANGUAGE, OTHER.LA...\ndbl (8): AGE, EDUCATION.rating_1, ENGLISH.PROFICIENCY, SHIPLEY, HLVA, FACTOR...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nWhen you read the data files in, give the data objects you create distinct name \ne.g. `study.two.gen` versus `study.122`.\n\n\n### Task 4 -- Inspect the data file\n\nUse the `summary()` or `head()` functions to take a look at both datasets.\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-4_e1efb44ed9374da56e6a14de51ad4bbe'}\n\n```{.r .cell-code}\nsummary(study.two.gen)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n```\n:::\n\n```{.r .cell-code}\nsummary(study.122)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  ResponseId             AGE           GENDER           EDUCATION        \n Length:65          Min.   :18.00   Length:65          Length:65         \n Class :character   1st Qu.:18.00   Class :character   Class :character  \n Mode  :character   Median :19.00   Mode  :character   Mode  :character  \n                    Mean   :19.42                                        \n                    3rd Qu.:19.00                                        \n                    Max.   :56.00                                        \n                                                                         \n EDUCATION.rating_1  ETHNICITY         NATIVE.LANGUAGE    OTHER.LANGUAGE    \n Min.   :4.000      Length:65          Length:65          Length:65         \n 1st Qu.:7.000      Class :character   Class :character   Class :character  \n Median :7.000      Mode  :character   Mode  :character   Mode  :character  \n Mean   :7.077                                                              \n 3rd Qu.:8.000                                                              \n Max.   :9.000                                                              \n                                                                            \n ENGLISH.PROFICIENCY  OCCUPATION           SHIPLEY           HLVA       \n Min.   :1.000       Length:65          Min.   :10.00   Min.   : 1.000  \n 1st Qu.:2.500       Class :character   1st Qu.:30.00   1st Qu.: 7.000  \n Median :3.000       Mode  :character   Median :32.00   Median : 8.000  \n Mean   :2.571                          Mean   :32.31   Mean   : 8.508  \n 3rd Qu.:3.000                          3rd Qu.:36.00   3rd Qu.:10.000  \n Max.   :3.000                          Max.   :40.00   Max.   :14.000  \n NA's   :58                                                             \n    FACTOR3         mean.acc        mean.self   \n Min.   :28.00   Min.   :0.2500   Min.   :2.60  \n 1st Qu.:43.00   1st Qu.:0.7500   1st Qu.:6.20  \n Median :46.00   Median :0.8500   Median :7.00  \n Mean   :46.91   Mean   :0.8231   Mean   :6.92  \n 3rd Qu.:52.00   3rd Qu.:0.9500   3rd Qu.:7.80  \n Max.   :61.00   Max.   :1.0000   Max.   :9.00  \n                                                \n```\n:::\n:::\n\n\n\n## Step 3: Compare the data from the different studies\n\n\n### Revise: practice to strengthen skills\n\n\n### Task 5 --  Compare the data distributions from the two studies\n\n\n- Q.1. What is the mean of the `mean.acc` and `SHIPLEY` variables in the two studies?\n- A.1. The means are:\n\n- study two -- `mean.acc`: mean = 0.7596\n- study two -- `SHIPLEY`: mean = 35.13\n- study PSYC122 -- `mean.acc`: mean = 0.8231\n- study PSYC122 -- `SHIPLEY`: mean = 32.31\n\n\n- Q.2. Draw histograms of both mean.acc and mean.self for both studies.\n- A.2. You can write the code as you have been shown to do e.g. in `2023-24-PSYC122-w19-how-to.Rmd`:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-5_876974c0c27ed4e88c416a07231ed690'}\n\n```{.r .cell-code}\nggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0, 40)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = study.122, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\") +\n  xlim(0, 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = study.122, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\") +\n  xlim(0, 40)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-5-4.png){width=672}\n:::\n:::\n\n\n\n### Introduce: make some new moves\n\n\n### Task 6 --  Create grids of plots to make the comparison easier to do\n\n### hint: Task 6 -- What we are going to do is to create two histograms and then present them side by side to allow easy comparison of variable distributions\n\nWe need to make two changes to the coding approach you have been using until now.\n\nBefore we explain anything, let's look at an example: run these line of code and check the result.\n\n- Make sure you identify what is different about the plotting code, shown following, compared to what you have done before: there is a *surprise* in what is going to happen.\n\nFirst, create plot objects, give them names, but do not show them:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-6_38ce9cf66c39e01b96486b110fa7b6cd'}\n\n```{.r .cell-code}\nplot.two <- ggplot(data = study.two.gen, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 1)\n\nplot.122 <- ggplot(data = study.122, aes(x = mean.acc)) + \n  geom_histogram(binwidth = .1) +\n  theme_bw() +\n  labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study PSYC122\") +\n  xlim(0, 1)\n```\n:::\n\n\nSecond, show the plots, side-by-side:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-7_cdc5086e25cb404f8099c13a90b6a5a2'}\n\n```{.r .cell-code}\nplot.two + plot.122\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\nRemoved 2 rows containing missing values (`geom_bar()`).\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThis is what you are doing: check out the process, step-by-step.\n(And notice that you repeat the process for each of two (or more) plots.)\n\n1. `ggplot(...)` tell R you want to make a plot using the `ggplot()` function;\n2. `plot.one <-` tell R you want to give the plot a name; the name appears in the environment;\n3. `ggplot(data = study.two.gen ...)` tell R you want to make a plot with the `study.two` data;\n4. `ggplot(..., aes(x = mean.acc))` tell R that you want to make a plot with the variable `mean.acc`;\n\n- here, specify the aesthetic mapping, `x = mean.acc`\n\n5. `geom_histogram()` tell R you want to plot values of `mean.acc` as a histogram;\n6. `binwidth = .1` adjust the binwidth to show enough detail but not too much in the distribution;\n7. `theme_bw()` tell R what theme you want, adjusting the plot appearance;\n8. `labs(x = \"Mean accuracy (mean.acc)\", y = \"frequency count\", title = \"Study Two\")` fix the x-axis and y-axis labels;\n\n- here, add a title for the plot, so you can tell the two plots apart;\n\n9. `xlim(0, 1)` adjust the x-axis limits to show the full range of possible score values on this variable.\n\nDo this process twice, once for each dataset, creating two plots so that you can compare the distribution of `mean.acc` scores between the studies.\n\nFinally, having created the two plots, produce them for viewing:\n  \n10. `plot.two + plot.122` having constructed -- and named -- both plots, you enter their names, separated by a +, to show them in a grid of two plots.\n\nNotice: until you get to step 10, **nothing will appear**. This will be **surprising** but it is perfectly normal when we increase the *level of complexity* of the plots we build.\n\n- You first build the plots. \n- You are creating plot objects and you give these objects names.\n- The objects will appear in the `Environment` with the names you give them.\n- You then *produce* the plots for viewing, by using their names.\n\nUntil you complete the last step, you will not see any changes until you use the object names to produce them for viewing.\n\nThis is how you construct complex arrays of plots. \n\n\n### Task 7 -- Try this out for yourself, focusing now on the distribution of `SHIPLEY` scores in the two studies\n\nFirst, create plot objects but do not show them.\n\n- Give each plot a name. You will use the names next.\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-8_c68a03f4b9c3f69a959f63ef915d8d36'}\n\n```{.r .cell-code}\nplot.two <- ggplot(data = study.two.gen, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\", title = \"Study Two\") +\n  xlim(0, 40)\n\nplot.122 <- ggplot(data = study.122, aes(x = SHIPLEY)) + \n  geom_histogram(binwidth = 2) +\n  theme_bw() +\n  labs(x = \"Vocabulary (SHIPLEY)\", y = \"frequency count\", title = \"PSYC122\") +\n  xlim(0, 40)\n```\n:::\n\n\nSecond produce the plots for viewing, side-by-side, by *naming* them.\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-9_54f3d6ed158eb39a0d3af5addd5d7cde'}\n\n```{.r .cell-code}\nplot.two + plot.122\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\nRemoved 2 rows containing missing values (`geom_bar()`).\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n- Q.3. Now use the plots to do some data analysis work: how do the `SHIPLEY` distributions compare, when you compare the `SHIPLEY` of `study.two.gen` versus `SHIPLEY` of `study.122`?\n- A.3. When you compare the plots side-by-side you can see that the `SHIPLEY` distributions are *mostly* similar: most people have high `SHIPLEY` scores.\n\nBut you can also see striking differences: \n\n- The peak of the distribution -- where the tallest bar is -- is at a higher `SHIPLEY` score in `study.two.gen` (around `SHIPLEY` = 37-38) than in `study.122` (where is it around `SHIPLEY` = 30).\n- There appear to be *fewer* participants with lower `SHIPLEY` scores in `study.122` than in `study.two`.\n\n- Q.4. Is the visual impression you get from comparing the distributions consistent with the statistics you see in the summary?\n- A.4. Yes: If you go back to the summary of `SHIPLEY`, comparing the two studies datasets, then you can see that the median and mean are higher in `study.122` than in `study.two.gen`.\n\n\n## Step 4: Now use scatterplots and correlation to examine associations between variables\n\n\n### Revise: practice to strengthen skills\n\n\n### Task 8 -- Draw scatterplots to compare the potential association between `mean.acc` and `mean.self` in both `study.two.gen` and `study.122` datasets\n\n### hint: Task 8 -- The plotting steps are explained in some detail in `2023-24-PSYC122-w17-how-to.Rmd` and you can see example code in `2023-24-PSYC122-w19-how-to.Rmd`\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-10_8dba02469b86971264ccd9b05be99d37'}\n\n```{.r .cell-code}\nggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = study.122, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n:::\n\n\n### Task 9 --  Create a grid of plots to make the comparison easier to do\n\n### hint: Task 9 -- We follow the same steps as we used in tasks 6 and 7 to create the plots\n\nWe again:\n\n1. First construct the plot objects and give them names;\n2. create and show a grid of named plots.\n\nThough this time we are producing a grid of **scatterplots**.\n\nFirst, create plot objects, give them names, but do not show them:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-11_d4e54d85489e94d402471c8b8e62e400'}\n\n```{.r .cell-code}\nplot.two <- ggplot(data = study.two.gen, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n\nplot.122 <- ggplot(data = study.122, aes(x = mean.self, y = mean.acc)) +\n  geom_point(alpha = 0.75, size = 3, colour = \"darkgrey\") +\n  geom_smooth(method = \"lm\", size = 1.5, colour = \"green\") +\n  theme_bw() +\n  labs(x = \"mean self-rated accuracy\", y = \"mean accuracy\") +\n  xlim(0, 10) + ylim(0, 1)\n```\n:::\n\n\nSecond name the plots, to show them side-by-side in the plot window:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-12_99df624a651d4e3f6af0bfb299a296be'}\n\n```{.r .cell-code}\nplot.two + plot.122\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nNow use the plots to make comparison judgments.\n\n- Q.5. How does the association, shown in the plots, between `mean.self` and `mean.acc` compare when you look at the `study.two.gen` versus the `study.122` plot?\n- hint: Q.5. When comparing evidence about associations in different studies, we are mostly going to focus on the slope -- the angle -- of the prediction lines, and the ways in which points do or do not cluster about the prediction lines.\n- A.5. If you examine the `study.two.gen` versus the `study.122` plots then you can see that in both plots higher `mean.self` scores appear to be associated with higher `mean.acc` scores. But the trend maybe is a bit stronger -- the line is steeper -- in `study.two.gen`.\n\nWe are now in a position to answer one of our research questions:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\nIf people *can* accurately evaluate whether they correctly understand written health information then `mean.self` (a score representing their evaluation) *should* be associated with `mean.acc` (a score representing their accuracy of understanding) for each person.\n\n\n### Revise: practice to strengthen skills\n\n\n### Task 10 --  Can you estimate the association between `mean.acc` and `mean.self` in both datasets?\n\n### hint: Task 10 -- We use `cor.test()` as you have been shown how to do e.g. in `2023-24-PSYC122-w16-how-to.Rmd`\n\nDo the correlation for both datasets.\n\nFirst, look at the correlation between `mean.acc` and `mean.self` in `study.two`:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-13_fcea3055a03914002615ae78f50c9b21'}\n\n```{.r .cell-code}\ncor.test(study.two.gen$mean.acc, study.two.gen$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  study.two.gen$mean.acc and study.two.gen$mean.self\nt = 8.4991, df = 170, p-value = 9.356e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4317217 0.6431596\nsample estimates:\n      cor \n0.5460792 \n```\n:::\n:::\n\n\n- Q.6. What is r, the correlation coefficient?\n- A.6. r = 0.5460792\n\n- Q.7. Is the correlation significant?\n- A.7. r is significant\n\n- Q.8. What are the values for t and p for the significance test for the correlation?\n- A.8. t = 8.4991, p = 9.356e-15\n\nSecond, look at the correlation between `mean.acc` and `mean.self` in `study.122`:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-14_9c53ce4075703af76809b551cd48c452'}\n\n```{.r .cell-code}\ncor.test(study.122$mean.acc, study.122$mean.self, method = \"pearson\",  alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  study.122$mean.acc and study.122$mean.self\nt = 3.4924, df = 63, p-value = 0.0008808\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1761474 0.5888052\nsample estimates:\n      cor \n0.4027438 \n```\n:::\n:::\n\n\n- Q.9. What is r, the correlation coefficient?\n- A.9. r = 0.4027438 \n\n- Q.10. Is the correlation significant?\n- A.10. r is significant\n\n- Q.11. What are the values for t and p for the significance test for the correlation?\n- A.11. t = 3.4924, p = 0.0008808\n\n\nNow we can answer the research question:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\n\n- Q.12. What do the correlation estimates tell you is the answer to the research question?\n- A.12. \n\n> The correlations are positive and significant, indicating that higher `mean.self` (evaluations) are associated with higher `mean.acc` (understanding), suggesting that people *can* judge their accuracy of understanding.\n\n- Q.13.  Can you compare the estimates, given the two datasets, to evaluate if the result in `study.two.gen` is *replicated* in `study.122`?\n- hint: Q.13. We can judge if the result in a study is replicated in another study by examining if -- here -- the correlation coefficient is significant in both studies *and* if the coefficient has the same size and sign in both studies.\n- A.13. If you compare the correlation estimates from both `study.two.gen` and `study.122` you can see:\n\n- first, the correlation is significant in both `study.two.gen` and `study.122`;\n- second, the correlation is positive in both studies.\n\nBut, if you compare the correlation estimates, you can see that the coefficient estimate is smaller in `study.122` (where r = .40) than in `study.two.gen` (where r = .55).\n\nThis may suggest that the association observed in `study.two.gen` is different from the association in `study.122`, for some reason.\n\n\n### Task 11 -- In working with R to do data analysis, we often work with libraries of function like `{tidyverse}` that enable us to do things (see the week 19 lecture for discussion).\n\nIn this way, we are using the `{patchwork}` library so that we can create plots and then present them in a grid.\n\nCan you find the online information about `{patchwork}` and use it to adjust the layout of the grids of plots you are using?\n\n### hint: Task 11 -- To find out more information about a function or a library in R, do a search for the keywords\n\nYou can do a search, using any search engine (e.g., Bing, Chrome, Google), by entering: \n\n> in r ...\n\nAnd pasting the words you want to know about to replace the `...` e.g. \"in r patchwork\".\n\nYou will then see a list of results including the link to the `{patchwork}` information:\n\n<https://patchwork.data-imaginist.com>\n\n\n## Step 5: Use a linear model to to answer the research questions -- multiple predictors\n\n\n### Revise: practice to strengthen skills\n\n\n### Task 12 -- Examine the relation between outcome mean accuracy (`mean.acc`) and multiple predictors \n\nWe specify linear models including as predictors the variables:\n\n- health literacy (`HLVA`); \n- vocabulary (`SHIPLEY`); \n- reading strategy (`FACTOR3`).\n\n### hint: Task 12 -- We use `lm()`, as we have been doing before, see e.g. `2023-24-PSYC122-w18-how-to.R`\n\n\n### Task 12 -- Examine the predictors of mean accuracy (`mean.acc`), first, for the `study.two.gen` data\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-15_823e5a7f72f5836b1cd74338577a18dc'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,\tAdjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nUsing the model estimates, we can answer the research question:\n\n1. What person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:  \n\n- Q.14. What is the estimate for the coefficient of the effect of the predictor `SHIPLEY` in *this* model?\n- A.14. 0.008397 \n\n- Q.15. Is the effect significant?\n- A.15. It is significant, p < .05\n\n- Q.16. What are the values for t and p for the significance test for the coefficient?\n- A.16. t = 4.533, p = 1.1e-05\n\n- Q.17. Now consider the estimates for all the variables, what do you conclude is the answer to the research question -- given the `study.two.gen` data:\n\n1. What person attributes predict success in understanding?\n\n- hint: Q.17. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\n\n- A.17. \n\n> We fitted a linear model with mean comprehension accuracy as the outcome and health literacy (`HLVA`),  reading strategy (`FACTOR3`), and vocabulary (`SHIPLEY`) as predictors. The model is significant overall, with F(3, 168) = 31.99, p< .001, and explains 35% of variance (adjusted R2 = 0.35). Mean accuracy was predicted to be higher given higher scores in health literacy (`HLVA` estimate = .018, t = 4.90, p < .001), vocabulary knowledge (`SHIPLEY` estimate = .008, t = 4.53, p < .001), and reading strategy (`FACTOR3` estimate = .003, t = 2.68, p = .008).\n\n\n### Task 13 -- Examine the predictors of mean accuracy (`mean.acc`), now, for the `study.122` data\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-16_8ffe641ceac87dc0680f394af2a59532'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37214 -0.07143 -0.01102  0.07411  0.25329 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.3066150  0.1447265   2.119   0.0382 *  \nHLVA        0.0335342  0.0071332   4.701 1.52e-05 ***\nSHIPLEY     0.0062524  0.0034741   1.800   0.0768 .  \nFACTOR3     0.0006217  0.0024450   0.254   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1162 on 61 degrees of freedom\nMultiple R-squared:  0.4158,\tAdjusted R-squared:  0.3871 \nF-statistic: 14.47 on 3 and 61 DF,  p-value: 3.156e-07\n```\n:::\n:::\n\n\nUsing the model estimates, we can answer the research question:\n\n1. What person attributes predict success in understanding?\n\nInspect the model summary, then answer the following questions:  \n\n- Q.18. What is the estimate for the coefficient of the effect of the predictor, `HLVA`, in *this* model?\n- A.18. 0.0335342 \n\n- Q.19. Is the effect significant?\n- A.19. It is significant, p > .05 because p = 1.52e-05\n\n- Q.20. What are the values for t and p for the significance test for the coefficient?\n- A.20. t = 4.701, p < .001\n\n- Q.21. Now consider the estimates for all the variables, what do you conclude is the answer to the research question -- given the `study.122` data:\n\n1. What person attributes predict success in understanding?\n\n- hint: Q.21. Can you report the model and the model fit statistics using the language you have been shown in the week 18 lecture?\n\n- A.21. \n\n> We fitted a linear model with mean comprehension accuracy as the outcome and health literacy (`HLVA`),  reading strategy (`FACTOR3`), and vocabulary (`SHIPLEY)` as predictors. The model is significant overall, with F(3, 61) = 14.47, p < .001, and explains 39% of variance (adjusted R2 = .387). Mean accuracy was predicted to be higher given higher scores in health literacy (`HLVA` estimate = .034, t = 4.70, p < .001). There were non-significant effects of individual differences in vocabulary knowledge (`SHIPLEY` estimate = .006, t = 1.80, p = .077) and reading strategy (`FACTOR3` estimate = .001, t = .25, p = .800). \n\n- At this point, we can evaluate the evidence from the PSYC122 sample -- based on your responses -- to assess if the patterns, the estimates, we saw previously are repeated in analyses of PSYC122 responses.\n\n- Q.22. Are the findings from `study.two.gen` replicated in `study.122`?\n- hint: Q.22. We can judge if the results in an earlier study are replicated in another study by examining if -- here -- the linear model estimates are significant in both studies *and* if the coefficient estimates have the same size and sign in both studies.\n- A.22. If you compare the linear model coefficient estimates from both the `study.two.gen` and `study.122` models, you can see:\n\n- first, that the `HLVA` effect estimate is significant in both `study.two.gen` and `study.122`;\n- second, that the estimates of the `HLVA` effect have the same sign -- positive -- in both studies while the estimated coefficient is a bit bigger in the `study.122` data (implying a stronger effect);\n- but, third that the estimates of the effects of variation in vocabulary knowledge (`SHIPLEY`) and reading strategy (`FACTOR3`) are significant in `study.two.gen` but not in `study.122`.  \n  \nThis suggests that the attributes -- the set of abilities -- that predict comprehension accuracy are similar but not the same in the `study.two.gen` participants compared to `study.122` participants.\n\n- Q.23. How would you describe the outstanding difference between the results of the two studies?\n- hint: Q.23. We can look at the estimates but we can also use the model prediction plotting code you used before, see:\n\n- `2022-23-PSYC122-w18-how-to.R`\n- `2022-23-PSYC122-w19-how-to.R`\n\n- hint: Q.23. Let's focus on comparing the `study.two.gen` and `study.122` estimates for the effect of `HLVA` in both models: we can plot model predictions, for comparison:\n\nFirst: fit the models -- using different names for the different models:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-17_4463dc7378455c5552aaeaeccbfbd757'}\n\n```{.r .cell-code}\nmodel.two <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\nsummary(model.two)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.242746 -0.074188  0.003173  0.075361  0.211357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.146896   0.076325   1.925  0.05597 .  \nHLVA        0.017598   0.003589   4.904  2.2e-06 ***\nSHIPLEY     0.008397   0.001853   4.533  1.1e-05 ***\nFACTOR3     0.003087   0.001154   2.675  0.00822 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.097 on 168 degrees of freedom\nMultiple R-squared:  0.3636,\tAdjusted R-squared:  0.3522 \nF-statistic: 31.99 on 3 and 168 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nmodel.122 <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\nsummary(model.122)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.122)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.37214 -0.07143 -0.01102  0.07411  0.25329 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.3066150  0.1447265   2.119   0.0382 *  \nHLVA        0.0335342  0.0071332   4.701 1.52e-05 ***\nSHIPLEY     0.0062524  0.0034741   1.800   0.0768 .  \nFACTOR3     0.0006217  0.0024450   0.254   0.8001    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1162 on 61 degrees of freedom\nMultiple R-squared:  0.4158,\tAdjusted R-squared:  0.3871 \nF-statistic: 14.47 on 3 and 61 DF,  p-value: 3.156e-07\n```\n:::\n:::\n\n\nSecond, create prediction plots for the `HLVA` effect for each model:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-18_f67c7df72b608d8000e195486855abbc'}\n\n```{.r .cell-code}\ndat.two <- ggpredict(model.two, \"HLVA\")\nplot.two <- plot(dat.two) + labs(title = \"Study Two\")\ndat.122 <- ggpredict(model.122, \"HLVA\")\nplot.122 <- plot(dat.122) + labs(title = \"Study PSYC122\")\n```\n:::\n\n\nThird, show the plots side-by-side:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-19_54e2d980d0981bdb01e9fe9954c3c38b'}\n\n```{.r .cell-code}\nplot.two + plot.122\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n- A.23. If we compare the estimates for the coefficient of the `HLVA` effect in the `study.two.gen` and `study.122` models we can see that:\n\n1. The health literacy `HLVA` effect is significant in both `study.two.gen` and `study.122`.\n2. The effect trends positive in both studies.\n3. The coefficient estimate is bigger in `study.122` than in `study.two.gen`.\n4. The prediction plots suggest the prediction line slope is steeper in `study.122`.\n5. The grey shaded area around the trend line (indicating our uncertainty about the estimated trend) is wider for `study.two.gen` than for `study.122`, suggesting we are more uncertain about the association for the `study.two.gen` data. \n\n- The breadth of the grey shaded area around the trend line is hard to compare between the two plots. You have to look carefully at the y-axis scale information to make a judgment about the relative width of these uncertainty ellipses.\n\nThe visualizations plus the model summaries suggests that the estimates of the effect of health literacy are different in the `study.122` compared to the `study.two.gen` data. Why is that?\n\n- We can redraw the prediction plots to add in more information about our samples. This change, see following, will help us to interpret the results of the analyses we have done.\n- And *that* will help you to see why data visualization and data analysis work well together.\n\n### Task 14 -- In producing prediction plots, we are using functions from the `{ggefects}` library. Can you locate online information about working with the library functions?\n\nTry doing a search with the key words: `in r ggeffects`.\n\nIf you do that, you will see links to the website:\n\n<https://strengejacke.github.io/ggeffects/>\n\n\n### Task 15 -- In the `{ggeffects}` online information, you can see links to practical examples. Can you use the information under \"Practical examples\" to adjust the appearance of the prediction plots: to make them black and white; to add points?\n\nFirst create the plots:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-20_67d8611fa558e95396e669058871d2a9'}\n\n```{.r .cell-code}\ndat.two <- ggpredict(model.two, \"HLVA\")\nplot.two <- plot(dat.two, colors = \"bw\", add.data = TRUE) + labs(title = \"Study Two\")\n\ndat.122 <- ggpredict(model.122, \"HLVA\")\nplot.122 <- plot(dat.122, colors = \"bw\", add.data = TRUE) + labs(title = \"Study PSYC122\")\n```\n:::\n\n\nThen show the plots:\n\n\n::: {.cell hash='2023-24-PSYC122-w19-workbook-answers_cache/html/unnamed-chunk-21_00b3c0e5b0de76b4d71ef44a08000cad'}\n\n```{.r .cell-code}\nplot.two + plot.122\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w19-workbook-answers_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n- Q.24. Given the information in the adjusted plots, can you explain what is different about the `HLVA` effect estimate in the `study.122` data compared to the ?\n- A.24. Adding points allow us to see:\n\n1. There are far fewer observations in the `study.122` dataset than in the `study.two.gen` data: this means that our estimate of the effect will be *more uncertain* because we have *less information* when we look at the `study.122` data.\n2. But it is also clear that the effect of `HLVA` appears to be stronger in the  `study.122` data because observed scores are *closer* to model predictions: the `HLVA` effect *explains more variation* in the `study.122` data than in the `study.two.gen` data.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}