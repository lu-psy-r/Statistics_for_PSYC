{
  "hash": "a7145d5bcbe77fba8c415a6d0f87d9a1",
  "result": {
    "markdown": "---\ntitle: \"2023-24-PSYC122-w18-how-to\"\nauthor: Rob Davies\ndate: \"2024-03-04\"\noutput: word_document\n---\n\n\n\n\n\n# Introduction\n\n\nIn Week 18, we aim to *further develop* skills in working with the linear model.\n\nWe do this to learn how to answer research questions like:\n\n1. What person attributes predict success in understanding?\n2. Can people accurately evaluate whether they correctly understand written \nhealth information?\n\nThese kinds of research questions can be answered using methods like the **linear model**.\n\nWhen we do these analyses, we need to think about how we report the results:\n\n- we usually need to report information about the kind of model we specify;\n- and we will need to report the nature of the association estimated in our model.\n\nWe usually need to decide:\n\n- is the association significant?\n- does the association reflect a positive or negative relationship between outcome \nand predictor?\n- and is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\n- focusing on how we edit ggplot() code to produce professional looking plots.\n\n## Naming things\n\nI will format dataset names like this: \n\n- `study-one-general-participants.csv`\n\nI will also format variable (data column) names like this: `variable` \n\nI will also format value or other data object (e.g. cell value) names like this: `studyone`\n\nI will format functions and library names like this: e.g. function `ggplot()` or e.g. library `{tidyverse}`.\n\n## The data we will be using\n\nIn this how-to guide, we use data from a 2020 study of the response of adults from a UK national sample to written health information:\n\n- `study-one-general-participants.csv`\n\n\n# Answers\n\n\n## Step 1: Set-up\n\n\nTo begin, we set up our environment in R.\n\n\n### Task 1 -- Run code to empty the R environment\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-1_7c4d91932c4350ecbe6f697759ecc0eb'}\n\n```{.r .cell-code}\nrm(list=ls())                            \n```\n:::\n\n\n\n### Task 2 -- Run code to load relevant libraries\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-2_4240b67b996471aa30ac87f7c4b1256a'}\n\n```{.r .cell-code}\nlibrary(\"ggeffects\")\nlibrary(\"tidyverse\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\n\n## Step 2: Load the data\n\n\n### Task 3 -- Read in the data file we will be using\n\nThe data file is called:\n\n- `study-one-general-participants.csv`\n\nUse the `read_csv()` function to read the data file into R:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-3_3b22a28e8452cf3a4312d71a71d6aa4a'}\n\n```{.r .cell-code}\nstudy.one.gen <- read_csv(\"study-one-general-participants.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 169 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nWhen you read the data file in, give the data object you create a distinct name \ne.g. `study.one.gen`.\n\n\n### Task 4 -- Inspect the data file\n\nUse the `summary()` or `head()` functions to take a look.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-4_b761773da260d08a3823470310045e35'}\n\n```{.r .cell-code}\nhead(study.one.gen)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  <chr>             <dbl>     <dbl> <chr>   <dbl>   <dbl> <dbl>   <dbl>    <dbl>\n1 studyone.1         0.49      7.96 studyo…    34      33     7      53       11\n2 studyone.10        0.85      7.28 studyo…    25      33     7      60       11\n3 studyone.100       0.82      7.36 studyo…    43      40     8      46       12\n4 studyone.101       0.94      7.88 studyo…    46      33    11      51       15\n5 studyone.102       0.58      6.96 studyo…    18      32     3      51       12\n6 studyone.103       0.84      7.88 studyo…    19      37    13      45       19\n# ℹ 3 more variables: GENDER <chr>, EDUCATION <chr>, ETHNICITY <chr>\n```\n:::\n\n```{.r .cell-code}\nsummary(study.one.gen)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n```\n:::\n:::\n\n\nEven though you have done this before, you will want to do it \nagain, here, and pay particular attention to:\n\n- summary information about the numeric variables;\n- summary information about variables of class: `character`.\n\n\n## Step 3: Use a linear model to to answer the research questions -- one predictor\n\n\n### Revise: Practice to strengthen skills\n\n\nWe start by revising how to use lm() with one predictor.\n\nOne of our research questions is:\n\n1. What person attributes predict success in understanding?\n\n\n### Task 5 -- Examine the relation between outcome mean accuracy (`mean.acc`) and health literacy (`HLVA`)\n\n### Hint: Task 5\n\nWe can use `lm()` to estimate whether variation in health literacy (`HLVA`) predicts outcome mean accuracy (`mean.acc`) of understanding.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-5_25668f4e8ad884d2eaa0810862fe9639'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA, data = study.one.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40848 -0.05304  0.01880  0.07608  0.19968 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.61399    0.03387  18.128  < 2e-16 ***\nHLVA         0.02272    0.00369   6.158 5.31e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1068 on 167 degrees of freedom\nMultiple R-squared:  0.1851,\tAdjusted R-squared:  0.1802 \nF-statistic: 37.92 on 1 and 167 DF,  p-value: 5.307e-09\n```\n:::\n:::\n\n\nIn R analysis code, we write `method(outcome ~ predictor)` so:\n\n```{}\nlm(mean.acc ~ HLVA, data = study.one.gen)\n```\n\n- gets us an analysis of whether or how `HLVA` predicts variation in\noutcome `mean.acc`.\n\nIf you look at the model `summary` you can answer the following questions.\n\n#### Questions: Task 5\n\n- Q.1. What is the estimate for the coefficient of the effect of the predictor, `HLVA`?\n\n- A.1. 0.02272 \n\n- Q.2. Is the effect significant?\n\n- A.2. It is significant, p < .05\n\n- Q.3. What are the values for t and p for the significance test for the coefficient?\n\n- A.3. t = 6.158, p = 5.31e-09\n\n- Q.4. What do you conclude is the answer to the research question, given the  linear model results?\n\n- A.4. The model slope estimate suggests that as HLVA scores increase so also do `mean.acc` scores\n\n- Q.5. What is the F-statistic for the regression? Report F, DF and the p-value.\n\n- A.5. F-statistic: 37.92 on 1 and 167 DF,  p-value: 5.307e-09\n\n- Q.6. Is the regression significant?\n\n- A.6. Yes: the regression is significant.\n\n- Q.7. What is the Adjusted R-squared?\n\n- A.7. Adjusted R-squared:  0.1802\n\n- Q.8. Explain in words what this R-squared value indicates?\n\n- A.8. The R-squared suggests that 18% of outcome variance can be explained by the model\n\n\n## Step 4: Use a linear model to to answer the research questions -- multiple predictors\n\n\n### Introduce: make some new moves\n\n\n### Task 6 -- Examine the relation between outcome mean accuracy (`mean.acc`) and *multiple* predictors\n\nHere, the predictors will include:\n\n- health literacy (`HLVA`); \n- vocabulary (`SHIPLEY`); \n- reading strategy (`FACTOR3`).\n\n#### Hint: Task 6\n\nWe use `lm()`, as before, but now specify each variable listed here by variable name\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-6_68190519c0933a0bd2f2218d3c4ef588'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40322 -0.05349  0.01152  0.07128  0.18434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.302030   0.091257   3.310  0.00115 ** \nHLVA        0.017732   0.003923   4.521 1.17e-05 ***\nSHIPLEY     0.005363   0.002336   2.296  0.02291 *  \nFACTOR3     0.003355   0.001264   2.654  0.00872 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1033 on 165 degrees of freedom\nMultiple R-squared:  0.2474,\tAdjusted R-squared:  0.2337 \nF-statistic: 18.08 on 3 and 165 DF,  p-value: 3.423e-10\n```\n:::\n:::\n\n\nNotice that we do the linear model in the steps:\n\n1. `model <- lm(...)` fit the model using `lm(...)`, giving the model a name; \nhere, we call it `model`;\n2. ` ...lm(mean.acc ~ HLVA...) ` tell R you want a model of the outcome `mean.acc` \npredicted (`~`) by the predictors listed, `HLVA`, `SHIPLEY`, and `FACTOR3`.\n3. `...data = study.one.gen)` tell R that the variables you name in the formula are in the `study.one.gen` dataset.\n4. `summary(model)` ask R for a summary of the model you called `model`.\n\nNotice: that we use the variable names as they appear in the dataset, and that \neach predictor variable is separated from the next by a plus (`+`) sign.\n\nNotice: R has a general formula syntax: `outcome ~ predictor` *or* `y ~ x`\nand uses the same format across a number of different analysis functions.\n\n- Each time, the left of the tilde symbol `~` is some output or outcome\nand the right of the tilde `~` is some input or predictor or set of predictors.\n\n#### Questions: Task 6\n\nIf you look at the model summary you can answer the following questions  \n\nQ.9. What is the estimate for the coefficient of the effect of the predictor `HLVA` in *this* model?\n\nA.9. 0.017732 \n\nQ.10. Is the effect significant?\n\nA.10. It is significant, p < .05\n\nQ.11. What are the values for t and p for the significance test for the coefficient?\n\nA.11. t = 4.521, p = 1.17e-05\n\nQ.12. What do you conclude is the answer to the research question, given the linear model results?\n\nA.12. The model slope estimate 0.017732 suggests that as `HLVA` scores \nincrease so also do `mean.acc` scores.\n\nQ.13. How is the coefficient estimate for the `HLVA` slope similar or different,  comparing this model with multiple predictors to the previous model with one predictor?\n\nA.13. It can be seen that the `HLVA` estimate in the two models is different in that it is a bit smaller in the model with multiple predictors compared to the model with one predictor. The `HLVA` estimate is similar in that it remains positive, it is about the same size.\n\nNotice that:-\n\n- The estimate of the coefficient of any one predictor can be expected to vary depending on the presence of other predictors.\n- This is one reason why we need to be transparent about why we choose to use the predictors we include in our model.\n\nQ.14. Can you report the estimated effect of `SHIPLEY` (the measure of vocabulary) using the kind of language you are shown in lecture week 18?\n\nA.14. The answer to the question can be written like this:\n\n> The effect of vocabulary knowledge (`SHIPLEY`) on mean accuracy of understanding is significant (estimate = 0.005, t = 2.296, p < .001) indicating that increasing vocabulary knowledge is associated with increasing accuracy of understanding.\n\nQ.15. Can you report the model and the model fit statistics?\n\nA.15. The answer to the question can be written like this:\n\n> We fitted a linear model with mean comprehension accuracy as the outcome and health literacy (`HLVA`), reading strategy (`FACTOR3`), and vocabulary (`SHIPLEY`) as predictors. The model is significant overall, with F(3, 165) = 18.08, p< .001, and explains 23% of variance (adjusted R2 = 0.23).\n\n\n## Step 5: Plot predictions from linear models with multiple predictors\n\n\n### Introduce: make some new moves\n\n\n### Task 7 -- Plot linear model predictions for one of the predictors\n\n#### Hint: Task 7\n\nPreviously, we used `geom_abline()`, specifying intercept and slope estimates, to draw model predictions.\n\nHere, we use functions that are very helpful when we need to plot model predictions, for models where we have multiple predictors\n\nWe do this in four steps:\n\n1. We first fit a linear model of the outcome, given our predictors.\n2. We save information about the model.\n3. We use the `ggpredict()` function from the `{ggeffects}` library to take  the information about the model and create a set of predictions we can use for plotting.\n4. We plot the model prediction plots.\n\nThese steps proceed as follows:\n\n1. We first fit a linear model of the outcome, given our predictors.\n\nLike this:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-7_9be2f3db1bc9f0f042abf641d65032fb'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3, data = study.one.gen)\n```\n:::\n\n\nThe code involves these key bits:\n\n- `model <- lm(...)` we fit the model using `lm(...)`, giving the model a name; \nhere, we call it `model`.\n- `...lm(mean.acc ~ HLVA...)` we tell R we want a model of the outcome `mean.acc` predicted (`~`) by the predictors `HLVA`, `SHIPLEY`, and `FACTOR3`.\n\nNotice: when we use lm() to fit the model, R creates a set of information about the model, including estimates.\n\nWe give that set of information a name `model`, and we use that name, next, to  access that information in the plotting step.\n\n2. We use the `ggpredict()` function from the `{ggeffects}` library to take the information about the model and create a set of predictions we can use for plotting.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-8_b5522d9bc358d1be2fa0f014e55cec94'}\n\n```{.r .cell-code}\ndat <- ggpredict(model, \"HLVA\")\n```\n:::\n\n\nNotice:\n\n- `dat <- ggpredict(...)` asks R to create a set of predictions, and we give that set of predictions a name `dat`.\n- `... ggpredict(model, \"HLVA\")` tells R what model information it should use (from `model`) *and* which predictor variable we need predictions for `\"HLVA\"`.\n\n3. We plot the model predictions with:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-9_42a492cf64e1a341e6a613a9fe464092'}\n\n```{.r .cell-code}\nplot(dat)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-how-to_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n### Task 8 -- Now produce plots that show the predictions for all the predictor variables in the model\n\n\n## Step 6: Now draw boxplots to examine associations between variables\n\n\n### Consolidation: practice to strengthen skills\n\n\n### Task 9 -- Create boxplots to examine the association between a continuous numeric outcome variable like `mean.acc` and a categorical variable like `ETHNICITY`\n\nHere, we use `geom_boxplot()`.\n\n#### Hint: Task 9 -- We can see where variables are not numeric using `summary()`\n\nThe boxplot can be produced using code like this:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-10_65b6171e92fe8249aa0ac4ce09789920'}\n\n```{.r .cell-code}\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) +\n  geom_boxplot() +\n  theme_bw() +\n  labs(x = \"Ethnicity, ONS categories\", \n       y = \"Mean accuracy of understanding ('mean.acc')\") +\n  ylim(0, 1.1)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-how-to_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe plotting code works bit-by-bit, as described following.\n\n1. `ggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc))` defines two aesthetic mappings:\n\n- `x = ETHNICITY`, the x variable has to be categorical or nominal, a factor like \n`ETHNICITY` with different levels.\n- `y = mean.acc`, the y variable has to be numeric, a set of numbers like `mean.acc` \n with different values.\n\n2. `geom_boxplot()` then uses that information about category `(x = ...)` and outcome `(y = ...)` to draw a box to represent the distribution of outcome scores for each group.\n\nNotice that when you draw the plot:\n\n- The middle line in each box represents the median outcome (here `mean.acc`) score for each group.\n- The shape of the box represents the distribution or spread of scores.\n- The top of the box represents the 75th percentile, what the score is for the people who are at the top 75% of the sample.\n- The bottom of the box represents the 25th percentile, what the score is for the \npeople at the 25% level of outcomes for the sample.\n\nMore information about boxplots can be found here:\n\n<https://ggplot2.tidyverse.org/reference/geom_boxplot.html>\n\nHere is an edit of the plot to make it a bit more effective:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-11_618e879bb3ce8975dcdaf0b9f856061b'}\n\n```{.r .cell-code}\nggplot(data = study.one.gen, aes(x = ETHNICITY, y = mean.acc)) +\n  geom_jitter(alpha = .5) +\n  geom_boxplot(outlier.shape = NA, colour = \"red\", alpha = .1) +\n  theme_bw() +\n  labs(x = \"Ethnicity, ONS categories\", \n       y = \"Mean accuracy of understanding ('mean.acc')\") +\n  ylim(0, 1.1)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-how-to_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe plot shows:\n\n- boxplots to indicate the average (median) and spread (percentiles) in \n`mean.acc` scores for each group;\n- plus, with points, individual `mean.acc` scores for the people in each group.\n\n#### Why are we learning how to do this?\n\nDrawing plots which show *both* summaries (like boxplots) and raw data (scores as points) is a common (advanced) professional visualization technique.\n\n- It is effective because these kinds of plots help you to see the pattern or trend *and* the nature of the underlying sample.\n\nNow you can use the plots to answer questions like the following\n\n#### Questions: Task 9\n\nQ.16. What do you notice about the distribution of scores in different groups?\n\nA.16. The average accuracy of understanding appears to be similar between groups.\n\nQ.17. Does anything in the plots give you reason to question the nature of the participant sample?\n\nA.17. This is a leading question: there is *plenty* in the plots to cause concern.\n\n- The scatter of points shows that we have many more `White` participants in the \nsample than participants from other ethnicities.\n- Because we have very few people in the study from ethnic minority \n(often classed as BAME) groups, we might be concerned about whether the results from our models are representative of what you would see in these groups, or whether the results are representative of the wider population in general.\n\nQ.18. Can you use the `ggplot()` reference information -- see the webpage link -- to see how and why I made the code edits I did?\n\nA.18. You can see example code for each edit in the webpage.\n\nQ.19. Do you understand what `geom_jitter()` is doing? -- and why I would use it?\n\nA.19. What the function does, and why I would use it can be found in the reference \ninformation webpage:\n\n<https://ggplot2.tidyverse.org/reference/geom_jitter.html>\n\n\n## Step 6: Estimate the effects of factors as well as numeric variables\n\n\n### Introduce: make some new moves\n\n\nWe have not yet included any categorical or nominal variables as predictors but we can, and should:\n\n- `lm()` can cope with any kind of variable as a predictor.\n\n\n### Task 10 -- Fit a linear model including both numeric variables and categorical variables as predictors\n\n#### Hint: Task 12\n\nWe can inspect the data to check what variables are categorical or nominal variables -- factors -- using `summary()`.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-12_11249a84602e1aa69aba5388144f78c1'}\n\n```{.r .cell-code}\nsummary(study.one.gen)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n participant_ID        mean.acc        mean.self        study          \n Length:169         Min.   :0.3600   Min.   :3.440   Length:169        \n Class :character   1st Qu.:0.7600   1st Qu.:6.080   Class :character  \n Mode  :character   Median :0.8400   Median :7.080   Mode  :character  \n                    Mean   :0.8163   Mean   :6.906                     \n                    3rd Qu.:0.9000   3rd Qu.:7.920                     \n                    Max.   :0.9900   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :34.00  \n 1st Qu.:24.00   1st Qu.:33.00   1st Qu.: 7.000   1st Qu.:46.00  \n Median :32.00   Median :35.00   Median : 9.000   Median :51.00  \n Mean   :34.87   Mean   :34.96   Mean   : 8.905   Mean   :50.33  \n 3rd Qu.:42.00   3rd Qu.:38.00   3rd Qu.:10.000   3rd Qu.:55.00  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:169         Length:169         Length:169        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :13.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.36                                                           \n 3rd Qu.:15.00                                                           \n Max.   :19.00                                                           \n```\n:::\n:::\n\n\nNotice that R shows categorical variables in the summary as having:\n`Class: character`.\n\n- Q.20. Can you report the estimated effect of `ETHNICITY`: differences in outcome for people in different self-reported ethnicity groups?\n\n- Hint: Q.20. Include the factor `ETHNICITY` as a predictor:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-13_fc2d486ef21defe6cceeb58c0db9b103'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n            data = study.one.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n    data = study.one.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40261 -0.05322  0.01168  0.07124  0.18391 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     0.302764   0.095806   3.160  0.00188 ** \nHLVA            0.017391   0.003980   4.370 2.22e-05 ***\nSHIPLEY         0.005249   0.002380   2.206  0.02882 *  \nFACTOR3         0.003495   0.001289   2.711  0.00744 ** \nETHNICITYBlack  0.016600   0.065962   0.252  0.80163    \nETHNICITYMixed -0.016080   0.048371  -0.332  0.74000    \nETHNICITYOther  0.083201   0.108382   0.768  0.44381    \nETHNICITYWhite -0.001006   0.028308  -0.036  0.97168    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1043 on 161 degrees of freedom\nMultiple R-squared:  0.2514,\tAdjusted R-squared:  0.2188 \nF-statistic: 7.723 on 7 and 161 DF,  p-value: 4.841e-08\n```\n:::\n:::\n\n\n- A.20. The effect of ethnicity (`ETHNICITY`) on mean accuracy of \nunderstanding is not significant.\n\n- Q.21. Can you report the model and the model fit statistics?\n\n- A.21. You can report the model and model statistics like this.\n\n> We fitted a linear model with mean comprehension accuracy as the outcome and \nhealth literacy (`HLVA`), vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`),\nand ethnicity (`ETHNICITY`) as predictors. The model is significant overall, \nwith F(7, 161) = 7.72, p< .001, and explains 22% of variance (adjusted R2 = 0.22).\n\n- Q.22. What changes, when you compare the models with versus without `ETHNICITY`?\n\n- A.22. If you compare the summaries, for the last two models, you can see that\nthe proportion of variance explained, `R-sq`, decreases slightly to 22% (Adjusted R-squared = 0.2188), suggesting that adding `ETHNICITY` as a predictor does\n*not* help to predict response accuracy in tests of comprehension of health advice.\n\n#### Why are we learning how to do this?\n  \nR handles factors, by default, by picking one level (here, `Asian`) as the reference level (or baseline) and comparing outcomes to that baseline, for each other factor level (here, `Other`).\n\n- Thus, in this model, the effect of `ETHNICITY` is estimated as the difference\nin `mean.acc` outcome for `Asian` compared to participants coded as `Black, Mixed, Other, White` (BAME).\n\nThere are different ways to code factors for analysis.\nYou will learn about these in second year classes.\n\n\n### Task 13 -- Fit a linear model including both numeric variables and categorical variables as predictors, and then plot the predicted effect of the factor (the categorical variable)\n\n#### Hint: Task 12 -- We first fit the model, including `ETHNICITY`, then use the `ggpredict()` function to get the predictions\n\n\n::: {.cell hash='2023-24-PSYC122-w18-how-to_cache/html/unnamed-chunk-14_4cc6c1239b808dd11725e3288c6b9ff4'}\n\n```{.r .cell-code}\nmodel <- lm(mean.acc ~ HLVA + SHIPLEY + FACTOR3 + ETHNICITY, \n            data = study.one.gen)\n\ndat <- ggpredict(model, \"ETHNICITY\")\nplot(dat)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-how-to_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n- Q.23. Compare the model summary and the prediction plot: what do they show you about the effect of `ETHNICITY`?\n\n- A.23. If you compare the summary and the plot you can see that:\n\n- there are some differences in accuracy between people coded as belonging to different ethnic groups;\n- but these differences are very small and are not significant.\n\nNotice that the points in the plot represent model predictions of the average\n`mean.acc` accuracy of response for each group. \n\n- The vertical lines on the point represent uncertainty about those estimates and that uncertainty can be seen to be substantial.\n- Longer lines represent more uncertainty.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}