{
  "hash": "101fd0f98dc49497a83e975f2bdf82a3",
  "result": {
    "markdown": "---\ntitle: \"2023-24-PSYC122-w18-workbook-answers\"\nauthor: Rob Davies\ndate: \"2024-03-04\"\noutput: word_document\n---\n\n\n\n\n\n# Introduction\n\n\nIn Week 18, we aim to *further develop* skills in working with the linear model.\n\nWe do this to learn how to answer research questions like:\n\n1. What person attributes predict success in understanding?\n2. Can people accurately evaluate whether they correctly understand written \nhealth information?\n\nThese kinds of research questions can be answered using methods like the **linear model**.\n\nWhen we do these analyses, we need to think about how we report the results:\n\n- we usually need to report information about the kind of model we specify;\n- and we will need to report the nature of the association estimated in our model.\n\nWe usually need to decide:\n\n- is the association significant?\n- does the association reflect a positive or negative relationship between outcome \nand predictor?\n- and is the association we see in our sample data relatively strong or weak?\n\nWe will consolidate and extend learning on data visualization:\n\n- focusing on how we edit ggplot() code to produce professional looking plots.\n\n## Naming things\n\nI will format dataset names like this: \n\n- `study-two-general-participants.csv`\n\nI will also format variable (data column) names like this: `variable` \n\nI will also format value or other data object (e.g. cell value) names like this: `studyone`\n\nI will format functions and library names like this: e.g. function `ggplot()` or e.g. library `{tidyverse}`.\n\n## The data we will be using\n\nIn this activity, we use data from *a second* 2020 study of the response\nof adults from a UK national sample to written health information:\n\n- `study-two-general-participants.csv`\n\n\n# Answers\n\n\n## Step 1: Set-up\n\n\nTo begin, we set up our environment in R.\n\n\n### Task 1 -- Run code to empty the R environment\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-1_020bea6dd770106942f99cd0ce094471'}\n\n```{.r .cell-code}\nrm(list=ls())                            \n```\n:::\n\n\n\n### Task 2 -- Run code to load relevant libraries\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-2_26aebb078aa483138f3a74e927ffe675'}\n\n```{.r .cell-code}\nlibrary(\"ggeffects\")\nlibrary(\"tidyverse\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.1.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\n\n## Step 2: Load the data\n\n\n### Task 3 -- Read in the data file we will be using\n\nThe data file is called:\n\n- `study-two-general-participants.csv`\n\nUse the `read_csv()` function to read the data file into R:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-3_aaf7283d5240493b1a1e3348cfac7073'}\n\n```{.r .cell-code}\nstudy.two.gen <- read_csv(\"study-two-general-participants.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 172 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): participant_ID, study, GENDER, EDUCATION, ETHNICITY\ndbl (7): mean.acc, mean.self, AGE, SHIPLEY, HLVA, FACTOR3, QRITOTAL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nWhen you read the data file in, give the data object you create a distinct name \ne.g. `study.two.gen`.\n\n\n### Task 4 -- Inspect the data file\n\nUse the `summary()` or `head()` functions to take a look.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-4_50e67f540463cc5d7302ed82bf389dcb'}\n\n```{.r .cell-code}\nhead(study.two.gen)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 12\n  participant_ID mean.acc mean.self study     AGE SHIPLEY  HLVA FACTOR3 QRITOTAL\n  <chr>             <dbl>     <dbl> <chr>   <dbl>   <dbl> <dbl>   <dbl>    <dbl>\n1 studytwo.1        0.411      6.07 studyt…    26      27     6      50        9\n2 studytwo.10       0.607      8.5  studyt…    38      24     9      58       15\n3 studytwo.100      0.875      8.93 studyt…    66      40    13      60       20\n4 studytwo.101      0.964      8.5  studyt…    21      31    11      59       14\n5 studytwo.102      0.714      7.07 studyt…    74      35     7      52       18\n6 studytwo.103      0.768      5.07 studyt…    18      40    11      54       15\n# ℹ 3 more variables: GENDER <chr>, EDUCATION <chr>, ETHNICITY <chr>\n```\n:::\n\n```{.r .cell-code}\nsummary(study.two.gen)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n participant_ID        mean.acc        mean.self        study          \n Length:172         Min.   :0.4107   Min.   :3.786   Length:172        \n Class :character   1st Qu.:0.6786   1st Qu.:6.411   Class :character  \n Mode  :character   Median :0.7679   Median :7.321   Mode  :character  \n                    Mean   :0.7596   Mean   :7.101                     \n                    3rd Qu.:0.8393   3rd Qu.:7.946                     \n                    Max.   :0.9821   Max.   :9.000                     \n      AGE           SHIPLEY           HLVA           FACTOR3     \n Min.   :18.00   Min.   :23.00   Min.   : 3.000   Min.   :29.00  \n 1st Qu.:25.00   1st Qu.:32.75   1st Qu.: 7.750   1st Qu.:47.00  \n Median :32.50   Median :36.00   Median : 9.000   Median :51.00  \n Mean   :35.37   Mean   :35.13   Mean   : 9.064   Mean   :51.24  \n 3rd Qu.:44.00   3rd Qu.:39.00   3rd Qu.:11.000   3rd Qu.:56.25  \n Max.   :76.00   Max.   :40.00   Max.   :14.000   Max.   :63.00  \n    QRITOTAL        GENDER           EDUCATION          ETHNICITY        \n Min.   : 6.00   Length:172         Length:172         Length:172        \n 1st Qu.:12.00   Class :character   Class :character   Class :character  \n Median :14.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :13.88                                                           \n 3rd Qu.:16.00                                                           \n Max.   :20.00                                                           \n```\n:::\n:::\n\n\nEven though you have done this before, you will want to do it \nagain, here, and pay particular attention to:\n\n- summary information about the numeric variables;\n- summary information about variables of class: `character`.\n\n\n## Step 3: Use a linear model to to answer the research questions -- one predictor\n\n\n### Revise: practice to strengthen skills\n\n\n### Revise: We start by revising how to use lm() with one predictor\n\n\nOne of our research questions is:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\nWe can address this question by examining whether someone's rated evaluation\nof their own understanding matches their performance on a test of that\nunderstanding, and by investigating what variables predict variation in \nmean self-rated accuracy.\n\n- Note that ratings of accuracy are ordinal data but that, here, we may choose\nto examine the average of participants' ratings of their own understanding of health\ninformation to keep our analysis fairly simple.\n- For these data, participants were asked to respond to questions about health \ninformation to get `mean.acc` scores and then were asked to rate their own understanding \nof the same information.\n\nIf you *can* evaluate your own understanding then ratings of understanding *should*\nbe associated with performance on tests of understanding\n\n\n### Task 5 -- Estimate the relation between outcome mean self-rated accuracy (`mean.self`) and tested accuracy of understanding (`mean.acc`)\n\n### hint: Task 5\n\nFor these data, participants were asked to respond to questions about health information to get `mean.acc` scores and were asked to rate their own understanding of the same information.\n\n### hint: Task 5\n\nWe can use `lm()` to estimate whether the ratings of accuracy actually predict the outcome tested accuracy levels.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-5_6b5ad2c30f9be4476295987377f95a1a'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ mean.acc, data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,\tAdjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n```\n:::\n:::\n\n\nIn R analysis code, we write `method(outcome ~ predictor)` so:\n\n```{}\nlm(mean.self ~ mean.acc, data = study.two.gen)\n```\n\n- gets us an analysis of whether or how `mean.self` predicts variation in\noutcome `mean.acc`.\n\nIf you look at the model `summary` you can answer the following questions.\n\n#### Questions: Task 5\n\n- Q.1. What is the estimate for the coefficient of the effect of the predictor \n`mean.acc` on the outcome `mean.self` in this model?\n\n- A.1. 5.5670 \n\n- Q.2. Is the effect significant?\n\n- A.2. It is significant, p < .05\n\n- Q.3. What are the values for t and p for the significance test for the coefficient?\n\n- A.3. t = 8.499, p = 9.36e-15\n\n- Q.4. What do you conclude is the answer to the research question, given the \nlinear model results?\n\n- A.4. The model slope estimate suggests that higher levels of tested understanding can predict higher levels of rated understanding so, yes: it does appear\nthat people can evaluate their own understanding.\n\n- Q.5. What is the F-statistic for the regression? Report F, DF and the p-value.\n\n- A.5. F-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n\n- Q.6. Is the regression significant?\n\n- A.6. Yes: the regression is significant.\n\n- Q.7. What is the Adjusted R-squared?\n\n- A.7. Adjusted R-squared:  0.2941\n\n- Q.8. Explain in words what this R-squared value indicates?\n\n- A.8. The R-squared suggests that about 30% of outcome variance can be explained \nby the model\n\n\n## Step 4: Use a linear model to to answer the research questions -- multiple predictors\n\n\n### Introduce: make some new moves\n\n\nOne of our research questions is:\n\n2. Can people accurately evaluate whether they correctly understand written health information?\n\nWe have already looked at this question by asking whether ratings of understanding\npredict performance on tests of understanding.\n\nBut there is a problem with that analysis -- it leaves open the question: \n\n- What *actually* predicts ratings of understanding?\n\nWe can look at this follow-up question, next.\n\n\n### Task 6 -- Examine the relation between outcome mean self-rated accuracy (`mean.self`) and  multiple predictors\n\nHere, the predictors will include:\n\n- health literacy (`HLVA`); \n- vocabulary (`SHIPLEY`); \n- age in years (`AGE`); \n- reading strategy (`FACTOR3`);\n- as well as average accuracy of the tested understanding of health information (`mean.acc`).\n\n#### hint: Task 6 -- We use `lm()`, as before, but now specify each variable listed here by variable name\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-6_753f6eab1934c4c84d8e095850ebdb40'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n            data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc, \n    data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.72027 -0.49118 -0.00177  0.55561  2.00134 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.561110   0.700632   0.801   0.4244    \nHLVA         0.041272   0.034833   1.185   0.2378    \nSHIPLEY     -0.046125   0.018701  -2.466   0.0147 *  \nFACTOR3      0.063689   0.010747   5.926 1.74e-08 ***\nAGE          0.025570   0.005472   4.673 6.12e-06 ***\nmean.acc     4.763278   0.708166   6.726 2.69e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8805 on 166 degrees of freedom\nMultiple R-squared:  0.5014,\tAdjusted R-squared:  0.4864 \nF-statistic: 33.39 on 5 and 166 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n#### Questions: Task 6\n\nIf you look at the model summary you can answer the following questions.\n\n- Q.9. What predictors are significant in this model?\n\n- A.9. Vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`), `AGE`, and performance on tests of accuracy of understanding (`mean.acc`) all appear to significantly predict variation in mean ratings of understanding (`mean.self`).\n\n- Q.10. What is the estimate for the coefficient of the effect of the predictor `mean.acc` in this model?\n\n- A.10. 4.763278 \n\n- Q.11. Is the effect significant?\n\n- A.11. It is significant, p < .05\n\n- Q.12. What are the values for t and p for the significance test for the coefficient?\n\n- A.12. t = 6.726, p = 2.69e-10\n\n- Q.13. What do you conclude is the answer to the follow-up question, what actually predicts ratings of understanding?\n\n- A.13. Ratings of understanding appear to be predicted by performance on tests of accuracy of understanding, together with variation in age, vocabulary knowledge, health literacy and reading strategy\n\n\n## Step 5: Understanding linear model predictions by comparing one outcome-predictor relation\n\n\nNext, we focus in on whether `mean.self` predicts `mean.acc` or, in reverse,\nwhether `mean.acc` predicts `mean.self`?\n\n- Note that a comparison between these models teaches us something important about \n*what* it is that linear models predict.\n  \n- Q.14. Why do you think it appears that the slope coefficient estimate is different if you compare :\n\n1. The model `mean.acc ~ mean.self` versus \n2. The model `mean.self ~ mean.acc`?\n\n- hint: Q.14. You want to fit two simple models here, using the verbal description\nin the Q.14 wording.\n\n**1. The model `mean.acc ~ mean.self`**\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-7_c5b1573a2f093f9ed0b814ced63e6fba'}\n\n```{.r .cell-code}\nmodel.1 <- lm(mean.acc ~ mean.self, data = study.two.gen)\nsummary(model.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ mean.self, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.293692 -0.069200  0.005422  0.080041  0.215240 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.379182   0.045415   8.349 2.31e-14 ***\nmean.self   0.053566   0.006303   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1013 on 170 degrees of freedom\nMultiple R-squared:  0.2982,\tAdjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n```\n:::\n:::\n\n\n**2. The model `mean.self ~ mean.acc`**\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-8_6f38d809e1942983208b70f90310fc05'}\n\n```{.r .cell-code}\nmodel.2 <- lm(mean.self ~ mean.acc, \n              data = study.two.gen)\nsummary(model.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,\tAdjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n```\n:::\n:::\n\n\n- hint: Q.14. You may benefit here by reflecting on the `lm-intro` lecture and\npractical materials, especially where they concern predictions.\n\n- A.14. Linear models are prediction models. We use them to predict variation in outcomes given some set of predictor variables. Predictions will necessarily be *scaled* in the same way as the outcome variable. \n\nSo, to expand on that explanation a bit more, to help understanding -- the answer is:\n \n1. If we have the model, `mean.acc ~ mean.self` then this means that the outcome is `mean.acc`.\n\n- So if we are predicting change in outcome `mean.acc`, which is **scaled 0-1**, then we are looking at coefficients that will lie somewhere on the same scale (also 0-1).\n- Here: the model estimate suggests that each unit change in values of the variable `mean.self` predicts an increase of 0.053566 in `mean.acc`.\n\n2. Whereas if we have the model, `mean.self ~ mean.acc` then this means that the outcome is `mean.self`.\n\n- So if we are predicting change in outcome `mean.self`, which is **scaled 1-9** , then we are looking at coefficients that will lie somewhere on the same scale (also 1-9).\n- Here: the model estimate suggests that unit change in `mean.acc` predicts increase of 5.5670 in `mean.self`.\n\nNote that:\n\n- Where we reference model estimates, here, we are looking at the values in the\n`Estimate` column of the `lm()` model summary.\n- These estimates give us the expected or predicted change in the outcome, given\nchange in the predictor variable named on that row.\n\nRemember that:\n\n- `mean.acc` is scaled from 0 to 1 because it represents the average accuracy of\nthe responses made by study participants to questions about health texts.\nThis average *has* to have a minimum of 0 (no responses correct) and a maximum\nof 1 (all responses correct). The average is calculated by adding up all the \ncorrect answers and dividing by the number of questions answered by each\nparticipant.\n- `mean.self` is scaled from 1 to 9 bcause it represents the average self-rated\naccuracy of understanding. Participants are asked to rate on a scale form \n1 (not all) to 9 (very well) how well they think they understand a health\ninformation text. The average is calculated by adding up all the \nratings and dividing by the number of texts responded to by each\nparticipant.\n\nThe **important lesson**, here, is that estimates of predictor effects are scaled\nin terms of predicted change in the outcome, so whatever scale the outcome\nmeasurement is in determines how big or small the predictor coefficient estimates\ncan be.\n\nWe can visualize this to see what it means in practice.\n\n- Q.15. Can you plot the predictions from each model?\n\n- A.15. Here is the code to plot the predictions from both models.\n\n**First** fit the models.\n\n- Remember to give each model object distinct names.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-9_94e8021014f22397f892dc9bd690c781'}\n\n```{.r .cell-code}\nmodel.1 <- lm(mean.acc ~ mean.self, data = study.two.gen)\nsummary(model.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.acc ~ mean.self, data = study.two.gen)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.293692 -0.069200  0.005422  0.080041  0.215240 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.379182   0.045415   8.349 2.31e-14 ***\nmean.self   0.053566   0.006303   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1013 on 170 degrees of freedom\nMultiple R-squared:  0.2982,\tAdjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n```\n:::\n\n```{.r .cell-code}\nmodel.2 <- lm(mean.self ~ mean.acc, \n            data = study.two.gen)\nsummary(model.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ mean.acc, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47926 -0.62782  0.02038  0.65403  2.37788 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.8725     0.5037   5.703 5.12e-08 ***\nmean.acc      5.5670     0.6550   8.499 9.36e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.032 on 170 degrees of freedom\nMultiple R-squared:  0.2982,\tAdjusted R-squared:  0.2941 \nF-statistic: 72.24 on 1 and 170 DF,  p-value: 9.356e-15\n```\n:::\n:::\n\n\n**Second** get the predictions:\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-10_aed5af2fbbe5871efe27f79956bad1dc'}\n\n```{.r .cell-code}\ndat.1 <- ggpredict(model.1, \"mean.self\")\ndat.2 <- ggpredict(model.2, \"mean.acc\")\n```\n:::\n\n\n**Third** make the prediction plots:\n\n1. Predictions from the model `mean.acc ~ mean.self`\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-11_e85a16af34df5ebfcbb6e49804a62739'}\n\n```{.r .cell-code}\nplot(dat.1)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-workbook-answers_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n1. Predictions from the model `mean.self ~ mean.acc`\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-12_90088174e44e3c115a89776f02063502'}\n\n```{.r .cell-code}\nplot(dat.2)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-workbook-answers_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n- Q.16. Look at the two plots: what do you see?\n- hint: Q.16. Look at changes in height of the prediction line, given \nchanges in x-axis position of the line\n\n- A.16. A side-by-side comparison shows that:\n\n1. For model `mean.acc ~ mean.self` increases in `mean.self` from about 4 to 9 are \nassociated with a change in `mean.acc` from about .6 to about .85;\n2. For model `mean.self ~ mean.acc` increases in `mean.acc` from about 0.4 to 1.0 are \nassociated with a change in `mean.self` from about 5 to about 9.\n\n\n## Step 6: Estimate the effects of factors as well as numeric variables\n\n\n### Consolidation: build your skills\n\n\nWe have not yet included any categorical or nominal variables as predictors\nbut we can, and should: `lm()` can cope with any kind of variable as a predictor.\n\nThere are different ways to do this, here we ask you to use the R default method.\n\n\n### Task 7 -- Fit a linear model to examine what variables predict outcome mean self-rated accuracy of `mean.self`\n\n#### hint: Task 7 -- Include as predictors both numeric variables and categorical variables \n\nHere, our model includes predictors that are both numeric like:\n\n- health literacy (`HLVA`); \n- vocabulary (`SHIPLEY`); \n- `AGE`;\n- reading strategy (`FACTOR3`);\n- accuracy `mean.acc`\n\nAs well as a categorical or nominal variable like\n\n- `EDUCATION`.\n\nNote: `EDUCATION` is different because participants are classified by\nwhat education category (`higher education, further education, secondary school`)\nthey report themselves as having received.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-13_db028507e4a71fa87b975cf6c6f20ad8'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc +\n                        EDUCATION, \n            data = study.two.gen)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + \n    EDUCATION, data = study.two.gen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70987 -0.50037  0.01988  0.55965  2.01412 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.487753   0.702049   0.695   0.4882    \nHLVA                0.047100   0.034915   1.349   0.1792    \nSHIPLEY            -0.044132   0.018719  -2.358   0.0196 *  \nFACTOR3             0.061918   0.010771   5.749 4.29e-08 ***\nAGE                 0.023997   0.005595   4.289 3.06e-05 ***\nmean.acc            4.912833   0.712381   6.896 1.10e-10 ***\nEDUCATIONHigher    -0.082217   0.146390  -0.562   0.5751    \nEDUCATIONSecondary  0.346161   0.266030   1.301   0.1950    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8783 on 164 degrees of freedom\nMultiple R-squared:  0.5099,\tAdjusted R-squared:  0.489 \nF-statistic: 24.38 on 7 and 164 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n- Q.17. Can you report the overall model and model fit statistics?\n\n- A.17. \n\n> We fitted a linear model with mean self-rated accuracy as the outcome and with the predictors: \nhealth literacy (`HLVA`), vocabulary (`SHIPLEY`), reading strategy (`FACTOR3`), `AGE`,\nas well as mean accuracy (`mean.acc`) and education level (`EDUCATION`). \nThe model is significant overall, with F(7, 164) = 24.38, p < .001, and \nexplains 49% of variance (adjusted R2 = 0.489).\n\n- Q.18. Can you plot the predicted effect of `EDUCATION` given your model?\n\n- hint: Q.18. We first fit the model, including `EDUCATION`.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-14_23cecb7beb8d2a7662db80de491c82c1'}\n\n```{.r .cell-code}\nmodel <- lm(mean.self ~ HLVA + SHIPLEY + FACTOR3 + AGE + mean.acc + EDUCATION, \n            data = study.two.gen)\n```\n:::\n\n\n- hint: Q.18. We then use the `ggpredict()` function to get the prediction for\nthe effect of `EDUCATION` differences on outcome `mean.self`.\n\n\n::: {.cell hash='2023-24-PSYC122-w18-workbook-answers_cache/html/unnamed-chunk-15_5bb8e4503a5dcb05f051626a58444929'}\n\n```{.r .cell-code}\ndat <- ggpredict(model, \"EDUCATION\")\nplot(dat)\n```\n\n::: {.cell-output-display}\n![](2023-24-PSYC122-w18-workbook-answers_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n- Q.19. The plot should give you dot-and-whisker representations of the estimated `mean.self` outcome for different levels of `EDUCATION`. What is the difference in the estimated `mean.self` between the groups?\n\n- hint: Q.19. The effect or prediction plot will show you **dot-and-whisker** representations of predicted outcome `mean.self`. In these plots, the dots represent the estimated `mean.self` while the lines (whiskers) represent confidence intervals.\n\n- A.19. The difference in the estimated `mean.self` between these groups is small: the groups vary between ratings of about 7, 7.10 and 7.5.\n\n- Q.20. Compare the difference in the estimated `mean.self` between these groups, given the plot, with the coefficient estimate from the model summary: what do you see?\n\n- A.20. The effect of `EDUCATION` is presented in the summary as two estimates:\n\n- `EDUCATIONHigher    -0.082217`\n- `EDUCATIONSecondary  0.346161`\n\nThe reference level for `EDUCATION` is `Further`. \n\nThe estimates therefore show that people with `Higher` education have `mean.self` \nscores about -.08 lower than `mean.self` for people with `Further` education. \n\nPeople with `Secondary` education have `mean.self` scores about .35 higher than \n`mean.self` for people with `Further` education.\n\nWe are learning some new things here so it is useful to explain them:\n\n1. Categorical variables or **factors** and reference levels.\n\n- If you have a categorical variable like `EDUCATION` then when you use it in\nan analysis, R will look at the different categories (called `levels) e.g., here,\n`higher education, further education, secondary school` and it will pick one\nlevel to be the *reference* or baseline level. \n- The *reference* is the the level against which other levels are compared. \n- Here, the reference level is `Further` (education) simply because, unless\nyou tell R otherwise, it picks the level with a category name that begins\nearlier in the alphabet as the reference level.\n\n2. Dot and whisker plots show estimates with confidence intervals.\n\n- Dot and whisker plots are a nice way to present a concise visual summary\nabout the estimates we get from prediction models.\n- Here, the plots show the coefficient estimates from our model (the dots) plus \nconfidence intervals (the lines or \"whiskers\").\n\n3. Confidence intervals are often misunderstood but they are helpful.\n\n- Essentially, a confidence interval tells us about we might expect to see\nusing our analysis procedure (Hoekstra et al., 2014).\n\n> If we were to repeat the experiment over and over, then 95 % of the time the \nconfidence intervals contain the true mean.\n\n- And you can read more about this here\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E. J. (2014). Robust misinterpretation of confidence intervals. *Psychonomic Bulletin & Review*, 21, 1157-1164.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}