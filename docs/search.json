[
  {
    "objectID": "Test/Week7.html",
    "href": "Test/Week7.html",
    "title": "Is it morning or day?",
    "section": "",
    "text": "This is a proof of concept that we can hide/autoshow information. It is a bit clunky and requires some javascript functions, but theoretically only requires updating once a year and then a simple copy-paste of information.\n\n\nSuccess! It is morning!\nThis is hidden!\n\n\n\n\nSuccess! It is afternoon!\nThis is hidden!"
  },
  {
    "objectID": "Test/Week7.html#this-content-shows-if-it-is-morning",
    "href": "Test/Week7.html#this-content-shows-if-it-is-morning",
    "title": "Is it morning or day?",
    "section": "",
    "text": "Success! It is morning!\nThis is hidden!"
  },
  {
    "objectID": "Test/Week7.html#this-shows-if-it-is-afternoon",
    "href": "Test/Week7.html#this-shows-if-it-is-afternoon",
    "title": "Is it morning or day?",
    "section": "",
    "text": "Success! It is afternoon!\nThis is hidden!"
  },
  {
    "objectID": "Staff/index.html",
    "href": "Staff/index.html",
    "title": "Staff Information",
    "section": "",
    "text": "Hi. This will have some documents/information on how to set up the materials for Quarto and have it push to the website.\nIt’ll have a .zip for the basic folder structure required for easy integration of the materials into the rest.\nMay even have the instructor files? Although obviously students will click a “For Staff” button, so maybe it needs to be on an invisible link.\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC121/Week8.html",
    "href": "PSYC121/Week8.html",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nWatch Part 4\n\nDownload the lecture slides here\n\n\nChapter 13 of Howell\nToday we will take a look at summarising means and standard errors (SEs) from our data. We will look at how we plot these together on the one graph (using ggplot() commands that allow us to share mappings between different geoms. We will explore our data on the famous “Stroop Task” and we will use a related-samples t-test to examine the differences between the means of our different conditions in this task.\n\n\n\nOnline tutorial: You must make every attempt to complete this before the lab! To access the pre-lab tutorial click here (on campus, or VPN required)\nGetting ready for the lab class\n\nCreate a folder for Week 8 and download the Week_8 csv file file and upload it into this new folder in RStudio Server.\n\n\n\n\n\n\nThe “Stroop Effect” is a classic demonstration of automaticity of behaviour. Participants have to say the colour a word is printed in, which is an easy task for a “compatible” stimulus like GREEN, and a much more difficult task for an “incompatible” stimulus like BLUE. We can’t help but read the text - it has seemingly become an automatic process.\n In this task we will calculate the means and standard errors of the means and then we will then plot them using ggplot(). First though, we’ll need to inspect the data and maybe do a bit of data wrangling by using our filter() command.\n\nCreate a new R Markdown document. If you’re unsure about this step, see the instructions from Week 6 (or 7).\nAs usual, add a code chunk with library(tidyverse) and a read_csv command (see above for the link to the csv). Assign the result to a new data object, and call your data something meaningful (perhaps data_w8 or data_stroop but maybe not bestest_most_fantastic_data_on_the_stroop_test_eva_init)\nView the data with View(data_object_name). You will see that the data are a little different from the data we have worked with previously. We have an pID variable, which gives a unique number for each person, but each person has 3 rows of data. This is because the different conditions of the Stroop task reflect a within-subjects variable (related samples). For data like this it is often useful to have them arranged in what is referred to as “long format”, with multiple rows for each response the participant provides. For the current data that means we have a variable called condition, which is our IV, and one called time which is our DV. We also have a column labelled avg_time, which is the average of the 3 time values for each participant (the data is duplicated, which is both normal and necessary with long format data).\nLet’s look at the distribution of time (our DV) as a function of condition. Add another chunk of code and include the following code:\n\n\n# distribution of times by condition\nyour_data_object %&gt;% \n  ggplot() +\n  geom_density(aes(x = missing_column_name_A, fill = missing_column_name_B), alpha = .8) + # you need to EDIT this for Q4\n  theme_dark()\n\n\nYou’ll need to “map” x to time and fill to condition for our geom_density() plot. You can play around with the alpha parameter (which sets the transparency of the elements of the graph), setting it to a value between 0 and 1. Note that this is done OUTSIDE of the aes() command.\nFrom the density plot, it does seem like we have some outlier values. It’s probably best if we remove data for the whole participant if their average time is unusual. To do that, we’ll look at the data using the avg_time column. Add the following code for a geom_histogram() to plot the distribution of values in the new avg_time column.\n\n\n# distribution of average times\nyour_data_object %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = missing_column_name_A), fill = \"pink\") + # you need to EDIT this line\n  theme_classic()\n\n\nLet’s use the filter command we learned last week to remove these high values. Like last week, we will do this (for now) in a fairly unprincipled manner, by “eyeballing” the data (next week we’ll consider something a bit more “scientific”). Complete the filter command so that it keeps only the responses for people that had an avg_time less than 12 seconds. Remember that you need to think about how you are storing the result of this filter process. Do you want to create a new object, or overwrite the existing object?\n\n\n# filter out the high values\nnew_data_object &lt;- # create a new object (or overwrite)\n  your_data_object %&gt;% # original data object \n  filter(insert_an_expression_here)\n\n\n\n\n\n\n\nCheck your result!\n\n\n\nIf you’ve done this correctly, you should now have a data object that has 360 rows (data for 120 participants, with 3 responses each).\n\n\n\nAdd and edit the following code to plot a histogram of the filtered data.\n\n\n# draw a histogram of the filtered data \nnew_data_object %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = missing_columns_name), \n                 fill = \"pink\", # try some different colours?\n                 colour = \"purple\", # and here?\n                 bins = 3) #  # adjust the bins? \n# you could also add (+) a theme to this plot! \n# for a list of themes, type: ?theme_classic\n\n\nFinally, copy the code for the original geom_density() plot that you drew in step 4. Paste it, and edit the code so that it now plots the filtered set of data (from step 7) for each of the three conditions in the stroop task.\n\n\n\n\nWe have seen in our density plots that the reaction times (DV) look different in the three different Stroop conditions (our IV). But now we need to look at whether there are statistically significant differences between the means of the three conditions.\nTo do this, we will first summarise the mean time taken by each condition in the Stroop task. In Week 3 we learnt how to use group_by() and summarise() to get summary stats (e.g., mean, sd) at each level of the IV. That’s what we want to do now:\n\nCopy the code below into your R Markdown and edit the group_by() line to specify the IV and the summarise() line to calculate the mean() of our DV. If you do this correctly, you’ll get three values - a mean value for each level (condition) of our IV. Do these means reflect what you would expect in the Stroop task? Do they match the central tendency of the distributions you plotted?\n\n\nname_of_data_object %&gt;%\n  group_by(name_of_IV_column) %&gt;% # you need to EDIT this for Q1\n  summarise(stroop_mean = mean(name_of_DV_column)) # you need to EDIT this for Q1\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nYou should have 3 values: 4.22, 5.69, 7.28\nIf all of your values are the same, you’ve analysed the wrong column.\n\n\n\n\nNext we need to test if these differences between our means are real. To do that, we can run a related samples t-test. We use this test because each level of the IV in this experiment came from the same person. First though, we must use a filter() to restrict the data to just two levels of the IV. The IV is the condition column/variable in the data. The related samples t-test looks at the difference between two means (and only two), so the column we use for the t-test needs to have just two levels of the IV (two of the conditions).\nCopy the code below into your R Markdown. The filter command is already set up to restrict the data to two of the conditions. Note that the filter uses an “|” symbol, which means “or”, because we want the data that is the same as (==) one condition OR is the same as (==) the other condition. You’ll need to edit the name of the data object to get this to run.\n\n\n# use filter to select two levels of the IV - Q3-5\nstroop_comparison &lt;-\n  name_of_data_object %&gt;% # Edit this for the name of YOUR data object\n  filter(condition == \"compatible\" | condition == \"incompatible\")\n\n# run the t-test comparing the means of these two levels\nt.test(data = stroop_comparison, time ~ condition, paired = TRUE)\n\n\nRun the t-test on this selection of data to compare the means from these two levels of the IV. Is the result significant? Note the t-value and the p-value.\nWrite out a statement in your R Markdown document to express this result. Here’s a template you can use, where you need to edit the bits in the []:\n\n\n“There [was a / was no] significant difference between the [describe the variables that were compared], t([degrees of freedom here]) = [t value here], p &lt; [p value here].”\n\n\nWith 3 levels to the IV condition there are 3 possible comparisons we can make (L1 vs. L2; L1 vs. L3; L2 vs. L3). Complete all three tests, by copying and pasting the code chunk twice more, editing each to make a different filter selection, and then running the t-test. Write out a reporting statement (Q5) for each of your comparisons.\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nUsing the filtered data (360 rows) you should get the following t statistics: -18.257, -11.754, -10.258\nRemember that it’s the magnitude that’s important, not whether it’s positive or negative. The sign simply depends which way round they are compared in the t calculations (mean_1 - mean_2 or mean_2 - mean_1)\n\n\n\n\n\n\n\nIn Task 2 you calculated the means for each condition in the Stroop task. We’ve seen in lectures that “standard error” provides an estimate of how variable that mean will be across the samples we collect. A very typical way to plot a mean value is to plot it with the standard error of the mean (SEM):\n\n\n\nThe code from Task 2, Question 1 will give the mean. We will now add a second line of this code to give the standard error values:\n\n\nstroop_summary &lt;- \n  name_of_data_object %&gt;%\n  group_by(name_of_IV_column) %&gt;% # you need to EDIT this for Q2\n  summarise(stroop_mean = mean(name_of_DV_column),\n            stroop_SE = sd(name_of_DV_column)/sqrt(n())) # you need to EDIT this for Q1\n\n\nAdd this code to your document and the correct column (DV) to both the sd() and the mean() commands. Note that you don’t need to put anything in n(), as this simply calculates how many rows there are.\nView the new summary object you have created. Check that the means and SEs are different for the 3 conditions. If they are the same, you probably summarised the wrong column!\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nThe SE values should be: 0.117, 0.170, 0.208\n\n\n\n\nWe will now plot these 3 mean values in a figure. Let’s use geom_point() so that our means and SEs look a bit like the figure above. Complete the ggplot command to plot our summarised value called stroop_mean (y), as a function of the IV, condition (x):\n\n\n# let's first plot the means\nname_of_data_object %&gt;%\n  ggplot(aes(x = name_of_IV_column, y = name_of_DV_column)) + # map variables to x and y for Q5\n  geom_point(size = 5)\n\n\nNow we need to add some “error bars” which provide a visual guide as to how much uncertainty we have in our mean value. Edit the code below for the ggplot() command to plot both geom_point() (same as Q5) and geom_errorbar. You will need to calculate a ymin and a ymax value.\n\n\n\n\n\n\n\nPlotting the error bars\n\n\n\nUse the illustration of the error bars above to work out how to combine the mean value and the SE value (hint: you’ll need to either ADD or SUBTRACT for the two statements) to create the right ymin and ymax. You need to put this in the “missing_equation” bit of the code below:\n\n\n\n# let's first plot the means\nname_of_data_object %&gt;%\n  ggplot(aes(x = name_of_IV_column, y = name_of_DV_column)) + # map variables to x and y for Q5\n  geom_point(size = 5) +\n  geom_errorbar(aes(ymin = missing_equation, # edit this for Q5\n                    ymax = missing_equation), # edit this for Q5\n                width = .2) \n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nThe correct result will have 3 points, and an error bar around each mean point. These 3 error bars should all be different sizes (as per the 3 SEs you calculated in steps 2-4)\n\n\n\nEXTRA: These next steps can be completed to practice customising your plot\n\nAdd a labs() layer to the plot to change the axis titles, and the title of the plot.\nChange the theme of the plot (e.g., theme_classic())\nMap the colour aesthetic to the variable condition. You can do this for geom_point or geom_errorbar or both at once by putting it in the aes() within the ggplot() command.\nTry changing your geom_point() to geom_col.\n\n\n\n\nLet’s try knitting the document. If you’ve done everything right, then the knitting process will work and you’ll get a nice output (in html, or PDF, whichever you choose). If something goes wrong, here’s a few things you can check\n\nDid you keep all your code in the code chunks?\nCheck all your code blocks run.\nAre there any red cross symbols next to your lines of code? These indicate a code error and need to be fixed before it will knit.\n\nWhen you knit the document, you will probably see the code you have written in the output. You can decide whether you want to present the code or not using the options for each code chunk:\n\nClick the cog, then select the type of output you want each code to produce.\nKnitting the document is a great way to see how your work functions as an actual report. Go back and add more description between your code chunks to describe all the steps you have performed in your analysis.\n\n\n\n\nYou can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC121/Week8.html#reading",
    "href": "PSYC121/Week8.html#reading",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "",
    "text": "Chapter 13 of Howell\nToday we will take a look at summarising means and standard errors (SEs) from our data. We will look at how we plot these together on the one graph (using ggplot() commands that allow us to share mappings between different geoms. We will explore our data on the famous “Stroop Task” and we will use a related-samples t-test to examine the differences between the means of our different conditions in this task."
  },
  {
    "objectID": "PSYC121/Week8.html#pre-lab-work-online-tutorial",
    "href": "PSYC121/Week8.html#pre-lab-work-online-tutorial",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "",
    "text": "Online tutorial: You must make every attempt to complete this before the lab! To access the pre-lab tutorial click here (on campus, or VPN required)\nGetting ready for the lab class\n\nCreate a folder for Week 8 and download the Week_8 csv file file and upload it into this new folder in RStudio Server."
  },
  {
    "objectID": "PSYC121/Week8.html#rstudio-tasks",
    "href": "PSYC121/Week8.html#rstudio-tasks",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "",
    "text": "The “Stroop Effect” is a classic demonstration of automaticity of behaviour. Participants have to say the colour a word is printed in, which is an easy task for a “compatible” stimulus like GREEN, and a much more difficult task for an “incompatible” stimulus like BLUE. We can’t help but read the text - it has seemingly become an automatic process.\n In this task we will calculate the means and standard errors of the means and then we will then plot them using ggplot(). First though, we’ll need to inspect the data and maybe do a bit of data wrangling by using our filter() command.\n\nCreate a new R Markdown document. If you’re unsure about this step, see the instructions from Week 6 (or 7).\nAs usual, add a code chunk with library(tidyverse) and a read_csv command (see above for the link to the csv). Assign the result to a new data object, and call your data something meaningful (perhaps data_w8 or data_stroop but maybe not bestest_most_fantastic_data_on_the_stroop_test_eva_init)\nView the data with View(data_object_name). You will see that the data are a little different from the data we have worked with previously. We have an pID variable, which gives a unique number for each person, but each person has 3 rows of data. This is because the different conditions of the Stroop task reflect a within-subjects variable (related samples). For data like this it is often useful to have them arranged in what is referred to as “long format”, with multiple rows for each response the participant provides. For the current data that means we have a variable called condition, which is our IV, and one called time which is our DV. We also have a column labelled avg_time, which is the average of the 3 time values for each participant (the data is duplicated, which is both normal and necessary with long format data).\nLet’s look at the distribution of time (our DV) as a function of condition. Add another chunk of code and include the following code:\n\n\n# distribution of times by condition\nyour_data_object %&gt;% \n  ggplot() +\n  geom_density(aes(x = missing_column_name_A, fill = missing_column_name_B), alpha = .8) + # you need to EDIT this for Q4\n  theme_dark()\n\n\nYou’ll need to “map” x to time and fill to condition for our geom_density() plot. You can play around with the alpha parameter (which sets the transparency of the elements of the graph), setting it to a value between 0 and 1. Note that this is done OUTSIDE of the aes() command.\nFrom the density plot, it does seem like we have some outlier values. It’s probably best if we remove data for the whole participant if their average time is unusual. To do that, we’ll look at the data using the avg_time column. Add the following code for a geom_histogram() to plot the distribution of values in the new avg_time column.\n\n\n# distribution of average times\nyour_data_object %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = missing_column_name_A), fill = \"pink\") + # you need to EDIT this line\n  theme_classic()\n\n\nLet’s use the filter command we learned last week to remove these high values. Like last week, we will do this (for now) in a fairly unprincipled manner, by “eyeballing” the data (next week we’ll consider something a bit more “scientific”). Complete the filter command so that it keeps only the responses for people that had an avg_time less than 12 seconds. Remember that you need to think about how you are storing the result of this filter process. Do you want to create a new object, or overwrite the existing object?\n\n\n# filter out the high values\nnew_data_object &lt;- # create a new object (or overwrite)\n  your_data_object %&gt;% # original data object \n  filter(insert_an_expression_here)\n\n\n\n\n\n\n\nCheck your result!\n\n\n\nIf you’ve done this correctly, you should now have a data object that has 360 rows (data for 120 participants, with 3 responses each).\n\n\n\nAdd and edit the following code to plot a histogram of the filtered data.\n\n\n# draw a histogram of the filtered data \nnew_data_object %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = missing_columns_name), \n                 fill = \"pink\", # try some different colours?\n                 colour = \"purple\", # and here?\n                 bins = 3) #  # adjust the bins? \n# you could also add (+) a theme to this plot! \n# for a list of themes, type: ?theme_classic\n\n\nFinally, copy the code for the original geom_density() plot that you drew in step 4. Paste it, and edit the code so that it now plots the filtered set of data (from step 7) for each of the three conditions in the stroop task.\n\n\n\n\nWe have seen in our density plots that the reaction times (DV) look different in the three different Stroop conditions (our IV). But now we need to look at whether there are statistically significant differences between the means of the three conditions.\nTo do this, we will first summarise the mean time taken by each condition in the Stroop task. In Week 3 we learnt how to use group_by() and summarise() to get summary stats (e.g., mean, sd) at each level of the IV. That’s what we want to do now:\n\nCopy the code below into your R Markdown and edit the group_by() line to specify the IV and the summarise() line to calculate the mean() of our DV. If you do this correctly, you’ll get three values - a mean value for each level (condition) of our IV. Do these means reflect what you would expect in the Stroop task? Do they match the central tendency of the distributions you plotted?\n\n\nname_of_data_object %&gt;%\n  group_by(name_of_IV_column) %&gt;% # you need to EDIT this for Q1\n  summarise(stroop_mean = mean(name_of_DV_column)) # you need to EDIT this for Q1\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nYou should have 3 values: 4.22, 5.69, 7.28\nIf all of your values are the same, you’ve analysed the wrong column.\n\n\n\n\nNext we need to test if these differences between our means are real. To do that, we can run a related samples t-test. We use this test because each level of the IV in this experiment came from the same person. First though, we must use a filter() to restrict the data to just two levels of the IV. The IV is the condition column/variable in the data. The related samples t-test looks at the difference between two means (and only two), so the column we use for the t-test needs to have just two levels of the IV (two of the conditions).\nCopy the code below into your R Markdown. The filter command is already set up to restrict the data to two of the conditions. Note that the filter uses an “|” symbol, which means “or”, because we want the data that is the same as (==) one condition OR is the same as (==) the other condition. You’ll need to edit the name of the data object to get this to run.\n\n\n# use filter to select two levels of the IV - Q3-5\nstroop_comparison &lt;-\n  name_of_data_object %&gt;% # Edit this for the name of YOUR data object\n  filter(condition == \"compatible\" | condition == \"incompatible\")\n\n# run the t-test comparing the means of these two levels\nt.test(data = stroop_comparison, time ~ condition, paired = TRUE)\n\n\nRun the t-test on this selection of data to compare the means from these two levels of the IV. Is the result significant? Note the t-value and the p-value.\nWrite out a statement in your R Markdown document to express this result. Here’s a template you can use, where you need to edit the bits in the []:\n\n\n“There [was a / was no] significant difference between the [describe the variables that were compared], t([degrees of freedom here]) = [t value here], p &lt; [p value here].”\n\n\nWith 3 levels to the IV condition there are 3 possible comparisons we can make (L1 vs. L2; L1 vs. L3; L2 vs. L3). Complete all three tests, by copying and pasting the code chunk twice more, editing each to make a different filter selection, and then running the t-test. Write out a reporting statement (Q5) for each of your comparisons.\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nUsing the filtered data (360 rows) you should get the following t statistics: -18.257, -11.754, -10.258\nRemember that it’s the magnitude that’s important, not whether it’s positive or negative. The sign simply depends which way round they are compared in the t calculations (mean_1 - mean_2 or mean_2 - mean_1)\n\n\n\n\n\n\n\nIn Task 2 you calculated the means for each condition in the Stroop task. We’ve seen in lectures that “standard error” provides an estimate of how variable that mean will be across the samples we collect. A very typical way to plot a mean value is to plot it with the standard error of the mean (SEM):\n\n\n\nThe code from Task 2, Question 1 will give the mean. We will now add a second line of this code to give the standard error values:\n\n\nstroop_summary &lt;- \n  name_of_data_object %&gt;%\n  group_by(name_of_IV_column) %&gt;% # you need to EDIT this for Q2\n  summarise(stroop_mean = mean(name_of_DV_column),\n            stroop_SE = sd(name_of_DV_column)/sqrt(n())) # you need to EDIT this for Q1\n\n\nAdd this code to your document and the correct column (DV) to both the sd() and the mean() commands. Note that you don’t need to put anything in n(), as this simply calculates how many rows there are.\nView the new summary object you have created. Check that the means and SEs are different for the 3 conditions. If they are the same, you probably summarised the wrong column!\n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nThe SE values should be: 0.117, 0.170, 0.208\n\n\n\n\nWe will now plot these 3 mean values in a figure. Let’s use geom_point() so that our means and SEs look a bit like the figure above. Complete the ggplot command to plot our summarised value called stroop_mean (y), as a function of the IV, condition (x):\n\n\n# let's first plot the means\nname_of_data_object %&gt;%\n  ggplot(aes(x = name_of_IV_column, y = name_of_DV_column)) + # map variables to x and y for Q5\n  geom_point(size = 5)\n\n\nNow we need to add some “error bars” which provide a visual guide as to how much uncertainty we have in our mean value. Edit the code below for the ggplot() command to plot both geom_point() (same as Q5) and geom_errorbar. You will need to calculate a ymin and a ymax value.\n\n\n\n\n\n\n\nPlotting the error bars\n\n\n\nUse the illustration of the error bars above to work out how to combine the mean value and the SE value (hint: you’ll need to either ADD or SUBTRACT for the two statements) to create the right ymin and ymax. You need to put this in the “missing_equation” bit of the code below:\n\n\n\n# let's first plot the means\nname_of_data_object %&gt;%\n  ggplot(aes(x = name_of_IV_column, y = name_of_DV_column)) + # map variables to x and y for Q5\n  geom_point(size = 5) +\n  geom_errorbar(aes(ymin = missing_equation, # edit this for Q5\n                    ymax = missing_equation), # edit this for Q5\n                width = .2) \n\n\n\n\n\n\n\nCheck your result!\n\n\n\n\nThe correct result will have 3 points, and an error bar around each mean point. These 3 error bars should all be different sizes (as per the 3 SEs you calculated in steps 2-4)\n\n\n\nEXTRA: These next steps can be completed to practice customising your plot\n\nAdd a labs() layer to the plot to change the axis titles, and the title of the plot.\nChange the theme of the plot (e.g., theme_classic())\nMap the colour aesthetic to the variable condition. You can do this for geom_point or geom_errorbar or both at once by putting it in the aes() within the ggplot() command.\nTry changing your geom_point() to geom_col.\n\n\n\n\nLet’s try knitting the document. If you’ve done everything right, then the knitting process will work and you’ll get a nice output (in html, or PDF, whichever you choose). If something goes wrong, here’s a few things you can check\n\nDid you keep all your code in the code chunks?\nCheck all your code blocks run.\nAre there any red cross symbols next to your lines of code? These indicate a code error and need to be fixed before it will knit.\n\nWhen you knit the document, you will probably see the code you have written in the output. You can decide whether you want to present the code or not using the options for each code chunk:\n\nClick the cog, then select the type of output you want each code to produce.\nKnitting the document is a great way to see how your work functions as an actual report. Go back and add more description between your code chunks to describe all the steps you have performed in your analysis."
  },
  {
    "objectID": "PSYC121/Week8.html#week-8-quiz",
    "href": "PSYC121/Week8.html#week-8-quiz",
    "title": "8. Related-samples t-tests, plotting means and SE bars",
    "section": "",
    "text": "You can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC121/Week6.html",
    "href": "PSYC121/Week6.html",
    "title": "6. Sampling, probability and binomial tests",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nWatch Part 4\n\nYou can download the lecture slides here"
  },
  {
    "objectID": "PSYC121/Week6.html#week-6-lecture",
    "href": "PSYC121/Week6.html#week-6-lecture",
    "title": "6. Sampling, probability and binomial tests",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nWatch Part 4\n\nYou can download the lecture slides here"
  },
  {
    "objectID": "PSYC121/Week6.html#reading",
    "href": "PSYC121/Week6.html#reading",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Reading",
    "text": "Reading\nChapter 8 of Howell"
  },
  {
    "objectID": "PSYC121/Week6.html#pre-lab-work",
    "href": "PSYC121/Week6.html#pre-lab-work",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Pre-lab work",
    "text": "Pre-lab work\n\nEnsure you have watched the above lecture content for Week 6.\nComplete the short learnr tutorial which will introduce you to running the binomial tests in R. You can find it here.\nlink for the class record of sampling data"
  },
  {
    "objectID": "PSYC121/Week6.html#some-basic-rmarkdown",
    "href": "PSYC121/Week6.html#some-basic-rmarkdown",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Some basic RMarkdown",
    "text": "Some basic RMarkdown\nWe introduced you to RMarkdown in Week 4. It’s like a .R script, only a bit more fancy! Today we’ll introduce a couple more features and use this in our tasks below.\n\nMake sure you have a Week 6 folder\nOnce in that folder in the files pane, click “more” and “set as working directory”\nThen click the new file button and select “R Markdown”\n\n\n\nYou’ll be asked to name this file. Leave the other options as they are and click OK.\nWhen the new R Markdown file appears, try “knitting” it (the icon at the top with the ball of wool). You should get a nice output of the default R Markdown document.\nNote that in R Markdown documents you can freely type in text in the main body of the file - you did this last week. But see how you can also create a “code chunk” within the document. These are places where you put your R code you want to run.\n\n\n\n\n\n\n\n.Rmd and .R differences\n\n\n\nIn a way, R Markdown files function in the opposite way to .R files:\n\n.Rmd: you write normal text in the main part (like you’d do in a word processor), but you create a special “code chunk” for your code.\n.R: you write code in the main body, and use the “#” to write normal text as a comment\n\n\n\n\nTry running the first code chunk (click the green arrow on the right). This will run the code and display the output (in the document and in the console)."
  },
  {
    "objectID": "PSYC121/Week6.html#creating-an-r-markdown-for-your-lab-work",
    "href": "PSYC121/Week6.html#creating-an-r-markdown-for-your-lab-work",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Creating an R Markdown for your lab work",
    "text": "Creating an R Markdown for your lab work\n\nDelete all of the script except the first title (## R Markdown)\nChange this title to something more relevant: (e.g., ## Task 1 - Card Sampling task)\nKnit your document to check it is still working!"
  },
  {
    "objectID": "PSYC121/Week6.html#card-sampling-task",
    "href": "PSYC121/Week6.html#card-sampling-task",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Card sampling task",
    "text": "Card sampling task\n\nIn the first task this week we will look at the sampling of events and we will apply the basic statistical test of the binomial test: binom.test()\nEach table has a set of cards. These will be 13 red cards and 13 black cards - please check your set to ensure you have the right number of each colour (it doesn’t matter what suit the cards are).\nWe are going to play a game in which one person chooses a set of these cards and biases the deck towards either red or black. The other members of the table have to try and work out which way the set is biased. To do this, they will draw samples from the deck.\n\n\n\n\n\n\nThe Experiment\n\n\n\nThink of this as an experiment: there is something real out there in the world in our “population” (the cards). As an experimenter we are trying to estimate what is true about the world, and in order to do this we need to take samples. When you can only see the backs of the cards, that data is unobserved. But as we draw samples, we start to understand how the “world” is - whether it is biased towards red or black.\nSo each time you draw a card, you are observing one data point from the population, and based on the data you collect (your samples) you are going to draw an inference about what is true about the population.\n\n\n\nSet up and instructions:\n\nOne person on each table should act as the “world” (the person who biases the cards). Congratulations, you are God! This person will determine what is true about the state of things in the world. This means they control what is contained in the deck of cards.\nFor each experiment, this person secretly looks at the cards, and removes some cards to use in the experiment. For example, from the set of 26 cards, they might choose to remove 4 black cards. The deck is now biased towards red (13 red; 9 black).\nIt’s important that no one sees what the cards are (the ones you’ve kept, or the ones removed). Shuffle the cards so they are ready to be sampled.\nThe remaining people (1 or more) will act as the experimenters. Your job is to draw samples and work out whether you think the deck is biased or not towards either red or black.\nNow copy the following text and code to your R Markdown document to record your work:\n\n### Experiment 1\n\nNumber of samples:\nTotal red cards found:\nTotal black cards found:\nConclusion: \nThe true bias was: \n\n\n```{r}\n\nbinom.test(x, n) # x is the number or red or black; n is the sample size\n\n```\n\n\nRunning each experiment\nDo these steps for each experiment:\n\nThe “World” removes some cards from the full deck (the number and colour of the cards removed is up to them). They shuffle the chosen cards ready to start the “experiment”.\nThe “Experimenters” pre-register their sample size. That is, they state how many cards they are going to draw.\nDraw samples one at a time (each experimenter can take one card, to speed things up).\n\n\n\n\n\n\n\nImportant!\n\n\n\nMake sure you replace all the cards each time you draw samples. The world/dealer should also give the pack a quick shuffle.\n\n\n\nDo step 3 until you have collect the sample size you chose\nOnce you have all the samples, the experimenters should draw a conclusion based initially on their own “gut feeling” about the data. Do you think the deck was biased towards red, black, or was it unbiased?\nChange the binom.test() code to provide a statistical result. Note the “p value”. Was this result unusual? How likely were the data given the null hypothesis?\nThe “world” can then reveal the hidden cards. Was the deck actually biased or not? How does this sit with a) your initial conclusions, and b) the result of the binomial test?\nComplete your record log in the .Rmd file. Feel free to Write a short statement about what you found in this experiment.\n\nRepeat all of the above steps (1-8) for a new experiment, making sure that you try different parameters for the experiment. So vary a) how many cards are removed from the deck, b) the combination of cards removed from the deck, and c) the pre-registered sample size. Feel free to swap the roles around.\nOnce you’ve conducted a few experiments, discuss on your table the results you found. It might be useful to think about the following things:\n\nwere there times when your intuitions were different to the statistical result? For example, you were sure there was a bias, but in fact the statistics told you this was not that unusual (p was &gt; .05)?\nwere there times when the deck was actually biased, but you failed to prove this with your experiment (you failed to see p &lt; .05)? Do you remember what this type of error is called?\nwere there times when the deck was not biased, but the test result suggested it was (p &lt; .05)? Do you remember what type of error this is called?"
  },
  {
    "objectID": "PSYC121/Week6.html#risky-and-safe-decisions",
    "href": "PSYC121/Week6.html#risky-and-safe-decisions",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Risky and safe decisions",
    "text": "Risky and safe decisions\nFor the second exercise today we will look at data from the survey on “risky and safe decisions”. You may remember that you were asked the following question:\n\n\n\n\n\n\nGain\n\n\n\nImagine you are on a game-show and you win £300. The presenter gives you have a choice: receive an additional £100 for sure, or take a gamble offering a 50% chance to gain £200 and a 50% chance to gain nothing. Which would you choose?\n\nreceive £100 for sure\ntake the gamble of a 50% chance to gain £200 and a 50% chance to gain nothing\n\n\n\nWe then asked you a similar question:\n\n\n\n\n\n\nLoss\n\n\n\nImagine you are on a different game-show and you win £500. Here you are given a choice between either losing £100 from your winnings for sure, or taking a gamble offering a 50% chance to lose nothing and a 50% chance to lose £200. Which would you choose?\n\nlose £100 for sure\ntake the gamble of a 50% chance to lose nothing and a 50% chance to lose £200\n\n\n\nWe’ve called these “gain” and “loss”, because in the first scenario you’re being asked about a chance to gain money, while in the second, it’s about a chance to lose money. Note that the “expected utility” of the choices is equivalent:\n\n\n\n\n\n\n“The expected utility of an act is a weighted average of the utilities of each of its possible outcomes, where the utility of an outcome measures the extent to which that outcome is preferred, or preferable, to the alternatives. The utility of each outcome is weighted according to the probability that the act will lead to that outcome.” see here\n\n\n\nThat’s to say, on average, you’ll end up with +£100 for the two cases in the gain scenario, or -£100 for the two cases in the loss scenario.\nBut what do people actually pick? Well people tend to be risk-averse, choosing the safe option overall. But interestingly, the safe option is picked far less when the scenario is presented as a loss. People seem to want to take the risk of potentially not losing anything (but maybe losing more).\nLet’s look to see if you showed the same pattern!\n\nCreate a new section of your markdown, giving it a suitable header\nCreate a new code chunk by clicking the “Code” menu, then “Insert Chunk”\nYou can download the data from this link, then upload it into the server.\nAdd a read_csv() command to read the data into the environment.\n\n\n\n\n\n\n\nReading CSVs\n\n\n\n\nRemember to set the working directory so R knows where the file is\nRemember to assign (&lt;-) to a new data object and give this a sensible name\n\n\n\n\nView the data, and see that the columns represent the gain and loss scenarios. The values represent the choices people made.\nUse the count() function to count the number of “safe” and “risky” choices that were made for our sample\n\n\ncount(my_data_object_name, gain)\n\n\nWe can now tell whether, in our sample, people tended to play it safe or take the risky choice. Did the sample have a meaningful bias towards one type of decision? If they didn’t we’d expect it to be a 50/50 split between safe and risky (people might make their choice at random). Use the binom.test() to look at whether the result would be expected by chance, noting the p value that is found.\nWrite a sentence or two after your code to explain what this result means.\nRepeat for the data from the loss column. Was the p value &lt; .05 here? Again, write a sentence or two to explain what this means."
  },
  {
    "objectID": "PSYC121/Week4.html",
    "href": "PSYC121/Week4.html",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Lecture Part 3\n\nWatch Lecture Part 4\n\nDownload the lecture slides here\n\n\n\nComplete materials from sessions in previous week. Consolidate what we have already covered.\nThis week - there’s a new learnr tutorial to follow and help prep for what we are covering: You can find it here.\nMake sure you have access to the week_4_2023.zip file for the RStudio server. You can get the file here.\nIf you create a folder and upload the file into RStudio before the lab class you’ll be even more ready to follow along!\n\n\n\n\nLast week we introduced two different ways to get descriptive information about a variable / column of scores investigated as a function of a separate piece of information. In others words, describe the DV a function of an IV\nStudents were generally very good at utilising each of these;\naggregate(x = DV, by = list(IV), FUN = mean)\nand\ndataframe %&gt;% group_by(IV) %&gt;% summarise(mean_estimate = mean(DV))\nThis week, we’re focusing on how you can edit or customise a graph to be more useful to a viewer.\n\n\n\nStep 1. Set up a folder for this week in the R Project that you created last week.\nStep 2. Bring the week_4_2023.zip file into R Studio server. Like last week, upload the zip file, and read in the data file. Launch the week_4 R script as before.\n{If you’ve done Step 1 &2 already as a pre-lab preparation, super, pat yourself on the back, skip these steps an move on)}\nStep 3. Once again, we’re gong to be using commands from the tidyverse library (the pipe operator is one example) so we need to ensure that it’s active. Run the command\nlibrary(tidyverse)\nStep 4. Read in the datafiles that will be on the server. There’s already a script line for this, you just need to change the file name (and we’ve done this in previous weeks)\nStep 5. We’ve provided a suggestion of how you can complete the visualisation challenge task from week 3.\nStep 6. Customize you graph work. We’ve provided some suggestions about adding titles and labels for your graph. Edit and play with the script lines to make them useful to you and to understand how they work. Note that the ggplot instructions have a similar structure / grammar to the group_by() instructions that we used: piping a data frame to a (here, plotting) function and piping that to an output or summarisation format.\n\nTry change the text, the colours, and so on of the graphs.\nAdd comments for yourself about what the different commands do. The idea is to learn by trying different things out (changing values, taking out elements of the command, putting other is) and record for yourself.\nIf you are struggling or not sure, try look at help files.\n\n\n\n\n\nHint / Reminder: Sketch a normal (z score) distribution and mark the mean/mode, and mark off the relevant parts of the question so you know what you are trying to achieve and how to interpret any calculations you make.\n\n\nHint/ Guide 2. For questions 6 & 7, typically in psychology we use the 5% level as a cutoff to decide, in broadly described terms, whether something is extreme or unlikely vs. at least somewhat plausible or likely.\n\n\n\nz-score distributions\nQ1. What is the relationship between the sign of a z-score and its position in a distribution?\nQ2. If a distribution has a mean of 100 and a standard deviation of 10, what is the raw score equivalent to a z-score of 1.96?\nQ3. If a distribution has a mean of 157 and a standard deviation of 19, what is the raw score equivalent to a z-score of 1?\n\n\n\nQ4. What proportion of scores lie between the mean and a z-score of 0.5?\nQ5. What is the combined proportion of scores lying between z=-1.2 and z=.85?\n\n\n\nQ6. A Neuropsychologist has presented a test of face recognition to 200 neurotypical participants and finds that the scores are normally distributed with a mean of 85 and the standard deviation of 12. Two brain-damaged patients are also given the test. The one with right hemisphere brain damage scored 58 and the one with left hemisphere damage scored 67.\n\nWhat is the z score of the right hemisphere patient when compared to the neurotypical group?\nWhat proportion of neurotypical participants score lower that this patient?\nIs this patient likely to belong to the population of neurotypical participants? (justify your answer)\nWhat is the z score of the left hemisphere patient when compared to the neurotypical group?\nWhat proportion of neurotypical participants score lower than this patient?\nIs this patient likely to belong to the population of neurotypical participants? (justify your answer)\n\n\n\n\nCome back to this afterwards for some extra practice if you want:\nQ7. Tom Bunion has completed a huge research study and measured the foot size of men and women and found each to be normally distributed. The men have a mean size of 55 with a standard deviation of 5 and the women a mean of 33 and a standard deviation of 5. Joanna Toes has foolishly measured two individuals but forgotten to note their gender. These have foot sizes of 37 and 47. To which gender is each more likely to belong? What evidence is there for this?\n\n\n\nFor a bit of fun… The following are parody music videos about stats. Now that you have a few weeks’ experience with R Studion and also, an introduction to hypothesis testing, you might appreciate the following\nThe R Inferno Song (Teenage Dirtbag Parody) filmed largely on campus at Maynooth University, Ireland:\n\nHypothesis testing and p values (plus bunny rabbits and a dog)\n\n\n\n\nSome students have asked for a pointer to additional R resources so they can structure some time exploring the R system. There are lots, but this is good and very compatible with the teaching we provide: R for data science"
  },
  {
    "objectID": "PSYC121/Week4.html#pre-lab-work",
    "href": "PSYC121/Week4.html#pre-lab-work",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "",
    "text": "Complete materials from sessions in previous week. Consolidate what we have already covered.\nThis week - there’s a new learnr tutorial to follow and help prep for what we are covering: You can find it here.\nMake sure you have access to the week_4_2023.zip file for the RStudio server. You can get the file here.\nIf you create a folder and upload the file into RStudio before the lab class you’ll be even more ready to follow along!"
  },
  {
    "objectID": "PSYC121/Week4.html#r-studio-tasks",
    "href": "PSYC121/Week4.html#r-studio-tasks",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "",
    "text": "Last week we introduced two different ways to get descriptive information about a variable / column of scores investigated as a function of a separate piece of information. In others words, describe the DV a function of an IV\nStudents were generally very good at utilising each of these;\naggregate(x = DV, by = list(IV), FUN = mean)\nand\ndataframe %&gt;% group_by(IV) %&gt;% summarise(mean_estimate = mean(DV))\nThis week, we’re focusing on how you can edit or customise a graph to be more useful to a viewer."
  },
  {
    "objectID": "PSYC121/Week4.html#section-1---customisation-of-data-plots",
    "href": "PSYC121/Week4.html#section-1---customisation-of-data-plots",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "",
    "text": "Step 1. Set up a folder for this week in the R Project that you created last week.\nStep 2. Bring the week_4_2023.zip file into R Studio server. Like last week, upload the zip file, and read in the data file. Launch the week_4 R script as before.\n{If you’ve done Step 1 &2 already as a pre-lab preparation, super, pat yourself on the back, skip these steps an move on)}\nStep 3. Once again, we’re gong to be using commands from the tidyverse library (the pipe operator is one example) so we need to ensure that it’s active. Run the command\nlibrary(tidyverse)\nStep 4. Read in the datafiles that will be on the server. There’s already a script line for this, you just need to change the file name (and we’ve done this in previous weeks)\nStep 5. We’ve provided a suggestion of how you can complete the visualisation challenge task from week 3.\nStep 6. Customize you graph work. We’ve provided some suggestions about adding titles and labels for your graph. Edit and play with the script lines to make them useful to you and to understand how they work. Note that the ggplot instructions have a similar structure / grammar to the group_by() instructions that we used: piping a data frame to a (here, plotting) function and piping that to an output or summarisation format.\n\nTry change the text, the colours, and so on of the graphs.\nAdd comments for yourself about what the different commands do. The idea is to learn by trying different things out (changing values, taking out elements of the command, putting other is) and record for yourself.\nIf you are struggling or not sure, try look at help files."
  },
  {
    "objectID": "PSYC121/Week4.html#section-2-z-scores",
    "href": "PSYC121/Week4.html#section-2-z-scores",
    "title": "4. Customisation of graphs, and z-scores",
    "section": "",
    "text": "Hint / Reminder: Sketch a normal (z score) distribution and mark the mean/mode, and mark off the relevant parts of the question so you know what you are trying to achieve and how to interpret any calculations you make.\n\n\nHint/ Guide 2. For questions 6 & 7, typically in psychology we use the 5% level as a cutoff to decide, in broadly described terms, whether something is extreme or unlikely vs. at least somewhat plausible or likely.\n\n\n\nz-score distributions\nQ1. What is the relationship between the sign of a z-score and its position in a distribution?\nQ2. If a distribution has a mean of 100 and a standard deviation of 10, what is the raw score equivalent to a z-score of 1.96?\nQ3. If a distribution has a mean of 157 and a standard deviation of 19, what is the raw score equivalent to a z-score of 1?\n\n\n\nQ4. What proportion of scores lie between the mean and a z-score of 0.5?\nQ5. What is the combined proportion of scores lying between z=-1.2 and z=.85?\n\n\n\nQ6. A Neuropsychologist has presented a test of face recognition to 200 neurotypical participants and finds that the scores are normally distributed with a mean of 85 and the standard deviation of 12. Two brain-damaged patients are also given the test. The one with right hemisphere brain damage scored 58 and the one with left hemisphere damage scored 67.\n\nWhat is the z score of the right hemisphere patient when compared to the neurotypical group?\nWhat proportion of neurotypical participants score lower that this patient?\nIs this patient likely to belong to the population of neurotypical participants? (justify your answer)\nWhat is the z score of the left hemisphere patient when compared to the neurotypical group?\nWhat proportion of neurotypical participants score lower than this patient?\nIs this patient likely to belong to the population of neurotypical participants? (justify your answer)\n\n\n\n\nCome back to this afterwards for some extra practice if you want:\nQ7. Tom Bunion has completed a huge research study and measured the foot size of men and women and found each to be normally distributed. The men have a mean size of 55 with a standard deviation of 5 and the women a mean of 33 and a standard deviation of 5. Joanna Toes has foolishly measured two individuals but forgotten to note their gender. These have foot sizes of 37 and 47. To which gender is each more likely to belong? What evidence is there for this?\n\n\n\nFor a bit of fun… The following are parody music videos about stats. Now that you have a few weeks’ experience with R Studion and also, an introduction to hypothesis testing, you might appreciate the following\nThe R Inferno Song (Teenage Dirtbag Parody) filmed largely on campus at Maynooth University, Ireland:\n\nHypothesis testing and p values (plus bunny rabbits and a dog)\n\n\n\n\nSome students have asked for a pointer to additional R resources so they can structure some time exploring the R system. There are lots, but this is good and very compatible with the teaching we provide: R for data science"
  },
  {
    "objectID": "PSYC121/Week2.html",
    "href": "PSYC121/Week2.html",
    "title": "2. Descriptive statistics in RStudio",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nDownload the lecture slides here"
  },
  {
    "objectID": "PSYC121/Week2.html#post---lab-recap-the-slides",
    "href": "PSYC121/Week2.html#post---lab-recap-the-slides",
    "title": "2. Descriptive statistics in RStudio",
    "section": "Post - lab recap: The slides",
    "text": "Post - lab recap: The slides\nWant to see the introduction slides that we used in the Levy lab? They are available here"
  },
  {
    "objectID": "PSYC121/index.html",
    "href": "PSYC121/index.html",
    "title": "Statistics for Psychologists I",
    "section": "",
    "text": "Welcome\nWelcome to the PSYC121 lab material for 2023!\nIn this module you will learn the basics of data handling, data processing and data visualisation. What that means is that, by the end of the this module (at Christmas time), you will be able to take a set of data, look at some basic statistics (e.g., the mean value), filter and process the data in order to answer basic questions about it, and present the data in an appealing way with different graphs. On top of this, you will be able to apply some of your knowledge of the basic “inferential” statistical tests that we will introduce in the lecture series (e.g., “t-test”).\nIn Week 1 we will introduce you to the software that we use to do all this useful work in statistics: “R” and “RStudio”. This is a coding language, and you will be taught the basics of how to write code in order to do all of the above key steps in data analysis. This tuition will continue in Term 2, and in your statistics modules in Year 2. Coding is challenging, but we know from experience that those students who attend classes, who work through the exercises carefully, and who seek help when they need it, do very well on these modules.\nMost of all, it’s important that you recognise that data analysis (statistics) is a critical aspect of the study of psychology. When we want to understand behaviour, we take measurements of that behaviour, which the majority of the time will result in quantitative (numerical) data. In order to understand the behaviour in a meaningful way, we need to conduct all of the above steps in our data analysis workflow. In summary, we cannot investigate psychological processes without the skills and toolbox of statistics and data analysis techniques.\n\n\nWorking at your own pace and seeking help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 1, Week 2, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our Graduate Teaching Assistants are there to help you. There are no “stupid questions” in statistics, so just ask the GTAs any question about what you’re doing. Likewise, ask the Lecturer.\nAsk on the Discussion Forum. On the PSYC121 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet 30+ other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\nAsking good questions - it’s really important that you give us as much information as you can when you ask your questions (in class and especially on the forum). It’s so much harder to help respond to “I can’t do Exercise 5 in Week 7” (because we don’t know why it is that you can’t do it) than for example “In Exercise 5 of Week 7, I’ve managed to read in the data, put the graph looks quite odd. Here is the code I’m using…”\n\n\nCourse Contacts\nIf you have something that needs to be private, then please feel free to email the academic staff at the email addresses below:\n\n\n\n\nEmail Address\n\n\n\n\nTom Beesley (Coordinator)\nt.beesley at lancaster dot ac dot uk\n\n\nJohn Towse\nj.towse at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Previous_Content/index.html",
    "href": "Previous_Content/index.html",
    "title": "Previous Conent",
    "section": "",
    "text": "This page will have links to previous years content, so that students can still go through stored content.\nWe would only need to keep two or three years worth as once they leave it isn’t imperative they have access to the old material, and they can see the new stuff if needed.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nWelcome to Lancaster University’s Department of Psychology 2023/2024 modules on Statistics for Psychologists. In the sidebar, you will find a complete list of all the statistics modules that are currently offered on this webpage. This is your one-stop shop for all the materials you need for working with R and statistics.\n\n\nAccessing the R Server\nTo log in to the R server, first make sure that you have the VPN switched on, or you will need to be connected to the university network (Eduroam). To set up the VPN, follow ISS instructions here or connecting to Eduroam here.\nWhen you are connected, navigate to https://psy-rstudio.lancaster.ac.uk, where you will be shown a login screen that looks like the below. Click the option that says “Sign in with SAML”.\n \nThis will take you through to the University login screen, where you should enter your username (e.g. ivorym) and then your university password. This will then redirect you to the R server where you can start using RStudio!\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have already logged in through the university login already, perhaps to get to the portal, then you may not see the username/password screen. When you click login, you will be redirected straight to RStudio. This is because the server shares the login information securely across the university.\n\n\n\n\nFAQs and Common Troubleshooting\n\n  \n    \n      \n        I can't access the server. It just loads and loads and then times out.\n      \n    \n    \n      If your web browser is constantly loading and timing out and never showing you the login for the R server, then it’s likely the issue is with the web connection. You need to make sure that you are either connecting to Lancaster’s Eduroam: https://portal.lancaster.ac.uk/ask/connect-eduroam/ or if you are off-campus, that you are connected to the VPN: https://portal.lancaster.ac.uk/ask/vpn/\n\nIf you are still having problems, it may be that the server is down, and you can check your others on the course to see if they have the same problems. If others are experiencing issues, get in touch with your module coordinator to get this looked at.\n    \n  \n  \n    \n      \n        My code doesn't work and keeps giving me errors. How do I fix this?\n      \n    \n    \n      Welcome to statistical programming. Try and carefully read the error codes to understand what the problem may be. You might be surprised to find out that the internet is an amazing resource for fixing your errors. Once you’ve checked it isn’t a typo, you can often copy-paste the error message into Google to see if others are having similar issues. Trusted resources include Stackoverflow, r-bloggers. The important thing is not to be afraid of errors, they’re trying to be helpful!\n\n    \n  \n  \n    \n      \n        Is the server down?\n      \n    \n    \n      Hopefully not, but maybe. If it is, then the error is likely a \"connection refused\" and may even say something about the server maybe being down. If this is the case, either wait a little while to see if we’re in the middle of booting it back up, or get in touch with your module coordinator to pass the message on to the R team.\n\n    \n  \n  \n    \n    \n      \n        Is there another way to use Rstudio without the R server?\n      \n    \n    \n      Yes! \n      You can also install R and Rstudio onto your own computer which has its advantages and disadvantages to using the R server. You can install R and Rstudio directly from Posit (https://posit.co/download/rstudio-desktop/), who develop and maintain Rstudio. You will need to install both, R is the programming language and Rstudio is the interface between you and the computer that runs R. The advantage of having your own installation of R and Rstudio (just referred to as Rstudio from here on in) is that *you* control the settings completely. \n\n\n\nYou can install new packages, set defaults, use specific versions of R and its libraries. In short, you have complete control over what you can do, which will lead to you becoming a better, more well-rounded data scientist (when we use R, we are data scientists as well as psychologists. You can wear many hats of expertise!). The disadvantage is that *you* are in control. If something goes wrong or doesn't install properly, it is up to you to resolve. As a department, we strongly recommend that you use the R server as your means of accessing Rstudio as we know that the server works, we have tested the teaching materials with the server and in labs we can help troubleshoot because we know that the version of R, the libraries, etc. are handled by us, we look after it so that you don't have to. A multitude of things can go wrong with a personal installation and you will need to fix this (which is part of being a well-rounded data scientist). If you ask for help with a local install, the first thing we will ask is \"does it work on the R server?\", if the answer is yes, then we can give some pointers but we cannot fix it for you (in my personal experience, I once spent 8+ hours of actively trying to fix a single issue with my Rstudio \\[okay, so it was quite complex an issue, but the point remains\\]). As you see, the advantage and disadvantage are intrinsically linked. \n\n\n\nFrom a teaching perspective, we cannot try and problem solve every person's individual and unique setup of Rstudio, there simply isn't enough time in a week. Yet the benefit of having your own version means you are totally unrestricted in what you can do with R, if you can imagine it, there is probably a set of libraries and functions that can help. If there isn't, you can make them! It is your choice for how to use Rstudio, but we recommend that you use the R server for the materials that we teach, but we provide this to complement and enhance the teaching experience. If you want to go beyond what is in the worksheets, then installing and using your own version of Rstudio is a very good first step\n    \n  \n  \n      \n    \n      \n        Where can I learn more about R and Rstudio outside of the labs?\n      \n    \n    \n      Great question. We can recommend looking at these books, R for Data Science, Advanced R, etc., as well as websites like StackOverflow, r-bloggers. Quite often, googling terms like \"r linear regression\" or \"r residuals for regression\" will help you find someone who has a tutorial and code to look at. Don’t be afraid to explore and adapt other people’s examples to work for you.\n    \n  \n  \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC121/Week1.html",
    "href": "PSYC121/Week1.html",
    "title": "Statistics for Psychologists",
    "section": "",
    "text": "Watch the introduction: Lecture Part 1\n\nWatch Lecture Part 2\n\nWatch Lecture Part 3\n\nWatch Lecture Part 4\n\nDownload the lecture slides here"
  },
  {
    "objectID": "PSYC121/Week1.html#task-1---check-in-with-the-university-attendance-register",
    "href": "PSYC121/Week1.html#task-1---check-in-with-the-university-attendance-register",
    "title": "Statistics for Psychologists",
    "section": "Task 1 - check-in with the University attendance register",
    "text": "Task 1 - check-in with the University attendance register\nWhen you arrive, make sure you have checked-in to your Analysis session in the Levy lab. All students are required by the University to confirm attendance at taught session\nStaff will remind you of this in your class."
  },
  {
    "objectID": "PSYC121/Week1.html#task-2---getting-dicy",
    "href": "PSYC121/Week1.html#task-2---getting-dicy",
    "title": "Statistics for Psychologists",
    "section": "Task 2 - Getting dicy",
    "text": "Task 2 - Getting dicy\n\nHere’s a simple task for you to complete as a group around each of the workstations;\nYou will be given a pair of dice\n\nWorking in pairs, one person rolls both dice.\nAdd up the total on each of them and have someone record that total (if you don’t have some spare paper or a pen, use your computer)\nRepeat those steps 20 times.\nThen swap over your roles (the person rolling the dice, the person recording the outcome)\nOnce everyone at the workstation has had a turn at this, each person should attempt to work out (a) the mean and (b) the median of their dice roll total.\nCheck each others working, and discuss any differences or problems you have.\n\nAre all your answers the same? Why / why not? If not, are they very different or very similar?"
  },
  {
    "objectID": "PSYC121/Week1.html#task-3---using-rstudio",
    "href": "PSYC121/Week1.html#task-3---using-rstudio",
    "title": "Statistics for Psychologists",
    "section": "Task 3 - Using RStudio",
    "text": "Task 3 - Using RStudio\n\nIntroducing R Studio\nR and RStudio is the software that we will be using to explore and learn about analysis in your Psychology degree. It’s a computational engine: a very snazzy calculator that you should see as your friend and ally in the journey to understand and appreciate psychology. It sits alongside what we teach about the concepts and interpretation of statistical analysis.\nR is the core software, RStudio is the interface for interacting with it. Put another way, R is the engine, RStudio is the cockpit.\nLike even a simplest calculator, it just does what you ask (at least when you ask nicely!) but it requires the user to know what they want from it and to understand what it is telling you. A calculator can’t help a kid get the right answer to a multiplication problem if they don’t know the difference between multiplication and division and addition etc. And whilst a calculator is brilliant at doing the number crunching (and as a bonus, R Studio can help with turning the numbers into beautiful graphs and images too), even a calculator requires a thoughtful person to take the answers and make sensible interpretations from them.\nTherefore, we need to learn both about the concepts of statistical analysis on the one hand, and the processing of statistical information -through R- on the other. The lectures will provide the starting point and the direction for statistical concepts, whilst these analysis labs provide the more practical experiences in how to use R, and how to make R your ally. Over the next year, in these labs we will increasingly be using RStudio to focus on the latter, processing side, which will allow you to focus your energies on the conceptual side and its relevance for appreciating psychology.\n\n\nGetting started with RStudio\nFor Lancaster University Psychology Students in 2023, we will be learning about R Studio through a simple but powerful web server architecture. That is, through the power of the internet, you can access and use R Studio by logging into a free account that we have provided and we will maintain for your use.\n\nHere’s a little secret: There are several different ways to access RStudio. For example, you can download a copy of the software onto your computer, or use a Virtual Machine set up to run a copy. There’s nothing to stop you having your local copy, but please note - we can’t support your own version through lab classes. We’re using the web server to make sure everyone has the same, controlled experience.\n\nTo log in to the R server, first make sure that you have the VPN switched on, or you will need to be connected to the university network (Eduroam). To set up the VPN, follow ISS instructions here or connecting to Eduroam here.\nWhen you are connected, navigate to https://psy-rstudio.lancaster.ac.uk, where you will be shown a login screen that looks like the below. Click the option that says “Sign in with SAML”.\n \nThis will take you through to the University login screen, where you should enter your username (e.g. ivorym) and then your university password. This will then redirect you to the R server where you can start using RStudio!\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have already logged in through the university login already, perhaps to get to the portal, then you may not see the username/password screen. When you click login, you will be redirected straight to RStudio. This is because the server shares the login information securely across the university.\n\n\n\n\nWhat does RStudio look like?\nWhen RStudio starts, it will look something like this: \nRStudio has three panels or windows: there are tabs for Console (taking up the left hand side), Environment (and History top right) , Current file (bottom right). You will also see a 4th window for a script or set of commands you develop, also (on the left hand side).\n\n\nLet’s get started!\nThe first thing we want to do in RStudio is to create a folder for this week so that we can put the relevant material there and keep it tidy.\nFrom the lower-right panel of RStudio, click the files tab.\nSelect the “new folder” option and create a new folder (eg “week 1”)\nClick on that folder to open it\nNext, we’ve prepared some instructions for RStudio to use - this is called a “script”. So we need to get this script into the server for you to explore and play with\n\nDownload the “zip” file by clicking this link\nFind the location of the file on your computer and check it is saved as a “.zip” file\nReturn to RStudio\nClick “Upload”\nClick choose file and find the file on your computer.\nSelect the file and click “Open”. Click “OK”\n\nYou should now see the files extracted in the directory.\nYou should now have the script available in RStudio.\nUse “Save…As” to create a new version of the script. By doing this, you’ll be able to have a “before” and “after” version of the script and can go back over the changes\nIn the script, select or highlight the first line of text, which is this one:\n\nRun your first ever R instruction!\n\n5 + 5\n\nand “run” this line. That tells RStudio to carry out the instruction.\nYou should see that in the console tab, RStudio calculates the answer to this incredibly hard maths challenge! (amazing huh? OK, maybe not *that* amazing…).\n\n\nModify your first ever R instruction!\nUse your imagination – add a new line to the script and ask a different simple arithmetic question of your own choosing! What happens?\n\n\nCalculate descriptive stats in R for the first time!\nIn this week’s analysis lecture, we looked at measures of central tendency and how to calculate them. So let’s get R to do these calculations also!\nFirst, we tell R about the data used in the lecture. We’ve already created the instruction that will do exactly this and it is in the script, so run this line from the script\n\nweek_1_lecture_data &lt;- c(7,8,8,7,3,1,6,9,3,8)\n\nThis creates an “object” called week_1_lecture_data. We can then perform calculations on this object. For example, we can find the mean by running the following command (use the script to do this)\n\nmean(week_1_lecture_data)\n\nCheck the answer is the same we found in the lecture (it should be 6!).\nNext, let’s ask for the median by running this line from the script:\n\nmedian(week_1_lecture_data)\n\nThis also should be the answer from the lecture (7)\nR doesn’t have a single corresponding command for the mode, but we can use the block of code in the script for this that starts and ends with the “getmode” text (there are 6 lines of text)\nThis is just a bit of clever jiggery-pokery that gets the mode. What does R say the mode is?\n\n\nYour challenge\nHow can you get RStudio to verify / check the dice calculations that you attempted earlier? Think about how you might solve this problem, on the basis of what we have covered so far.\nWe will discuss this in class and attempt to get RStudio to check your answers. In doing so, annotate the script (add notes for you - not RStudio) using the “#” command"
  },
  {
    "objectID": "PSYC121/Week1.html#before-you-finish",
    "href": "PSYC121/Week1.html#before-you-finish",
    "title": "Statistics for Psychologists",
    "section": "Before you finish",
    "text": "Before you finish\n\nMake sure you save a copy of the script that you have been working on by the end of the session. This provides you with the record - the digital trace - on what you have done. And it means you can come back and repeat any of the work you have performed.\nEnd your session on the RStudio server, this logs you out of the server and stops any ongoing activities and tasks you have set up, maybe in the background.\n\nThere is a red “power” button near the top right of the R studio window (do ask for help if you can’t find it). It’s a good habit to get into to turn the session off\n\n\nExtra content for outside the lab class\n\nIn the Howell text book on statistics, there’s some R code on descriptive statistics. It is included in the script for you to look at and play with.\nin your own time and think about the following:\n\nIn R, “&lt;-” is the assignment operator as in the command we used:\n\nPSYC121_week_1_data &lt;- c(7,8,8,7,3,1,6,9,3,8)\n\nWe create the variable label on the left (Analysis_week1_data) and we give it those numbers on the right. The nameAnalysis_week1_data is largely arbitrary: try use a variable of your own naming (your own name?) instead - and then use that alternative name for the other commands.\n\nThroughout this year, we’ll use the convention of the “underscore” to separate words in labels (it_makes_them_easier_to_read than ifyoudidn’thaveanyspaces)"
  },
  {
    "objectID": "PSYC121/Week1.html#task-4-review-the-learnr-sample-practice-questions",
    "href": "PSYC121/Week1.html#task-4-review-the-learnr-sample-practice-questions",
    "title": "Statistics for Psychologists",
    "section": "Task 4 – Review the learnr sample / practice questions",
    "text": "Task 4 – Review the learnr sample / practice questions\nAfter every block of teaching in part-1 analysis (specifically, we mean in week 5, week 10, week 15 and week 20) there will be a class test. This will assess your knowledge and your understanding of the material that has been covered.\nThe class test will comprise a set of Multiple Choice Questions (and the set of questions will be different for each student, as the test will involve random selection from a larger pool) under timed conditions.\nIn order to help you get (a) a broad or basic feel for the sort of questions you might get in the class test (b) self-review your progress through the term, we will provide MCQs each week for you to attempt.\nSo these are for your benefit… you can take the questions when you choose to, and the learnr quiz will provide feedback on the answers your provide. Just bear in mind:\n\nWe place a set of questions at the end of the learnr pages so that you can attempt these at the end of each week, after you’ve completed lab activities, follow-up work, weekly Q&As etc. But it’s up to you when you answer the questions\nThese are meant as indicative questions. There’s no point in learning/ memorising these questions (they won’t be on the quiz!) and our advice is to reflect on how the teaching and content links to the sorts of questions that get posed."
  },
  {
    "objectID": "PSYC121/Week1.html#task-5-data-collection-exercise",
    "href": "PSYC121/Week1.html#task-5-data-collection-exercise",
    "title": "Statistics for Psychologists",
    "section": "Task 5 – Data collection exercise",
    "text": "Task 5 – Data collection exercise\nIn order to learn about psychology and data analysis techniques, we need data! Rather than rely too much on artificial data (certainly it is sometimes useful to say “Here are a bunch of numbers and this is what we can do with them” – think about the R Studio example for this week’s lab) for the most part, we prefer to draw on datasets that are a bit more engaging and meaningful that you have a stake in yourself! By using a common data set, that we can return to over the year, we can also build up familiarity and confidence in the data and remove a potential obstacle to thinking about the more important analysis part.\nSo a key task will be for everyone to have a go at taking our online survey, and contribute to a dataset that can be used throughout the year.\nThe survey runs by following this link"
  },
  {
    "objectID": "PSYC121/Week1.html#post---lab-recap-the-slides-we-used",
    "href": "PSYC121/Week1.html#post---lab-recap-the-slides-we-used",
    "title": "Statistics for Psychologists",
    "section": "Post - lab recap: The slides we used",
    "text": "Post - lab recap: The slides we used\nWant to see again the introduction slides that we used in the Levy lab? They are available here"
  },
  {
    "objectID": "PSYC121/Week3.html",
    "href": "PSYC121/Week3.html",
    "title": "3. DVs and IVs in RStudio",
    "section": "",
    "text": "Note: due to to Uni-based technical issues these are last year’s videos and cannot be edited. They will be updated once system fixes are in place)\nWatch Part 1\n\nWatch Part 2\n\nWatch Lecture Part 3\n\nWatch Lecture Part 4\n\nDownload the lecture slides here\n\n\nLast week we asked you to\n\nUse a script to run instructions in RStudio\nPut data into RStudio form a data file and explore how to run descriptive stats\n\nThis week - again, there’s a learnr tutorial to follow and help prep for this week’s activities. You can find it here\n\n\n\nFor the weight of a cow data last week, we provided you with estimates data, and you were able to generate descriptive statistics for the estimates (if not, please go back and work through that part of the week 2 activity again). You also found the weight estimates for the female and non-female guesses, right?\nHowever, in order to find the estimates separately for gender identity, we needed to have a column for each gender category. Whilst that worked, it could get cumbersome over time always to work with data created like that.\nThere is a better way…\n\n\nStep 1. Create a project and a folder, and set the working directory. This is covered in the learnr tutorial so head over there if you need reminding.\nStep 2. Bring the week3.zip file into R Studio server. Like last week, upload the zip file, and launch the R script. You can get the file here\nStep 3. This week, we again want to explore commands from the tidyverse library (toolkit) which can help us do more powerful things more elegantly. So let’s get R to work again with the tidyverse library by running the code line\nlibrary(tidyverse)\nStep 4. Explore help() commands. R can give you more information about how it works.\nStep 5. Read or load the penelope data into R. That is what line 16 of the code is designed to do\ndata_object_name &lt;- read_csv(\"fill in\") # use your own dataobject_name and specify the file you want to work with\nbut note that you will need to edit this line -and ensure you are in the correct working directory- for this to be successful. Then have a look at it using the View() command in the script\nThis time, let’s ask for the estimate data arranged by identity:\naggregate(x = *MISSING*$estimate, by = list(*MISSING*$identity), FUN = mean)\nFirst, let’s try this (you will need to use your dataframe/variable name in place of MISSING). What do you get? Does this match what we did last week when we calculated the mean for the female and for the other (i.e., non-female) group?\nSecond, let’s look at what is happening here:\naggregate This is a command to call for descriptive statistics\nx= This defines what column we are analyzing\nby=list Now we tell R how to group the estimate data, and which column does that\nFUN=mean Specifies which descriptive function is being asked for Can you explore whether you can call on alternate measures?)\n\n\nThere’s another way that also allows us to group scores by a (nominal) variable. This is explored in the learnr tutorial, which should help you create the command the get weight estimates broken down by gender identity. You need to define the data frame for the estimates data, and the gender IV and the estimates DV\n*MISSING* %&gt;% group_by(*MISSING*) %&gt;% summarise(mean_estimate = mean(*MISSING*))\nFirst, try this command and see what you get. If you run this command as entered, it won’t work. So now use your experience at skills from the above and the learnr tutorial to work out what is required.\nNote\n%&gt;% This is called a “pipe operator”, basically take the output from the left and feed it into the requests on the right. Summarise Provide summary statistics information for the specified variable as specified (whether mean, median etc)\n\n\n\nAs well as learning about the pipe operator, we want to remind you /draw attention explicitly to another important element of the R command line syntax: the assignment operator. Uing a command such as\ncows &lt;- read_csv(\"penelope22.csv\")\nlooks for the csv datafile called ‘penelope22’, and assign it to an object or variable called ‘cows’\nWe could create any object name we wanted (within limits of names already known to RStudio). It isn’t just for reading in data files, we can perform a whole range of functions and assign them to an object.\n\n\n\nUsing aggregate and summarise may not seem like much progress, because they are just replicating what we had already done with mean() is week 2. However (a) this emphasizes that there are often several ways to get at the same thing in R (b) now we know about grouping, about working with 2-dimensional data, we can start to do more efficient and informative things.\nNow, let’s turn to the guesses made about median salary in the UK. We can get the data from the file wages2023.csv (you will need to adapt the code we used above for the weight estimation file so that it will load in the wages data, and in what follows the assumption is your new variable name is called wages)\nLet’s take a peek at the dataset with\nglimpse(wages)\nGlimpse pretty much does what you might think from the meaning of the word – it just gives us a data sample (handy because this is a much bigger dataset) and shows that we have 3 columns; uk_region (where someone lives, note ‘other’ probably equals Northern Ireland, Europe, China, etc), family_position (age relationship with siblings), and salary (estimate).\nBy the way, the govt statistics say the actual median income in 2022 was approx. £32,300 see this link\n\nWriting into your script, use the working “aggregate” commands from task 1 with the penelope weight data to find out the salary guesses as a function of where someone lives? That is, can you adapt that code for this problem? First, make sure you read in the data file into an R object.\nCan you use the aggregate command to find out salary guess as a function of family relationships? (if you are the youngest child maybe you have older siblings earning money that changes your evaluation?)\nCan you get a breakdown of guess as a function of BOTH UK region AND family relationship together?\nCan you use the group by() command to display salary guesses as a function of where someone lives? Check this gives you the same answer.\n\n\n\n\n\n\nDataset 3: Use the dataset of phone screen time usage, screentime2023.csv to further explore and consolidate the group_by() command (ie we’ll drop the aggregate command for this task to focus on group_by()). Use copy and paste to adapt the existing script lines from the above two tasks so that this time you read in and calculate screen time usage as a function of the type of phone. In other words, add line (and comments) to the scripts for this new task.\nUse RStudio to figure out the overall mean screen time usage estimate and the standard deviation. Calculate by hand what usage estimate would have a z score of z=-1.5?\n\n\n\n\nCan you find a way to visualise the screentime usage data that you have been working with above? The script provides two ways to consider doing this - boxplots (which we have looked at in script commands already) and ggplot, which we have spent less time with but is an extremely powerful engine for creating plots. We’ve provided the start of the code in each case, leaving you to work out the specifics. Remember to annotate your creations!\n\n\n\nRemember to complete your notes in the script, save the script file, and end the server session.\n\n\n\n\nWant to see the introduction slides used in the Levy lab? They are available here"
  },
  {
    "objectID": "PSYC121/Week3.html#pre-lab-work",
    "href": "PSYC121/Week3.html#pre-lab-work",
    "title": "3. DVs and IVs in RStudio",
    "section": "",
    "text": "Last week we asked you to\n\nUse a script to run instructions in RStudio\nPut data into RStudio form a data file and explore how to run descriptive stats\n\nThis week - again, there’s a learnr tutorial to follow and help prep for this week’s activities. You can find it here"
  },
  {
    "objectID": "PSYC121/Week3.html#r-studio-tasks",
    "href": "PSYC121/Week3.html#r-studio-tasks",
    "title": "3. DVs and IVs in RStudio",
    "section": "",
    "text": "For the weight of a cow data last week, we provided you with estimates data, and you were able to generate descriptive statistics for the estimates (if not, please go back and work through that part of the week 2 activity again). You also found the weight estimates for the female and non-female guesses, right?\nHowever, in order to find the estimates separately for gender identity, we needed to have a column for each gender category. Whilst that worked, it could get cumbersome over time always to work with data created like that.\nThere is a better way…\n\n\nStep 1. Create a project and a folder, and set the working directory. This is covered in the learnr tutorial so head over there if you need reminding.\nStep 2. Bring the week3.zip file into R Studio server. Like last week, upload the zip file, and launch the R script. You can get the file here\nStep 3. This week, we again want to explore commands from the tidyverse library (toolkit) which can help us do more powerful things more elegantly. So let’s get R to work again with the tidyverse library by running the code line\nlibrary(tidyverse)\nStep 4. Explore help() commands. R can give you more information about how it works.\nStep 5. Read or load the penelope data into R. That is what line 16 of the code is designed to do\ndata_object_name &lt;- read_csv(\"fill in\") # use your own dataobject_name and specify the file you want to work with\nbut note that you will need to edit this line -and ensure you are in the correct working directory- for this to be successful. Then have a look at it using the View() command in the script\nThis time, let’s ask for the estimate data arranged by identity:\naggregate(x = *MISSING*$estimate, by = list(*MISSING*$identity), FUN = mean)\nFirst, let’s try this (you will need to use your dataframe/variable name in place of MISSING). What do you get? Does this match what we did last week when we calculated the mean for the female and for the other (i.e., non-female) group?\nSecond, let’s look at what is happening here:\naggregate This is a command to call for descriptive statistics\nx= This defines what column we are analyzing\nby=list Now we tell R how to group the estimate data, and which column does that\nFUN=mean Specifies which descriptive function is being asked for Can you explore whether you can call on alternate measures?)\n\n\nThere’s another way that also allows us to group scores by a (nominal) variable. This is explored in the learnr tutorial, which should help you create the command the get weight estimates broken down by gender identity. You need to define the data frame for the estimates data, and the gender IV and the estimates DV\n*MISSING* %&gt;% group_by(*MISSING*) %&gt;% summarise(mean_estimate = mean(*MISSING*))\nFirst, try this command and see what you get. If you run this command as entered, it won’t work. So now use your experience at skills from the above and the learnr tutorial to work out what is required.\nNote\n%&gt;% This is called a “pipe operator”, basically take the output from the left and feed it into the requests on the right. Summarise Provide summary statistics information for the specified variable as specified (whether mean, median etc)\n\n\n\nAs well as learning about the pipe operator, we want to remind you /draw attention explicitly to another important element of the R command line syntax: the assignment operator. Uing a command such as\ncows &lt;- read_csv(\"penelope22.csv\")\nlooks for the csv datafile called ‘penelope22’, and assign it to an object or variable called ‘cows’\nWe could create any object name we wanted (within limits of names already known to RStudio). It isn’t just for reading in data files, we can perform a whole range of functions and assign them to an object.\n\n\n\nUsing aggregate and summarise may not seem like much progress, because they are just replicating what we had already done with mean() is week 2. However (a) this emphasizes that there are often several ways to get at the same thing in R (b) now we know about grouping, about working with 2-dimensional data, we can start to do more efficient and informative things.\nNow, let’s turn to the guesses made about median salary in the UK. We can get the data from the file wages2023.csv (you will need to adapt the code we used above for the weight estimation file so that it will load in the wages data, and in what follows the assumption is your new variable name is called wages)\nLet’s take a peek at the dataset with\nglimpse(wages)\nGlimpse pretty much does what you might think from the meaning of the word – it just gives us a data sample (handy because this is a much bigger dataset) and shows that we have 3 columns; uk_region (where someone lives, note ‘other’ probably equals Northern Ireland, Europe, China, etc), family_position (age relationship with siblings), and salary (estimate).\nBy the way, the govt statistics say the actual median income in 2022 was approx. £32,300 see this link\n\nWriting into your script, use the working “aggregate” commands from task 1 with the penelope weight data to find out the salary guesses as a function of where someone lives? That is, can you adapt that code for this problem? First, make sure you read in the data file into an R object.\nCan you use the aggregate command to find out salary guess as a function of family relationships? (if you are the youngest child maybe you have older siblings earning money that changes your evaluation?)\nCan you get a breakdown of guess as a function of BOTH UK region AND family relationship together?\nCan you use the group by() command to display salary guesses as a function of where someone lives? Check this gives you the same answer.\n\n\n\n\n\n\nDataset 3: Use the dataset of phone screen time usage, screentime2023.csv to further explore and consolidate the group_by() command (ie we’ll drop the aggregate command for this task to focus on group_by()). Use copy and paste to adapt the existing script lines from the above two tasks so that this time you read in and calculate screen time usage as a function of the type of phone. In other words, add line (and comments) to the scripts for this new task.\nUse RStudio to figure out the overall mean screen time usage estimate and the standard deviation. Calculate by hand what usage estimate would have a z score of z=-1.5?\n\n\n\n\nCan you find a way to visualise the screentime usage data that you have been working with above? The script provides two ways to consider doing this - boxplots (which we have looked at in script commands already) and ggplot, which we have spent less time with but is an extremely powerful engine for creating plots. We’ve provided the start of the code in each case, leaving you to work out the specifics. Remember to annotate your creations!\n\n\n\nRemember to complete your notes in the script, save the script file, and end the server session."
  },
  {
    "objectID": "PSYC121/Week3.html#post---lab-recap-the-slides",
    "href": "PSYC121/Week3.html#post---lab-recap-the-slides",
    "title": "3. DVs and IVs in RStudio",
    "section": "",
    "text": "Want to see the introduction slides used in the Levy lab? They are available here"
  },
  {
    "objectID": "PSYC121/Week5.html",
    "href": "PSYC121/Week5.html",
    "title": "5. Class test",
    "section": "",
    "text": "Formulae for weeks 1-4\nHere you can download a list of the formulae used in the first half of this module.\nThere are no other materials for this week!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "PSYC121/Week7.html",
    "href": "PSYC121/Week7.html",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nWatch Part 4\n\nDownload the lecture slides here\n\n\nChapter 12 of Howell\nToday we will look in a bit more detail at people’s estimates of the average UK salary. We will first plot this data using geom_histogram() and also geom_boxplot(). When we do this, we’ll see that there are some unusual values, and we’ll need to do a bit of data wrangling to remove them, using the filter() command. We’ll then turn to the conceptual ideas of the lecture - how can we tell if the mean of our sample is unusual, or whether we would actually expect this mean value under the null hypothesis? Finally, we’ll continue to develop our skills in data visualisation by exploring geom_density() plots."
  },
  {
    "objectID": "PSYC121/Week7.html#reading",
    "href": "PSYC121/Week7.html#reading",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "",
    "text": "Chapter 12 of Howell\nToday we will look in a bit more detail at people’s estimates of the average UK salary. We will first plot this data using geom_histogram() and also geom_boxplot(). When we do this, we’ll see that there are some unusual values, and we’ll need to do a bit of data wrangling to remove them, using the filter() command. We’ll then turn to the conceptual ideas of the lecture - how can we tell if the mean of our sample is unusual, or whether we would actually expect this mean value under the null hypothesis? Finally, we’ll continue to develop our skills in data visualisation by exploring geom_density() plots."
  },
  {
    "objectID": "PSYC121/Week7.html#task-3---sample-size-size-of-effect-and-the-one-sample-t-test",
    "href": "PSYC121/Week7.html#task-3---sample-size-size-of-effect-and-the-one-sample-t-test",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "Task 3 - Sample size, size of effect, and the one sample t-test",
    "text": "Task 3 - Sample size, size of effect, and the one sample t-test\nIn the lecture this week, Tom used an application to show the process of sampling data. You can access this application at the link below. There are three “parameters” you can change in this:\n\nThe true mean of the effect: Think of this like the bias that was set up in your deck of cards last week. There is some true state out there in the world, and we are going to draw samples from a distribution of data that has a mean that equals this value. If you make this 100, then the true mean is equal to that under the null hypothesis (there is no effect).\nThe standard deviation of the data: This sets how variable the data are in this population. If the data are more variable, then our samples will produce estimations that are less accurate of the true mean value.\nThe sample size: How many observations are drawn in the sample. These are represented by the yellow circles in the plot.\n\nEach time you draw a sample the data points are plotted in yellow and the mean of the sample is marked with the red line. The application also runs a one-sample t-test against the expected mean under the null hypothesis, of 100. The null hypothesis is also represented by the static distribution presented in grey, centred on 100.\nThings to try:\n\nStart with a sample size of 10, and a mean of the effect of 110 (SD = 15). How often do you get a significant result (p &lt; .05) when you draw a new sample?\nNow try changing the mean of the effect to 120. Does this increase or decrease the likelihood of getting significant results? What about changing to 130?\nNow keep the mean effect constant (say 110), but increase the sample size. Try 5, then 10, 15, and so on. Does this increase or decrease the likelihood of getting significant results?\nSet the mean of the effect to 100 and the sample size to 10. Keep drawing new samples, noting each time the p value. You will evenutally get a p value of &lt; .05. What type of error is this?\n\nClick here for the one-sample t-test application\n\nTask 4 - Practising filtering\n\nFiltering is very useful for selecting certain sub-sets of our data. Here we have given you an example of how we select a sub-set of data based on two conditions from two different columns:\n\n\nname_of_the_data_object %&gt;% \n  filter(home_location_in_UK == \"NW\" & sibling_order == \"oldest\")\n\nWe have given you a few different columns to look at and to use in practicing your filter commands:\n\nsibling_order: what position in age was the respondent within their siblings\nhome_location: UK / Asia / Europe, etc\nhome_location_in_UK: NW, NE, etc (NA is non-UK residents)\nattention_check: respondents were asked “click strongly agree to show you are paying attention” - some people failed this!!!\n\nGain some skills in filtering by trying to complete the following filters. Use the filtered data object that has 130 rows. We’ve put in () the number of rows you should see in the resulting object, after the filter.\n\nJust those people who come from the North East (15 rows)\nThose people who come from South East and are an only child within their siblings (7 rows)\nThose people who failed the attention check (17 rows)\nThose people passed the attention check, are from the UK, and are the oldest child (30 rows)\nThose people who are NOT from the North West (hint: you’ll need to use !=) (64 rows)\nThose people who are from the South East or (|) the South West (33 rows)"
  },
  {
    "objectID": "PSYC121/Week7.html#week-7-quiz",
    "href": "PSYC121/Week7.html#week-7-quiz",
    "title": "7. Filtering data and testing means (one-sample t-test)",
    "section": "Week 7 Quiz",
    "text": "Week 7 Quiz\nYou can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC122/index.html",
    "href": "PSYC122/index.html",
    "title": "Statistics for Psychologists II",
    "section": "",
    "text": "Welcome\nWelcome to PSYC122!\nThis module builds on the knowledge and skills acquired in Statistics for Psychologists 1 (PSYC121). You will continue to practise data handling, data processing and data visualisation, using R and R Studio. In addition, you will learn about statistical methods to test whether two (or more) variables are associated and how to implement those methods in R and R Studio.\nWatch the video below (~ 5 minutes) to get a short overview of the topics we will cover in weeks 11 to 15.\n\nThis page gives you access to all the materials that you will need. You will have timetabled lab classes during which you are expected to work through a series of exercises to practise that week’s material. Before you come to your lab session, you should watch the lectures for that week, read the relevant book chapter and complete the pre-lab activities. Following all that and to check that you’ve understood the week’s materials, you can complete a quick quiz.\nThere will be class tests in weeks 15 and 20. These take place, in person, during your regular lab session.\n\n\nAsking for help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 11, Week 12, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our Graduate Teaching Assistants are there to help you. There are no “stupid questions” in statistics, so just ask the GTAs any question about what you’re doing. Likewise, ask the Lecturer.\nAsk on the Discussion Forum. On the PSYC122 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet 30+ other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nMargriet Groen\nm.groen at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies1 at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Test/Presentation/index.html#introduction-1",
    "href": "Test/Presentation/index.html#introduction-1",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Introduction #1",
    "text": "Introduction #1\n\nSoftware development is more than just the technical implementation, it is a blend of social, cognitive, and technical mechanisms\nPsychology can offer insights into the individual differences and human behaviours within secure coding\nDespite best efforts by the software engineering community, developers still write insecure code!\nBy applying psychological perspectives to secure coding, we can better address security challenges"
  },
  {
    "objectID": "Test/Presentation/index.html#introduction-2",
    "href": "Test/Presentation/index.html#introduction-2",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Introduction #2",
    "text": "Introduction #2\n\nWe collected data from a sample of software engineers and examined their perceptions of risk when considering software security\nThey told us about their behaviours and perspective on security within their work, as well as completed a battery of cognitive tests\nWe applied a mixed-analysis: a thematic analysis, and a quantitative modelling process\nTwo papers, one submitted to ACM Transactions on Computer-Human Interaction and the other to APA Technology, Mind & Behaviour"
  },
  {
    "objectID": "Test/Presentation/index.html#methods",
    "href": "Test/Presentation/index.html#methods",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Methods",
    "text": "Methods\n\n\n\n145 participants\n\n73 professional freelancers\n72 CS students\n\n\n\n\nParticipants completed four main parts:\n\nOWASP vulnerability task\nCognitive reflection test\nGambling task\nFour qualitative rich-text questions"
  },
  {
    "objectID": "Test/Presentation/index.html#owasp-vulnerability-task-ovt",
    "href": "Test/Presentation/index.html#owasp-vulnerability-task-ovt",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "OWASP Vulnerability Task (OVT)",
    "text": "OWASP Vulnerability Task (OVT)\n\nA measure of optimism bias\nIndividuals often underestimate the likelihood of negative events affecting them [14, 15]\nUses OWASP 2021 top 5: Injection flaws, Broken Authentication, Sensitive Data Exposure, XML External Entity flaws and Broken Access Control\nEstimate the likelihood of a vulnerability existing in applications released by the “average developer”\nEstimate the likelihood of themselves introducing these vulnerabilities\nThe \\(\\Delta\\) of average and individual scores gives an indication of potential biased perspectives. A score of 75 for average developers and 50 for myself gives a score of 25, suggesting I expect my work to be better than the average developer."
  },
  {
    "objectID": "Test/Presentation/index.html#cognitive-reflection-test-crt",
    "href": "Test/Presentation/index.html#cognitive-reflection-test-crt",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Cognitive Reflection Test (CRT)",
    "text": "Cognitive Reflection Test (CRT)\n\n\n\n\n\nPhotograph: Getty Images\n\n\n\n“A bat and a ball cost £1.10 in total. The bat costs £1.00 more than the ball. How much does the ball cost?”\n\n\n\n5p\n\n\n\n\nA measure of system 2 processing [5], an aspect of dual processing theory [4]\n\n\n\n\nDual Processing Theory\n\nTwo systems of cognitive processing\n\nSystem 1: intuitive and automatic\nSystem 2: reflective and deliberate"
  },
  {
    "objectID": "Test/Presentation/index.html#gambling-task",
    "href": "Test/Presentation/index.html#gambling-task",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Gambling Task",
    "text": "Gambling Task\n\nA measure used by [5] to assess risk aversion.\nRisk aversion can be linked to prospect theory, which suggests decisions maximise gains and minimise losses [10].\nPeople experience negativity from a loss more strongly than positivity from gains. Accordingly, people typically make choices that minimise loss over maximising gain [11].\n“Gain £1,000 for sure or a 90% chance of £5,000” - Gain frame\n“Lose £100 for sure or a 75% chance to lose £200” - Loss frame"
  },
  {
    "objectID": "Test/Presentation/index.html#qualitative-questions",
    "href": "Test/Presentation/index.html#qualitative-questions",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Qualitative Questions",
    "text": "Qualitative Questions\n\n\n\n\n\n\n\n\n\nNumber\nQuestion\n\n\n\n\n1\nDescribe a time when you successfully developed and released/launched a software project, either in a professional or personal capacity. This could be a recent example, or a project you were particularly proud of.\n\n\n2\nWhen considering the process of developing and launching software/web applications, what is at risk of potentially going wrong and how could these risks affect you?)\n\n\n3\nIf you were to consider software development as a series of ‘gambles’ (decisions that confer possible risk), what gambles would be considered worthwhile or worth a risk during the process of developing software? Why?\n\n\n4\nWhat approaches or considerations, do you, or your team, take when aiming to identify potential risks or security vulnerabilities when developing software? What is the reasoning behind these decisions?"
  },
  {
    "objectID": "Test/Presentation/index.html#the-roar-of-software-security",
    "href": "Test/Presentation/index.html#the-roar-of-software-security",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "The ROAR of software security",
    "text": "The ROAR of software security\nHow Responsibility, Optimism And Risk shape developers’ security perceptions\n\n\n\nA thematic analysis of the qualitative responses [2]\nTwo psychological theories were found which helped explain the findings:\n\nthe Social Identity Approach [1, 6].\nHeuristics and Biases [9].\n\n\n\n\n\n\nGroupings of themes and subthemes seen\n\n\n\n\n\nSocial identities are not congruent with typecasts, but are fluid, self-defined group memberships to allow individuals to associate with others who share emotionally significant norms and values\nHeuristics are cognitive “shortcuts” people rely upon during decision making. Heuristics make use of frameworks and cognitively simple processes to make intuitive, instinctive judgments"
  },
  {
    "objectID": "Test/Presentation/index.html#responsibility-and-social-identity",
    "href": "Test/Presentation/index.html#responsibility-and-social-identity",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Responsibility and Social Identity",
    "text": "Responsibility and Social Identity\n\n\n\nTom Gauld\n\n\n\n\nDiffusion - when individuals view themselves as parts of a chain where an assumption of responsibility is made for others\n\nDisplacement - where responsibility is passed upwards through hierarchies, such as towards team leaders or managers\n\nAcceptance - where people take responsibility for their actions, their work, and the consequences.\n\n\n\nDiffusion\n\nPushing responsibility to others deemed as outsiders\nA shared identity can invoke trust, but this can be abused by those who feel less as part of the group\nTools/software can represent other engineers, increasing people’s reliance. Official sources can be seen as an ingorup member\nAccountability can reduce diffusion, particularly towards outgroups\n\nDisplacement\n\nLanguage can indicate an ingroup/outgroup relationship\nThose in positions of management highlight their feelings of responsibility\nPeople can assume senior employees are there to double check work\nPolicies can also be used to displace\nClients and stakeholders can be assumed to have ultimate responsibility\n\nAcceptance\n\nA key factor is moral/emotional connections\nOr via social values, such as empathy\nAnd even expressing caution about using third party software or tools"
  },
  {
    "objectID": "Test/Presentation/index.html#optimism",
    "href": "Test/Presentation/index.html#optimism",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Optimism",
    "text": "Optimism\n\nOptimism was commonly associated with risk mitigation, representing a potentially idealistic view on resolving these issues. Unrealistic optimism biases manifest in different ways, from planning fallacies to over-optimism that security is good enough.\nOthers refuse the possibility they may be victims\nDevelopers expressing an optimism bias often spoke about security and risk in absolutes and dismissed uncertainty or insecure code as issues of other developers, but not for themselves."
  },
  {
    "objectID": "Test/Presentation/index.html#risk",
    "href": "Test/Presentation/index.html#risk",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Risk",
    "text": "Risk\n\n\n\nAppetite - Risk appetites can be defined as passive or active. Active decisions intentionally reduce efforts in specific areas, and passive decisions increase risk through a reduction of attention\n\n Mitigation - Mitigation of risk was mainly mentioned alongside planning and testing\n\nDirection - could be directed towards or away from an individual. The direction is linked to the emotional/moral language associated\n\n\n\n\nPassive and Active risk appetites were seen\nPassive appetites are centred ons ecurity, such as delaying its inclusion\nTime constraints and technical debts alter active appetites, with greater risks being considered acceptable\n\nDirection\n\nRisks could be directed away or towards the individual\nRisk to others was typically presented without any personal emotional connection.\nExperiencing failures or having to abandon projects due to self-directed risks could challenge a developer’s perception of their competence"
  },
  {
    "objectID": "Test/Presentation/index.html#discussion",
    "href": "Test/Presentation/index.html#discussion",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Discussion",
    "text": "Discussion\n\n\nResponsibility can be linked to an organisation’s security culture, with managers playing a key role in motivating developers to consider the real-world implications and impact of insecure software\nGaining different perspectives on the development process may reduce biases through increased communication and reflection. For solo workers, increasing communication with clients and stake- holders may provide similar benefits.\nPassive risk appetites and poor risk mitigation strategies are likely linked with intuitive system 1 processing and less reflective thinking.\nSocial identities assumed by software developers can have a profound impact on their feelings of responsibility and motivation towards their role in the development process."
  },
  {
    "objectID": "Test/Presentation/index.html#recognising-the-known-unknowns",
    "href": "Test/Presentation/index.html#recognising-the-known-unknowns",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Recognising the known unknowns",
    "text": "Recognising the known unknowns\nThe interaction between reflective thinking and optimism for uncertainty among software developer’s security perceptions\n\nA quantitative analysis of the cognitive battery and a content analysis of the rich-text\nWe found an interaction between cognitive reflection and optimism associated with the presence of uncertainty-related language (reflecting risk sensitivity)"
  },
  {
    "objectID": "Test/Presentation/index.html#reflection-and-optimism",
    "href": "Test/Presentation/index.html#reflection-and-optimism",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Reflection and Optimism",
    "text": "Reflection and Optimism\n\nOverly optimistic outlooks combined with higher cognitive reflection drives up expressions of uncertainty, while pessimistic or realistic individuals reduce uncertainty as cognitive reflection increases."
  },
  {
    "objectID": "Test/Presentation/index.html#discussion-1",
    "href": "Test/Presentation/index.html#discussion-1",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Discussion",
    "text": "Discussion\n\nThe finding that cognitive reflection or optimism alone explain very little variance in security perceptions highlights the entangled nature of cognition in the real-world\nOverly optimistic software engineers view additional security implementation as holding minimal value, as they believe their current level of security to be sufficient. When considering security, therefore, they may require stronger cues or framing to activate system 2 when making security decisions\nOne catalyst for system 2 thinking during secure decision making might be peer communication, which allows for the balancing of perspectives and a reduction of biases.\nThe use of rewards, either intrinsic or extrinsic, for encouraging secure coding behaviours can be used to increase motivation and subsequently increase task performance.\n\n\nintrinsic rewards are those internal to the individual and are inherently found in the task itself and upon completion, and extrinsic rewards are external to the task, such as pay or recognition\nThe exact nature of verifying secure coding practices on freelance platforms is beyond the scope of this paper, but if a system can be devised that is universally trusted and easily implementable, then the use of gamification may work as a reward system."
  },
  {
    "objectID": "Test/Presentation/index.html#where-am-i-going-from-here",
    "href": "Test/Presentation/index.html#where-am-i-going-from-here",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Where am I going from here?",
    "text": "Where am I going from here?\n\nThe next stage is to assess these measures of cognition (CRT, OVT, intuitive processing) against secure code comprehension\nUsing a paradigm designed by Oliveira et al. (2018) [12] and tested in Python and Java [3], we will see whether aspects of cognition will associate with error detection.\nOliveira and colleagues posited that code vulnerabilities occupy a cognitive blindspot [13] but haven’t applied any measures of cognition relating to heuristics/cognitive processing styles\nWe would expect greater comprehension and error detection from those who score highly on CRT, lower on optimism measures, greater rational processing styles, lower intuitive processing styles, but no difference for expertise, familiarity, or cybersecurity knowledge"
  },
  {
    "objectID": "Test/Presentation/index.html#thank-you",
    "href": "Test/Presentation/index.html#thank-you",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "Thank You",
    "text": "Thank You\nThank you! Any questions?\n matthew.ivory@lancaster.ac.uk\nSlides are here: https://www.lancaster.ac.uk/staff/ivorym/ROAR\nSocial Paper: https://psyarxiv.com/pexvz/ [7]\nCognitive Paper: https://psyarxiv.com/vrf97 [8]"
  },
  {
    "objectID": "Test/Presentation/index.html#references",
    "href": "Test/Presentation/index.html#references",
    "title": "Responsibility, Reflection, and Biases in Secure Coding",
    "section": "",
    "text": "[1] Abrams, D. and Hogg, M. 1990. An Introduction to the Social Identity Approach. Social identity theory: Constructive and critical advances. Harvester Wheatsheaf. 1–9.\n\n\n[2] Braun, V. and Clarke, V. 2006. Using thematic analysis in psychology. Qualitative research in psychology. 3, 2 (2006), 77–101. DOI:https://doi.org/10.1191/1478088706qp063oa.\n\n\n[3] Brun, Y. et al. 2022. Blindspots in Python and Java APIs Result in Vulnerable Code. ACM Transactions on Software Engineering and Methodology. (Nov. 2022). DOI:https://doi.org/10.1145/3571850.\n\n\n[4] Evans, J.St.B.T. 2003. In two minds: dual-process accounts of reasoning. Trends in Cognitive Sciences. 7, 10 (Oct. 2003), 454–459. DOI:https://doi.org/10.1016/j.tics.2003.08.012.\n\n\n[5] Frederick, S. 2005. Cognitive reflection and decision making. Journal of Economic perspectives. 19, 4 (2005), 25–42. DOI:https://doi.org/10.1257/089533005775196732.\n\n\n[6] Haslam, A. 2012. The Social Identity Approach. Psychology in Organizations: The Social Identity Approach. SAGE Publications Ltd. 17–39.\n\n\n[7] Ivory, M. et al. 2023. Can you hear the ROAR of software security? How Responsibility, Optimism And Risk shape developers’ security perceptions. PsyArXiv.\n\n\n[8] Ivory, M. et al. 2023. Recognising the known unknowns; the interaction between reflective thinking and optimism for uncertainty among software developer’s security perceptions. PsyArXiv.\n\n\n[9] Kahneman, D. et al. eds. 1974. Judgment under uncertainty: Heuristics and biases. Cambridge University Press.\n\n\n[10] Kahneman, D. and Tversky, A. 1979. Prospect Theory: An Analysis of Decision under Risk. Econometrica. 47, 2 (1979), 263–291. DOI:https://doi.org/10.2307/1914185.\n\n\n[11] Levy, J.S. 1992. An Introduction to Prospect Theory. Political Psychology. 13, 2, (1992), 171–186.\n\n\n[12] Oliveira, D.S. et al. 2018. {API} Blindspots: Why Experienced Developers Write Vulnerable Code. (Baltimore, MD, USA, 2018), 315–328.\n\n\n[13] Oliveira, D.S. et al. 2014. It’s the psychology stupid. Proceedings of the 30th Annual Computer Security Applications Conference (New Orleans, LA, USA, 2014), 296–305.\n\n\n[14] Sharot, T. 2011. The optimism bias. Current Biology. 21, 23 (Dec. 2011), R941–R945. DOI:https://doi.org/10.1016/j.cub.2011.10.030.\n\n\n[15] Weinstein, N.D. 1980. Unrealistic optimism about future life events. Journal of Personality and Social Psychology,. 39, 5 (1980), 806–820. DOI:https://doi.org/10.1037/0022-3514.39.5.806."
  },
  {
    "objectID": "PSYC121/Week6.html#week-7-quiz",
    "href": "PSYC121/Week6.html#week-7-quiz",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Week 7 Quiz",
    "text": "Week 7 Quiz\nYou can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC121/Week6.html#week-6-quiz",
    "href": "PSYC121/Week6.html#week-6-quiz",
    "title": "6. Sampling, probability and binomial tests",
    "section": "Week 6 Quiz",
    "text": "Week 6 Quiz\nYou can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC121/Week9.html",
    "href": "PSYC121/Week9.html",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "Watch Part 1\n\nWatch Part 2\n\nWatch Part 3\n\nWatch Part 4\n\nDownload the lecture slides here\n\n\nChapter 14 of Howell\n\n\n\nOnline tutorial: You must make every attempt to complete this before the lab! To access the pre-lab tutorial click here (on campus, or VPN required)\nGetting ready for the lab class\nCreate a folder for Week 9 and download the Week_9 csv file file and upload it into this new folder in RStudio Server.\n\n\n\n\n\nIn this class we will be exploring some data on people’s estimations on aspects of the UK population. We asked people 4 different questions:\n\nOut of every 100 people, about how many do you think are:\n\n\n\nChristian?\nMuslim?\nOver the age of 65?\n\n\nWe also asked a related question about immigration:\n\nWhat percentage of the UK population do you think are immigrants to this country? (i.e. not born in UK)\n\n\nCreate a new R Markdown document for Week 9.\nIn the first chunk add library(tidyverse) and create a new data object by using read_csv() to read “data_wk9.csv”.\nYou can view the data by clicking on it in the environment. Note that in previous weeks we’ve used the view() command in our scripts (which does the same thing), but that can conflict with knitting the .Rmd file.\nTake a look at the summary statistics for all of the columns in our data using summary(your_data_object_name)\n\nTo what extent are people’s estimations of these population parameters related? Let’s look at this by plotting these data as geom_point().\n\nCopy the following code. Edit it to map one of the numeric columns in the data to x and another numeric column to y. You can pick any of the columns you like, but it’s important that you understand what research question you are asking with your choice. For example, you might be asking “Do people who estimate that there are more Christians in the population also think there are more Muslims in the population?”\n\n\ndata_object_name %&gt;% \n  ggplot(aes()) + # map two of the columns to x and y\n  geom_point() # you can change the size or colour of the points if you wish\n\n\nConsider the graph, noting any general pattern/trend in the data. Is there a postive relationship: do people who give high estimations for one variable tend to give high estimations for the other variable? Or is there a negative relationship: do people who give high estimations for one variable tend to give lower estimations for the other variable? Or is there no discernible relationship at all?\nWrite a statement after this code chunk to briefly make a comment about any pattern you see in the data (or absence of a pattern).\nCopy this code into new chunks and explore relationships between the other numeric variables, each time noting the research question you are asking, and discussing with people on your table what kind of relationship you can see in the data. Write some comments in your R Markdown document to describe the patterns you are seeing.\n\n\n\n\n\nYou may have noticed that there are some fairly extreme values in some of these numeric estimations of the population. As we’ve discussed in previous weeks, these outlier values can be problematic when we run our statistical tests, so (like last week) we probably want to control their influence by removing them. As you saw in your online tutorial, we can convert the data to z scores, and then remove z values above and below certain values.\nLet’s create a “z-transform column” called z_imm for the estimates of the percentage of immigrants. Complete the code below by changing the data object names and adding the relevant variable (column) name. Note that you may want to assign the result (&lt;-) to a new data object at this point.\n\n\n# use mutate and scale to create z-scores of immigration estimates\nnew_data_object_name &lt;- \n  data_object_name %&gt;% \n  mutate(z_imm = scale(column_name))\n\n\nView the new data object to check this column has been created correctly. Like in the online tutorial, it would be a good idea to calculate some descriptive statistics for this new column to check it conforms to what we know about z-scores (e.g., mean() = 0, give or take some rounding, and sd() = 1).\n\n\n# check the mean and sd of the new column\nmean(data_object_name$column_name)\nsd(data_object_name$column_name)\n\n\nWe know from our earlier lectures on the z distribution that values of greater than 2 (or less than -2) reflect around 5% of the distribution, and values greater than 3 (or less than -3) represent less than 1% of the distribution:\n\n\n\nLet’s consider an outlier any value that has a z of 2.5 (a conventional cutoff). Plot a histogram of the z_imm column in order to inspect whether there are data that are above 2.5 or below -2.5.\n\n\n# histogram of the z_imm column\n\n# eh, what, no code? Come on...you've got this!!! \n# start with the data, pipe, then ggplot\n# if you get really stuck, look back at last week\n\n\nAdd a filter command to remove the values in the z_imm column are greater than 2.5 or less than -2.5. That means you’ll need two separate statements with an & in the middle\n\n\n# add a filter command\ndata_object_filtered &lt;- \n  data_object_name %&gt;% \n  filter(first_expression_here & second_expression_here) \n\n\nYou should have removed 3 rows of data. Make a note of this in your R markdown document.\n\n\n\n\n\nWe have also included a categorical variable in our data this week, which is one you have seen before in our analysis classes: the home location in the UK of the respondent, home_location_in_UK. For this data object we have included only those responses from those people from the “North” (NW and NE) and those from the “South” (SW and SE). Other respondents from elsewhere have been removed from the data. We can therefore look at whether people’s home location determines their population estimations.\n\nFirst we will look at the mean population estimations, split by home location. To do this, copy and edit the code below and complete the group_by() and summarise() commands to give the mean() estimates of the proportion of immigrants in the population by home location. You don’t need to edit the N = n() line - this provides the number of participants at each level of the home_location_in_UK variable.\n\n\n# summary statistics\ndata_object_name %&gt;% \n  group_by(column_name) %&gt;% \n  summarise(mean_imm_est = complete_this_statement,\n            sample_size = n())\n\n\nWhat do the means suggest? Do people in the North and South give different estimations? Write a statement in your .Rmd file to describe the difference.\nLet’s test if these differences are real. First, it is worth noting that many more respondents originate from the North than from the South (see the N column in the summary). We have unequal sample sizes, and potentially unequal variances. Copy the code below into your .Rmd. The first bit of code runs the var.test() to check if the variances of the two samples are similar (homogeneity of variance). If this test produces a p value less that .05, then the variances in the two samples are unequal. That will have consequences for how we run the t-test() in the next step.\n\n\n# check if variances are unequal (p &lt; .05) - Q3\nvar.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name)\n\n\nNow let’s run the t-test. This week we are comparing data from different samples of participants (those who are from the North and South). We need to tell the t-test that the data are NOT paired (paired = FALSE). The result of the var.test() in the last step will tell you whether the var.equal value should be TRUE or FALSE. Set var.equal = FALSE or var.equal = TRUE depending on whether the variances are equal. When you’re happy with the parameters, run the t-test.\n\n\n# run unrelated samples t-test\nt.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name, \n       paired = FALSE, \n       var.equal = missing_value) # you'll need to set this to TRUE or FALSE depending on what you found in var.test\n\n\nIf you’ve done this correctly, you should have a t-statistic = -1.2801. Examine the p-value and discuss on your table what this means. Write a line in your .Rmd to formally state the result of the t-test (look at last week for the format). Describe what this result means in your own words.\nIn that t-test we looked at the pop_est_immigrants variable, but we can do this test for all of our population estimates. Copy the code to run another var.test() and t.test(), for the pop_est_christian variable. Document the result of the t-test in your .Rmd and describe the finding. What do these tell us about the relationship between home_location and estimates of the population (if anything)? Feel free to come back to this and run the other two tests on the other population estimations.\n\n\n\n\n\nWe saw in last week’s lab tasks that there was a significant effect in our Stroop task data: participants were faster to say the colour names of the compatible list compared to the incompatible list (there were significant differences with the control list too). We will now use these data to calculate an effect size (Cohen’s d) for the t-statistic that we observed in that test.\nImport the new stroop data csv file. We have reduced the data down to just the compatible and incompatible conditions.\nAdd the following code into a chunk and run it (edit the data object name) to calculate the cohens_d() effect size, which is reported as effsize. You can ignore any negative sign, taking note of the absolute value.\n\n\nlibrary(effectsize)\nlibrary(pwr)\n\n# add code here to read in the stroop csv file\n\ncohens_d(time ~ condition, \n         data = your_stroop_data_object,\n         paired = TRUE)\n\n\nWe already know that this large effect size was significant with our large sample of participants. What might we have expected with a much smaller sample size? Copy the code below and use the pwr.t.test() function to add in the effect size that you calculated (Cohen’s d) in step 3. We can set the N to 20. What power would we have achieved with this sample size, to detect this large effect? Discuss with your table, or staff, what this power means.\n\n\npwr.t.test(d = value_from_step_3, n = 20) #Q4\n\n\nLet’s say we wanted our next experiment to have an 80% chance of finding an effect at least as large as the one we found. Copy the code you used in step 4, and edit it to run pwr.t.test() to work out the minimum sample size we would need to achieve power of .8, with the effect size you calculated in step 3.\nLet’s say we are looking to run a new experiment in which we give people a stressful task to complete simultaneously. We will ask them to put their hands in a bucket of ice cold water while doing the Stroop task (this is a real “stressor task” people use!). We are unsure of what consequence this will have for our effect size, but we want to estimate the effect size that could be detected in our experiment. We decide to run 40 participants, and want to achieve a power of .90 (90% chance to find an effect at least this large). Copy the pwr-t-test() code and edit it to find the minimum effect size we could hope to detect under these conditions?\n\n\n\n\nScripts: By now you are hopefully getting used to editing and working within the R Markdown script. As you know, to save a script, you simply click the save icon, or press ctrl+S (cmd+s on a mac).\nPlots: To save a graph you have produced, click the “Export” button in the plot window, then “Save as Image”. You can resize the graph and give it an appropriate filename. If you’ve set the working directory correctly, then the new file should appear in the current folder.\nData: The data objects you create (in the Environment) only exist within RStudio, and are temporary (with a script and the csv file, you can always redo the analysis). But what if you want to use the data elsewhere? For example you may want to share the data with your project (PEP?) supervisor. To do this, we need to write the data to a csv file (like those we use to import the data). You can do this with the following command: write_csv(the_data_object, \"the_filename.csv\").\nExporting from RStudio: The above save operations save files to a folder within RStudio Server. At some stage you will need to get these files out of RStudio Server, for example if you need a graph for your report, or you need to share the data or the scripts. Or maybe you want to make the csv file available to other researchers. To get files out of RStudio, simply select the files you want in the Files pane, click “More” and then “Export”. Selecting multiple files will produce a “.zip” file, which will need to be “unzipped” on your computer to access the individual files (instructions for Windows and instructions for Mac)\n\n\n\nYou can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC121/Week9.html#reading",
    "href": "PSYC121/Week9.html#reading",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "Chapter 14 of Howell"
  },
  {
    "objectID": "PSYC121/Week9.html#pre-lab-work-online-tutorial",
    "href": "PSYC121/Week9.html#pre-lab-work-online-tutorial",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "Online tutorial: You must make every attempt to complete this before the lab! To access the pre-lab tutorial click here (on campus, or VPN required)\nGetting ready for the lab class\nCreate a folder for Week 9 and download the Week_9 csv file file and upload it into this new folder in RStudio Server."
  },
  {
    "objectID": "PSYC121/Week9.html#rstudio-tasks",
    "href": "PSYC121/Week9.html#rstudio-tasks",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "In this class we will be exploring some data on people’s estimations on aspects of the UK population. We asked people 4 different questions:\n\nOut of every 100 people, about how many do you think are:\n\n\n\nChristian?\nMuslim?\nOver the age of 65?\n\n\nWe also asked a related question about immigration:\n\nWhat percentage of the UK population do you think are immigrants to this country? (i.e. not born in UK)\n\n\nCreate a new R Markdown document for Week 9.\nIn the first chunk add library(tidyverse) and create a new data object by using read_csv() to read “data_wk9.csv”.\nYou can view the data by clicking on it in the environment. Note that in previous weeks we’ve used the view() command in our scripts (which does the same thing), but that can conflict with knitting the .Rmd file.\nTake a look at the summary statistics for all of the columns in our data using summary(your_data_object_name)\n\nTo what extent are people’s estimations of these population parameters related? Let’s look at this by plotting these data as geom_point().\n\nCopy the following code. Edit it to map one of the numeric columns in the data to x and another numeric column to y. You can pick any of the columns you like, but it’s important that you understand what research question you are asking with your choice. For example, you might be asking “Do people who estimate that there are more Christians in the population also think there are more Muslims in the population?”\n\n\ndata_object_name %&gt;% \n  ggplot(aes()) + # map two of the columns to x and y\n  geom_point() # you can change the size or colour of the points if you wish\n\n\nConsider the graph, noting any general pattern/trend in the data. Is there a postive relationship: do people who give high estimations for one variable tend to give high estimations for the other variable? Or is there a negative relationship: do people who give high estimations for one variable tend to give lower estimations for the other variable? Or is there no discernible relationship at all?\nWrite a statement after this code chunk to briefly make a comment about any pattern you see in the data (or absence of a pattern).\nCopy this code into new chunks and explore relationships between the other numeric variables, each time noting the research question you are asking, and discussing with people on your table what kind of relationship you can see in the data. Write some comments in your R Markdown document to describe the patterns you are seeing.\n\n\n\n\n\nYou may have noticed that there are some fairly extreme values in some of these numeric estimations of the population. As we’ve discussed in previous weeks, these outlier values can be problematic when we run our statistical tests, so (like last week) we probably want to control their influence by removing them. As you saw in your online tutorial, we can convert the data to z scores, and then remove z values above and below certain values.\nLet’s create a “z-transform column” called z_imm for the estimates of the percentage of immigrants. Complete the code below by changing the data object names and adding the relevant variable (column) name. Note that you may want to assign the result (&lt;-) to a new data object at this point.\n\n\n# use mutate and scale to create z-scores of immigration estimates\nnew_data_object_name &lt;- \n  data_object_name %&gt;% \n  mutate(z_imm = scale(column_name))\n\n\nView the new data object to check this column has been created correctly. Like in the online tutorial, it would be a good idea to calculate some descriptive statistics for this new column to check it conforms to what we know about z-scores (e.g., mean() = 0, give or take some rounding, and sd() = 1).\n\n\n# check the mean and sd of the new column\nmean(data_object_name$column_name)\nsd(data_object_name$column_name)\n\n\nWe know from our earlier lectures on the z distribution that values of greater than 2 (or less than -2) reflect around 5% of the distribution, and values greater than 3 (or less than -3) represent less than 1% of the distribution:\n\n\n\nLet’s consider an outlier any value that has a z of 2.5 (a conventional cutoff). Plot a histogram of the z_imm column in order to inspect whether there are data that are above 2.5 or below -2.5.\n\n\n# histogram of the z_imm column\n\n# eh, what, no code? Come on...you've got this!!! \n# start with the data, pipe, then ggplot\n# if you get really stuck, look back at last week\n\n\nAdd a filter command to remove the values in the z_imm column are greater than 2.5 or less than -2.5. That means you’ll need two separate statements with an & in the middle\n\n\n# add a filter command\ndata_object_filtered &lt;- \n  data_object_name %&gt;% \n  filter(first_expression_here & second_expression_here) \n\n\nYou should have removed 3 rows of data. Make a note of this in your R markdown document."
  },
  {
    "objectID": "PSYC121/Week9.html#unrelated-samples-t-test",
    "href": "PSYC121/Week9.html#unrelated-samples-t-test",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "We have also included a categorical variable in our data this week, which is one you have seen before in our analysis classes: the home location in the UK of the respondent, home_location_in_UK. For this data object we have included only those responses from those people from the “North” (NW and NE) and those from the “South” (SW and SE). Other respondents from elsewhere have been removed from the data. We can therefore look at whether people’s home location determines their population estimations.\n\nFirst we will look at the mean population estimations, split by home location. To do this, copy and edit the code below and complete the group_by() and summarise() commands to give the mean() estimates of the proportion of immigrants in the population by home location. You don’t need to edit the N = n() line - this provides the number of participants at each level of the home_location_in_UK variable.\n\n\n# summary statistics\ndata_object_name %&gt;% \n  group_by(column_name) %&gt;% \n  summarise(mean_imm_est = complete_this_statement,\n            sample_size = n())\n\n\nWhat do the means suggest? Do people in the North and South give different estimations? Write a statement in your .Rmd file to describe the difference.\nLet’s test if these differences are real. First, it is worth noting that many more respondents originate from the North than from the South (see the N column in the summary). We have unequal sample sizes, and potentially unequal variances. Copy the code below into your .Rmd. The first bit of code runs the var.test() to check if the variances of the two samples are similar (homogeneity of variance). If this test produces a p value less that .05, then the variances in the two samples are unequal. That will have consequences for how we run the t-test() in the next step.\n\n\n# check if variances are unequal (p &lt; .05) - Q3\nvar.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name)\n\n\nNow let’s run the t-test. This week we are comparing data from different samples of participants (those who are from the North and South). We need to tell the t-test that the data are NOT paired (paired = FALSE). The result of the var.test() in the last step will tell you whether the var.equal value should be TRUE or FALSE. Set var.equal = FALSE or var.equal = TRUE depending on whether the variances are equal. When you’re happy with the parameters, run the t-test.\n\n\n# run unrelated samples t-test\nt.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name, \n       paired = FALSE, \n       var.equal = missing_value) # you'll need to set this to TRUE or FALSE depending on what you found in var.test\n\n\nIf you’ve done this correctly, you should have a t-statistic = -2.0735. Examine the p-value and discuss on your table what this means. Write a line in your .Rmd to formally state the result of the t-test (look at last week for the format). Describe what this result means in your own words.\nIn that t-test we looked at the pop_est_immigrants variable, but we can do this test for all of our population estimates. Copy the code to run another var.test() and t.test(), for the pop_est_christian variable. Document the result of the t-test in your .Rmd and describe the finding. What do these tell us about the relationship between home_location and estimates of the population (if anything)? Feel free to come back to this and run the other two tests on the other population estimations."
  },
  {
    "objectID": "PSYC121/Week9.html#power-and-effect-size-d-calculations",
    "href": "PSYC121/Week9.html#power-and-effect-size-d-calculations",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "We saw in last week’s lab tasks that there was a significant effect in our Stroop task data: participants were faster to say the colour names of the compatible list compared to the incompatible list (there were significant differences with the control list too). We will now use these data to calculate an effect size (Cohen’s d) for the t-statistic that we observed in that test.\nImport the new stroop data csv file. We have reduced the data down to just the compatible and incompatible conditions.\nAdd the following code into a chunk and run it (edit the data object name) to calculate the cohens_d() effect size, which is reported as effsize. You can ignore any negative sign, taking note of the absolute value.\n\n\nlibrary(effectsize)\nlibrary(pwr)\n\n# add code here to read in the stroop csv file\n\ncohens_d(time ~ condition, \n         data = your_stroop_data_object,\n         paired = TRUE)\n\n\nWe already know that this large effect size was significant with our large sample of participants. What might we have expected with a much smaller sample size? Copy the code below and use the pwr.t.test() function to add in the effect size that you calculated (Cohen’s d) in step 3. We can set the N to 20. What power would we have achieved with this sample size, to detect this large effect? Discuss with your table, or staff, what this power means.\n\n\npwr.t.test(d = value_from_step_3, n = 20) #Q4\n\n\nLet’s say we wanted our next experiment to have an 80% chance of finding an effect at least as large as the one we found. Copy the code you used in step 4, and edit it to run pwr.t.test() to work out the minimum sample size we would need to achieve power of .8, with the effect size you calculated in step 3.\nLet’s say we are looking to run a new experiment in which we give people a stressful task to complete simultaneously. We will ask them to put their hands in a bucket of ice cold water while doing the Stroop task (this is a real “stressor task” people use!). We are unsure of what consequence this will have for our effect size, but we want to estimate the effect size that could be detected in our experiment. We decide to run 40 participants, and want to achieve a power of .90 (90% chance to find an effect at least this large). Copy the pwr-t-test() code and edit it to find the minimum effect size we could hope to detect under these conditions?"
  },
  {
    "objectID": "PSYC121/Week9.html#a-note-on-saving-your-work",
    "href": "PSYC121/Week9.html#a-note-on-saving-your-work",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "Scripts: By now you are hopefully getting used to editing and working within the R Markdown script. As you know, to save a script, you simply click the save icon, or press ctrl+S (cmd+s on a mac).\nPlots: To save a graph you have produced, click the “Export” button in the plot window, then “Save as Image”. You can resize the graph and give it an appropriate filename. If you’ve set the working directory correctly, then the new file should appear in the current folder.\nData: The data objects you create (in the Environment) only exist within RStudio, and are temporary (with a script and the csv file, you can always redo the analysis). But what if you want to use the data elsewhere? For example you may want to share the data with your project (PEP?) supervisor. To do this, we need to write the data to a csv file (like those we use to import the data). You can do this with the following command: write_csv(the_data_object, \"the_filename.csv\").\nExporting from RStudio: The above save operations save files to a folder within RStudio Server. At some stage you will need to get these files out of RStudio Server, for example if you need a graph for your report, or you need to share the data or the scripts. Or maybe you want to make the csv file available to other researchers. To get files out of RStudio, simply select the files you want in the Files pane, click “More” and then “Export”. Selecting multiple files will produce a “.zip” file, which will need to be “unzipped” on your computer to access the individual files (instructions for Windows and instructions for Mac)"
  },
  {
    "objectID": "PSYC121/Week9.html#week-9-quiz",
    "href": "PSYC121/Week9.html#week-9-quiz",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "You can access a set of quiz questions related to this week here."
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html",
    "title": "PSYC121: Week 9 Lab",
    "section": "",
    "text": "For this week’s online tutorial we have data on how much students use social media platforms and people’s mean reading times from the stroop task. We will use these data to look at how we create new variables (columns) using mutate(). We will also expand what we have learnt about filtering data based on conditions, using the filter() function. Let’s take a look at the data we have using the summary(), to get useful statistics. You can also use head() to look at the first few rows of data\n\n\nsummary(data)\nhead(data)"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#exploring-the-data",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#exploring-the-data",
    "title": "PSYC121: Week 9 Lab",
    "section": "",
    "text": "For this week’s online tutorial we have data on how much students use social media platforms and people’s mean reading times from the stroop task. We will use these data to look at how we create new variables (columns) using mutate(). We will also expand what we have learnt about filtering data based on conditions, using the filter() function. Let’s take a look at the data we have using the summary(), to get useful statistics. You can also use head() to look at the first few rows of data\n\n\nsummary(data)\nhead(data)"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#mutating-new-variables",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#mutating-new-variables",
    "title": "PSYC121: Week 9 Lab",
    "section": "“Mutating” new variables",
    "text": "“Mutating” new variables\nIn this data set, all of the variables are numerical. Sometimes we may want to recode a variable to turn it from a continuous numerical variable, to a categorical/nominal variable. For example, maybe we want to compare students who are high users of facebook, to those who are low users of facebook. We could do that in the following way using the mutate() function:\n\n\ndata %&gt;% \n  mutate(facebook_use = facebook_days &gt;= 4)\n\n\n\n\n\nWhen you run this code you’ll see that mutate() has created a new column on the end, which tells us whether the person uses facebook for at least 4 days a week. Note that the new column is called “facebook_use” - this works in exactly the same way as the summarise() commands you have been practising, where you tell it the new variable name you want to create. The values “TRUE” and “FALSE” are not especially informative here - we probably want to be a bit clearer in the names we give to these levels of the new variable. To do that we can modify this code a little to use an if_else(), which checks if the “conditional statement” (facebook_days &gt;= 4) is TRUE or FALSE, and specifies the values to use in each case:\n\n\ndata %&gt;% \n  mutate(facebook_use = if_else(facebook_days &gt;= 4,true = \"high\",false = \"low\"))\n\n\n\n\n\n\nJust like with summarise(), we can have multiple new columns created within the one mutate() command. Each of these needs to be separated by a comma, and it’s good practice to put each one on a new line. Try copying and pasting the if_else command, and then modifying it to make two new variables to code for “high” and “low” instagram and twitter use:\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(facebook_use = if_else(facebook_days &gt;= 4,true = \"high\",false = \"low\"),\n         instagram_use = ,\n         twitter_use = )\n\ndata\n# because we are assigning (&lt;-) the changes to update \"data\", \n# we write it again here to display the results\n\n\n\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(facebook_use = if_else(facebook_days &gt;= 4,true = \"high\",false = \"low\"),\n         instagram_use = if_else(instagram_days &gt;= 4,true = \"high\",false = \"low\"),\n         twitter_use = if_else(twitter_days &gt;= 4,true = \"high\",false = \"low\"))\n\ndata\n# because we are assigning (&lt;-) the changes to update \"data\", \n# we write it again here to display the results\n\n\n\n\n\nLet’s now look at our avg_stroop variable, and first plot the data in a box and whisker plot:\n\n\ndata %&gt;% \n  ggplot() +\n  geom_boxplot(aes(y = avg_stroop))\n\n\n\n\n\n\nWe can see here that we have a number of points that lie outside the “whiskers” on the plot. One thing we can do to identify potential outliers is to create a new variable that transforms the data to a z distribution. This is easy to do in R using the scale() function:\n\n\ndata &lt;- \n  data %&gt;% \n  mutate(z_stroop = scale(avg_stroop))\n\ndata\n# because we are assigning (&lt;-) the changes to update \"data\", \n# we write it again here to display the results\n\n\n\n\n\n\nYou may remember that a distribution of z scores has a mean of 0 and a standard deviation of 1. Let’s check that here:\n\n\nmean()\nsd()\n\n\n\n\n\nmean(data_set$variable) # example\nsd(data_set$variable) # example\n\n\n\n\nmean(data$z_stroop)\nsd(data$z_stroop)\n\n\nYou’ll notice that the value for the mean is not quite 0 (but it is very very small!). This is probably due to a rounding of values in the scale() function. To get a value of 0 we could encolse the statement in the round() function, e.g. `round(mean(),digits = 2).\n\n\n\nA good way to get a sense of the range of values in our z-scores is to use arrange() to sort them in order. We can then use head() and tail() to see the values at each end of the distribution (the first ‘n’ rows, and the last ‘n’ rows)\n\n\ndata &lt;- \n  data %&gt;% \n  arrange(desc(z_stroop)) # arrange in descending order\n\nhead(data, n = 10)\ntail(data, n = 10)\n\n\n\nYou can see that we’ve got some quite extreme values here. First, we’ve got some very slow participants, showing average reading times of over 10 seconds. Secondly, we’ve got some extremely fast participants. The fastest participant of all is particularly unusual - perhaps they put in incorrect values into the survey?"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#filtering-data",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#filtering-data",
    "title": "PSYC121: Week 9 Lab",
    "section": "Filtering data",
    "text": "Filtering data\nAs you can see, we quite often want to filter our data to select or remove some of the rows we are working with. To do this, we can use the filter() command.\nTo use filter(), we simply specify the data first, and then we need to use an expression to state how we want the data to be filtered. For example:\n\n\ndata %&gt;% \n  filter(z_stroop &lt;= 2) \n# find all those people who have z_stroop values lower than positive 2\n\n\n\n\nCommon expressions\nThe following table gives some examples of very common expressions used in filtering data:\n\n\n\n\n\nOperator\nMeaning\nExample\n\n\n\n\n==\nis the same as\nfilter(dataQ, age==27)\n\n\n&lt;\nis less than\nfilter(dataQ, age&lt;25)\n\n\n&gt;\nis greater than\nfilter(dataQ, age&gt;30)\n\n\n!=\nis not equal to\nfilter(dataQ, gender != 'female')\n\n\n&\nand\nfilter(dataQ, age&lt;30 & gender == 'female')\n\n\n|\nor\nfilter(dataQ, gender == 'male' | gender == 'non-binary')\n\n\n\n\n\n\n\nIt’s particularly important to note the difference between “==” and “=” in R. “=” is used as an assignment operator - you’ve used it several times already inside functions (e.g., na.rm = TRUE, mu = 29600). You can think of “=” as meaning “set this to”. In contrast the double equals operator, “==”, asks a question: “is this thing the same as this other thing?” In the above example, z_stroop &lt;= 2, it looks for all rows in the data where z_stroop is the same as, or less than, the value of 2. In programming terms, the expression returns a boolean value, which reports whether the statement is TRUE or FALSE (and when used in the filter, it finds all rows where it is TRUE). You can see this in the results of the following “conditional expressions”:\n\n\n2 == 3\n\"blah\" == \"blah\"\n\"blah\" == \"BLAH\"\n\"John\" == \"rock star\"\nmean(c(3,4,5,6)) == 4.5\nTRUE == FALSE # this is getting meta...\n\n\n\n\n\nPractice filtering\nPractice writing your own filter commands in the box below. Try to filter the data to match the following queries:\n\nData for those people who are “high” facebook users (hint: facebook_use == )\nData for those people who use instagram for 7 days, and have a z_stroop score of less than -1 (hint: use &)\nData for those people who are “high” users of at least one social media platform (hint: this needs two “or”: | )\n\n[Each hint here gives the solution to each query]\n\n\ndata %&gt;% \n  filter()\n\n\n\n\n\n# Query 1 solution\ndata %&gt;% \n  filter(facebook_use == \"high\")\n\n\n\n\n# Query 2 solution\ndata %&gt;% \n  filter(instagram_days == 7 & z_stroop &lt; -1)\n\n\n\n\n# Query 3 solution\ndata %&gt;% \n  filter(facebook_use == \"high\" | instagram_use == \"high\" | twitter_use == \"high\")"
  },
  {
    "objectID": "PSYC121/data/Week_9/Week_9_learnr.html#section-6",
    "href": "PSYC121/data/Week_9/Week_9_learnr.html#section-6",
    "title": "PSYC121: Week 9 Lab",
    "section": "",
    "text": "End of tutorial\nThis is now the end of the online tutorial on filter() and mutate(). Please return to the tasks in the lab worksheet."
  },
  {
    "objectID": "PSYC121/Week9.html#task-3---unrelated-samples-t-test",
    "href": "PSYC121/Week9.html#task-3---unrelated-samples-t-test",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "We have also included a categorical variable in our data this week, which is one you have seen before in our analysis classes: the home location in the UK of the respondent, home_location_in_UK. For this data object we have included only those responses from those people from the “North” (NW and NE) and those from the “South” (SW and SE). Other respondents from elsewhere have been removed from the data. We can therefore look at whether people’s home location determines their population estimations.\n\nFirst we will look at the mean population estimations, split by home location. To do this, copy and edit the code below and complete the group_by() and summarise() commands to give the mean() estimates of the proportion of immigrants in the population by home location. You don’t need to edit the N = n() line - this provides the number of participants at each level of the home_location_in_UK variable.\n\n\n# summary statistics\ndata_object_name %&gt;% \n  group_by(column_name) %&gt;% \n  summarise(mean_imm_est = complete_this_statement,\n            sample_size = n())\n\n\nWhat do the means suggest? Do people in the North and South give different estimations? Write a statement in your .Rmd file to describe the difference.\nLet’s test if these differences are real. First, it is worth noting that many more respondents originate from the North than from the South (see the N column in the summary). We have unequal sample sizes, and potentially unequal variances. Copy the code below into your .Rmd. The first bit of code runs the var.test() to check if the variances of the two samples are similar (homogeneity of variance). If this test produces a p value less that .05, then the variances in the two samples are unequal. That will have consequences for how we run the t-test() in the next step.\n\n\n# check if variances are unequal (p &lt; .05) - Q3\nvar.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name)\n\n\nNow let’s run the t-test. This week we are comparing data from different samples of participants (those who are from the North and South). We need to tell the t-test that the data are NOT paired (paired = FALSE). The result of the var.test() in the last step will tell you whether the var.equal value should be TRUE or FALSE. Set var.equal = FALSE or var.equal = TRUE depending on whether the variances are equal. When you’re happy with the parameters, run the t-test.\n\n\n# run unrelated samples t-test\nt.test(pop_est_immigrants ~ home_location_in_UK, data = your_data_object_name, \n       paired = FALSE, \n       var.equal = missing_value) # you'll need to set this to TRUE or FALSE depending on what you found in var.test\n\n\nIf you’ve done this correctly, you should have a t-statistic = -1.2801. Examine the p-value and discuss on your table what this means. Write a line in your .Rmd to formally state the result of the t-test (look at last week for the format). Describe what this result means in your own words.\nIn that t-test we looked at the pop_est_immigrants variable, but we can do this test for all of our population estimates. Copy the code to run another var.test() and t.test(), for the pop_est_christian variable. Document the result of the t-test in your .Rmd and describe the finding. What do these tell us about the relationship between home_location and estimates of the population (if anything)? Feel free to come back to this and run the other two tests on the other population estimations."
  },
  {
    "objectID": "PSYC121/Week9.html#task-4---power-and-effect-size-d-calculations",
    "href": "PSYC121/Week9.html#task-4---power-and-effect-size-d-calculations",
    "title": "9. Unrelated-samples t-test and Power",
    "section": "",
    "text": "We saw in last week’s lab tasks that there was a significant effect in our Stroop task data: participants were faster to say the colour names of the compatible list compared to the incompatible list (there were significant differences with the control list too). We will now use these data to calculate an effect size (Cohen’s d) for the t-statistic that we observed in that test.\nImport the new stroop data csv file. We have reduced the data down to just the compatible and incompatible conditions.\nAdd the following code into a chunk and run it (edit the data object name) to calculate the cohens_d() effect size, which is reported as effsize. You can ignore any negative sign, taking note of the absolute value.\n\n\nlibrary(effectsize)\nlibrary(pwr)\n\n# add code here to read in the stroop csv file\n\ncohens_d(time ~ condition, \n         data = your_stroop_data_object,\n         paired = TRUE)\n\n\nWe already know that this large effect size was significant with our large sample of participants. What might we have expected with a much smaller sample size? Copy the code below and use the pwr.t.test() function to add in the effect size that you calculated (Cohen’s d) in step 3. We can set the N to 20. What power would we have achieved with this sample size, to detect this large effect? Discuss with your table, or staff, what this power means.\n\n\npwr.t.test(d = value_from_step_3, n = 20) #Q4\n\n\nLet’s say we wanted our next experiment to have an 80% chance of finding an effect at least as large as the one we found. Copy the code you used in step 4, and edit it to run pwr.t.test() to work out the minimum sample size we would need to achieve power of .8, with the effect size you calculated in step 3.\nLet’s say we are looking to run a new experiment in which we give people a stressful task to complete simultaneously. We will ask them to put their hands in a bucket of ice cold water while doing the Stroop task (this is a real “stressor task” people use!). We are unsure of what consequence this will have for our effect size, but we want to estimate the effect size that could be detected in our experiment. We decide to run 40 participants, and want to achieve a power of .90 (90% chance to find an effect at least this large). Copy the pwr-t-test() code and edit it to find the minimum effect size we could hope to detect under these conditions?"
  },
  {
    "objectID": "PSYC122/Week11.html",
    "href": "PSYC122/Week11.html",
    "title": "1. Week 11 - Correlation",
    "section": "",
    "text": "Today we will take a look at correlation as a measure of association between two numerical variables. We will create scatterplots to visualise correlations, we will run a correlation analysis and we will practise interpreting and reporting the results."
  },
  {
    "objectID": "PSYC122/Week11.html#lectures",
    "href": "PSYC122/Week11.html#lectures",
    "title": "1. Week 11 - Correlation",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material comes in two flavours.\n\nTheory(~30 minutes) {#sec-wk11-theory-lecture} Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video. Finally, if you open the video in ‘eStream’ by clicking on the green ‘e’ in the bottom right, you can navigate to separate sections of the video by clicking on the ‘chapters’ pane. This might be particularly useful if you quickly want to revisit a particular section.\n\n\nSlides Transcript\n\nHow to This year, short ‘how to’ videos talking you through different bits and pieces to do with R and R Studio are embedded in the pre-lab and lab activities."
  },
  {
    "objectID": "PSYC122/Week11.html#reading",
    "href": "PSYC122/Week11.html#reading",
    "title": "1. Week 11 - Correlation",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week and next week is from chapter 9 of the core text by Howell (2017).\nRougly, this week we’ll cover the material in sections 9.1 to 9.4, as well as sections 9.8 to 9.11 and section 9.15. Next week, we’ll cover the material in sections 9.5 to 9.7, and sections 9.12 to 9.13. Even if a section is not mentioned here, all of chapter 9 is relevant."
  },
  {
    "objectID": "PSYC122/Week11.html#pre-lab-activities",
    "href": "PSYC122/Week11.html#pre-lab-activities",
    "title": "1. Week 11 - Correlation",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures on correlation and read the textbook sections you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualing correlations\nHave a look at this visualisation of correlations by Kristoffer Magnusson.\nAfter having read the relevant sections of Howell (2017) Chapter 9, use this visualisation page to visually replicate the scatterplots in Figures 9.1 and 9.2 - use a sample of 100. After that, visually replicate the scatterplots in Figure 9.3.\nEach time you change the correlation, pay attention to the shared variance (the overlap between the two variables) and see how this changes with the changing level of relationship between the two variables. The greater the shared variance, the stronger the relationship.\nAlso, try setting the correlation to r = .5 and then moving a single dot to see how one data point, a potential outlier, can change the stated correlation value between two variables.\n\n\nPre-lab activity 2: Guess the correlation\nNow that you are well versed in interpreting scatterplots (scattergrams) have a go at this online app on guessing the correlation.\nThis is a very basic app that allows you to see how good you are at recognising different correlation strengths from the scatterplots. We would recommend you click the “Track Performance” tab so you can keep an overview of your overall bias to underestimate or overestimate a correlation.\nIs this all just a bit of fun? Well, yes, because stats is actually fun, and no, because it serves a purpose of helping you determine if the correlations you see in your own data are real, and to help you see if correlations in published research match with what you are being told. As you will have seen from the above examples, one data point can lead to a misleading relationship and even what might be considered a medium to strong relationship may actually have only limited relevance in the real world. One only needs to mention Anscombe’s Quartet to be reminded of the importance of visualising your data, which leads us to the final pre-lab activity for this week.\n\n\nPre-lab activity 3: Anscombe’s quartet\nAnscombe (1973) showed that four sets of bivariate data (X, Y) that have the exact same means, medians, and relationships can look very different when plotted. You can read more about this here.\nAll in this is a clear example of why you should visualise your data and not to rely on just the numbers.\n\n\nPre-lab activity 4: Getting ready for the lab class\n\nRemind yourself of the basics of how to work with RStudio and get your files ready\nYou might want to re-visit the materials that John and Tom provided in PSYC121:\n\nBasics of working with RStudio\nCreate a folder for Week 11.\nDownload the 122_week11_forStudents.zip file and upload it into the new folder in RStudio Server you created at the previous step."
  },
  {
    "objectID": "PSYC122/Week11.html#lab-activities",
    "href": "PSYC122/Week11.html#lab-activities",
    "title": "1. Week 11 - Correlation",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconstructing and interpreting scatterplots\nrunning correlation analysis and interpret the results\nreporting the results in APA format\nconstructing a correlation matrix in APA format\nwhen and why to apply correlation analysis to answers questions in psychological science\n\n\nLab activity 1: Interpreting correlation\n\nQuestion 1\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph using one of the following:\n\nPerfect positive correlation\nPerfect negative correlation\nStrong positive correlation\nStrong negative correlation\nModerate positive correlation\nModerate negative correlation\nNull correlation\n\nFigure A \nFigure B \nFigure C \nFigure D \n\n\n\n\n\n\nNote\n\n\n\nFor the following questions, explain your chosen answer based on the statistic given, not on why you think the correlation may or may note make ‘logical’ sense.\n\n\n\n\nQuestion 2\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\nTRUE or FALSE? Explain why.\n\n\nQuestion 3\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\nTRUE or FALSE? Explain why.\n\n\nQuestion 4\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n51%\n70%\n49%\n30%\nWho cares I’ve got great hair.\n\nWhat was the reason for your answer?\nWhat is this ‘new coefficient’ called?\n\n\n\nLab activity 2: Visualising, calculating and reporting correlations\nGoing back to the data discussed in Chapter 11 of Miller & Haden, you’ll remember it contains data from 25 8-year-old children on:\n\na standardised test of reading ability (Abil)\nintelligence (IQ)\nthe number of minutes per week spent reading in the home (Home)\nand the number of minutes per week spent watching TV (TV)\n\nIn the video on ‘How to conduct correlation analysis using R’ we looked at the correlation between reading ability and intelligence. Now, let’s look at the correlation between number of minutes per week spent reading in the home and watching TV.\nThe folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’ contains the datafile (“MillerHadenData.csv”) as well as the R-script from the ‘How to …’ video (122_wk11_howtoExample.R) that you can use here and adapt.\n\nLoad the ‘broom’ and the ‘tidyverse’ libraries by running the first two lines of code.\nRead in the data. You should now see an object with 25 observations and 5 variables in the ‘Environment’. Click on it to view it.\nConstruct a scatterplot of the relationship between ‘Home’ and ‘TV’.\nWhat can you tell from the scatterplot about the direction of the relationship?\nConduct the correlation analysis.\nWhat is the correlation coefficient (Pearson’s r)?\nWhat is the p value?\nIs the correlation significant at the p &lt; .05 level?\nWhat are the degrees of freedom you need to report?\nHow much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’? (Hint: you can use the Console in RStudio as a calculator.)\nWrite a few sentences in which you report this result, following APA guidelines.\n\n\n\nLab activity 3: More correlations\nResearchers were interested in the relationship between hazardous alcohol use and impulsivity (making unplanned, rapid decisions without thinking or ‘acting on a whim’). To investigate the relationship, 20 participants completed both the alcohol use disorder identification test (AUDIT; Saunders, Aasland, Babor, de la Fuente, & Grant, 1993) and the Barratt’s Impulsiveness Scale (BIS-11) (Patton, Stanford, & Barratt, 1995). The datafile (“alcoholUse_Impulsivity.csv”) is in the folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’. Again, the R-script from the ‘How to …’ video (122_wk11_howtoExample.R) is useful here.\n\nLoad the ‘broom’ and the ‘tidyverse’ libraries by running the first two lines of code.\nRead in the data. You should now see an object containing the data in the ‘Environment’. How many variables does it have?\nConstruct a scatterplot of the relationship between ‘Hazardous Alcohol Use’ and ‘Impulsivity’.\nWhat can you tell from the scatterplot about the direction of the relationship?\nConduct the correlation analysis.\nWhat is the correlation coefficient (Pearson’s r)?\nWhat is the p value?\nIs the correlation significant at the p &lt; .05 level?\nWhat are the degrees of freedom you need to report?\nHow much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’? (Hint: you can use the Console in RStudio as a calculator.)\nConstruct a correlation matrix to display the correlation coefficient in a table.\nGive three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\nJob completed — Well done!"
  },
  {
    "objectID": "PSYC122/Week11.html#answers",
    "href": "PSYC122/Week11.html#answers",
    "title": "1. Week 11 - Correlation",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at code written by someone else…\n\n\nLab activity 1: Interpreting correlation\n\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nstrong positive correlation\nnull correlation\nmoderate positive correlation\nperfect negative correlation\n\n\n\n\n\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFALSE Explanation: The correlation coefficient is negative and therefore infers a negative correlation. As such, older people pay less for car insurance: as age increases, car insurance costs decrease.\n\n\n\n\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFALSE Explanation: This is a bit of trick question as it has the sneaky ‘cause’ word in. The correlation coefficient is a positive number, suggesting a positive relationship between length of time in prison and aggression. However, causation cannot be inferred from correlation and therefore we cannot know whether time spent in prison CAUSES aggression, and rather we suggest a relationship between the two: as length of time in prison increases, aggression increases.\n\n\n\n\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nc 49% The ‘coefficient of determination’ or ‘R-squared’ tells us the proportion or variance in one variable that can be predicted if we know the other variable. We can determine this by squaring the r. Therefore, .72 = .49, R2 = .49.\n\n\n\n\n\nLab activity 2: Constructing scatterplots and calculating correlations\nYou can download the RMd-script that contains the code to complete lab activities 2 and 3 here: 122_wk11_labActivities2_3.Rmd.\nQuestion 3a: What can you tell from the scatterplot about the direction of the relationship?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a negative association between ‘Home’ and ‘TV’. This means that the longer a child spends watching TV, the shorter they will read at home.\n\n\n\nQuestion 4a: What is the correlation coefficient (Pearson’s r)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nr = -.65\n\n\n\nQuestion 4b: What is the p value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\np &lt; .001\n\n\n\nQuestion 4c: Is the correlation significant at the p &lt; .05 level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, because the p-value is smaller than .005\n\n\n\nQuestion 4d: What are the degrees of freedom you need to report?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n23\n\n\n\nStep 5. How much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n42%\n\n\n\nStep 6. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomething along the lines of: A Pearson’s correlation coefficient was used to assess the relationship between time spent reading at home and time spent watching TV at home. There was a significant negative correlation, r(23) = -.65, p &lt; .001. As time spent watching TV increased, time spent reading at home decreased.\n\n\n\n\n\nLab activity 3: Hazardous alcohol use and impulsivity\nQuestion 1a: How many variables does it have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n3\n\n\n\nQuestion 2a: What can you tell from the scatterplot about the direction of the relationship?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is a positive association between ‘hazardous alcohol use’ and ‘impulsivity’. This means that as a participant’s score on ‘hazardous alcohol use’ goes up, their score on ‘impulsivity’ also goes up.\n\n\n\nQuestion 3a: What is the correlation coefficient (Pearson’s r)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nr = .54\n\n\n\nQuestion 3b: What is the p value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\np = .014\n\n\n\nQuestion 3c: Is the correlation significant at the p &lt; .05 level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes\n\n\n\nQuestion 3d: What are the degrees of freedom you need to report?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n18\n\n\n\nQuestion 3e: How much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n29%\n\n\n\nQuestion 3f:. Give three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nJust really looking for reasoning here.\nExamples:\n\nBeing more impulsive may make people consume more alcohol.\nConsuming more alcohol may make people more impulsive.\nAn outgoing personality might influence both your level of impulsivity and you are more likely to be socialising in the pub and consuming alcohol. So the same ‘third factor’ may influence both our variables of interest.\n\n\n\n\nStep 4. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomething along the lines of: A Pearson’s correlation coefficient was used to assess the relationship between alcohol use and impulsivity. There was a significant positive correlation, r(18) = .54, p &lt; .014. People who reported to consume more alcohol, scored higher on the impulsivity scale."
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-reading",
    "href": "PSYC122/Week11.html#sec-wk11-reading",
    "title": "1. Week 11 - Correlation",
    "section": "Reading",
    "text": "Reading\nThe reading that accompanies the lectures this week and next week is from chapter 9 of the core text by Howell (2017).\nRougly, this week we’ll cover the material in sections 9.1 to 9.4, as well as sections 9.8 to 9.11 and section 9.15. Next week, we’ll cover the material in sections 9.5 to 9.7, and sections 9.12 to 9.13. Even if a section is not mentioned here, all of chapter 9 is relevant."
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-theory-lecture",
    "href": "PSYC122/Week11.html#sec-wk11-theory-lecture",
    "title": "1. Week 11 - Correlation",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material comes in two parts.\n\nTheory(~30 minutes) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video. Finally, if you open the video in ‘eStream’ by clicking on the green ‘e’ in the bottom right, you can navigate to separate sections of the video by clicking on the ‘chapters’ pane. This might be particularly useful if you quickly want to revisit a particular section.\n\n\nSlides Transcript\n\nHow to(~13 minutes) Watch this part after you’ve completed the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript"
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-labactivities",
    "href": "PSYC122/Week11.html#sec-wk11-labactivities",
    "title": "1. Week 11 - Correlation",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nconstructing and interpreting scatterplots\nrunning correlation analysis and interpret the results\nreporting the results in APA format\nconstructing a correlation matrix in APA format\nwhen and why to apply correlation analysis to answers questions in psychological science\n\n\nLab activity 1: Interpreting correlation\n\nQuestion 1\nBelow are scatterplots that show the relationship between ‘how much you know about correlation and how attractive you appear to members of the opposite (&/or same) sex’. Choose the type of correlation (strength and direction) displayed in each graph using one of the following:\n\nPerfect positive correlation\nPerfect negative correlation\nStrong positive correlation\nStrong negative correlation\nModerate positive correlation\nModerate negative correlation\nNull correlation\n\nFigure A \nFigure B \nFigure C \nFigure D \n\n\n\n\n\n\nNote\n\n\n\nFor the following questions, explain your chosen answer based on the statistic given, not on why you think the correlation may or may note make ‘logical’ sense.\n\n\n\n\nQuestion 2\nSuppose it was observed that there is a correlation of r = -.81 between a driver’s age and the cost of car insurance. This correlation would mean that, in general, older people pay more for car insurance.\nTRUE or FALSE? Explain why.\n\n\nQuestion 3\nSuppose that there is a correlation of r = .87 between the length of time a person is in prison and the amount of aggression the person displays on a psychological inventory administered at release. This means that spending a longer amount of time in prison causes people to become more aggressive.\nTRUE or FALSE? Explain why.\n\n\nQuestion 4\nA significant correlation was found between having great hair and performance in correlation labs. The correlation coefficient was .7. How much variance in correlation lab performance can the ‘greatness’ of your hair explain?\n\n51%\n70%\n49%\n30%\nWho cares I’ve got great hair.\n\nWhat was the reason for your answer?\nWhat is this ‘new coefficient’ called?\n\n\n\nLab activity 2: Visualising, calculating and reporting correlations\n\n\n\n\n\n\nWatch the ‘How to’ video\n\n\n\nIf you haven’t done so already, this is a good time to watch the ‘How to’ video (here Section 1) on ‘How to conduct a correlation analysis using R’.\n\n\nGoing back to the data discussed in the ‘How to’ video (see Section 1), you’ll remember it contains data from 25 8-year-old children on:\n\na standardised test of reading ability (Abil)\nintelligence (IQ)\nthe number of minutes per week spent reading in the home (Home)\nand the number of minutes per week spent watching TV (TV)\n\nIn the video on ‘How to conduct correlation analysis using R’ we looked at the correlation between reading ability and intelligence. Now, let’s look at the correlation between number of minutes per week spent reading in the home and watching TV.\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’ contains the datafile (“MillerHadenData.csv”). Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nDo this if you couldn’t upload files to the server\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/MillerHadenData.csv?raw=true\", destfile = \"MillerHadenData.csv\")\n\n\n\n\n\n\n\nNew R Markdown script\n\n\n\nBefore we begin, make sure you have started a new R Markdown script. If you need a reminder of how to do that, please revisit week 6 of PSYC121 (here).\n\n\n\nStep 1. Add the code to load the broom and the tidyverse libraries in a new code chunk. If you are unsure, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library()function. Remember to put it inside a ‘code chunk’ in your R Markdown script.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(tidyverse)\n\n\n\n\nStep 2. Read in the data. You should now see a dataframe with 25 observations and 5 variables in the ‘Environment’. Click on it to view it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\n\n\n\nStep 3. Construct a scatterplot of the relationship between ‘Home’ and ‘TV’. Also add a line of best fit and make sure you use clear labels for your axes.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the ggplot()function in combination with geom_point() and geom_smooth(). Make sure you use clear labels for your axes by using labs().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variable names. Also add clear labels for your axes.\nggplot(DATA, aes(x = , y = )) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nggplot(mh, aes(x = Home, y = TV)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Time spend reading at home\", y = \"Time spend watching TV at home\")\n\n\n\nQuestion 3a: What can you tell from the scatterplot about the direction of the relationship? Write a few sentences in your R Markdown script to describe the relationship.\n\nStep 4. Conduct the correlation analysis.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the cor.test()function in combination with tidy().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variables names.\nresults &lt;- cor.test(DATA$X, \n                    DATA$Y, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nresults &lt;- cor.test(mh$Home, \n                    mh$TV, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\nOnce you’ve run this code chunk, the output should appear in your R Markdown script and you can answer the questions below using that output. You can also pull out the different pieces of information by using the pull() function and round the values using the round() function, like this:\nr &lt;- results %&gt;%\n  pull(estimate) %&gt;%\n  round(2)\nQuestion 4a: What is the correlation coefficient (Pearson’s r)?\nQuestion 4b: What is the p value?\nQuestion 4c: Is the correlation significant at the p &lt; .05 level?\nQuestion 4d: What are the degrees of freedom you need to report?\n\nStep 5. Calculate how much variance in ‘time spent reading’ can be accounted for by ‘time spent watching TV’?\n\nAs discussed in the theory lecture, this is referred to as the ‘coefficient of determination’ or ‘R-squared’. To calculate it, you square the value for Pearson’s r. To calculate how much variance in one variable is accounted for by the other variable, you multiply it by 100 and round it to 0 decimals.\n\nStep 6. Write a few sentences in which you report this result, following APA guidelines.\n\n\n\nLab activity 3: Hazardous alcohol use and impulsivity\nResearchers were interested in the relationship between hazardous alcohol use and impulsivity (making unplanned, rapid decisions without thinking or ‘acting on a whim’). To investigate the relationship, 20 participants completed both the alcohol use disorder identification test (AUDIT; Saunders, Aasland, Babor, de la Fuente, & Grant, 1993) and Barratt’s Impulsiveness Scale (BIS-11) (Patton, Stanford, & Barratt, 1995).\n\n\n\n\n\n\nBefore we begin\n\n\n\nAssuming you are using the same R Markdown script as for the previous lab activity, you should already have code to load the broom and the tidyverse libraries. If this is a new session, you just need to re-run that code chunk to ensure they are loaded. At this point, it is a good idea to clear your environment to avoid any confusion between data frames or values. You can do this by clicking on the broom icon on the top right of the Environment pane. The data file (“alcoholUse_Impulsivity.csv”) is in the folder you were asked to download under ‘Pre-lab activity 4: Getting ready for the lab class’. As long as that folder is set as your working directory, you are good to go.\n\n\n\n\n\n\n\n\nDo this if you couldn’t upload files to the server\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/122_week11_forStudents/alcoholUse_Impulsivity.csv?raw=true\", destfile = \"alcoholUse_Impulsivity.csv\")\n\n\nStep 1. Read in the data. You should now see an object containing the data in the ‘Environment’.\n\nQuestion 1a: How many variables does it have?\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv()function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\ndata &lt;- read_csv(\"alcoholUse_Impulsivity.csv\")\n\n\n\n\nStep 2. Plot the relationship between hazard alcohol use and impulsivity using a scatterplot and a line of best fit\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the ggplot()function in combination with geom_point() and geom_smooth(). Make sure you use clear labels for your axes by using labs().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nUse this code template and add the name of the data frame and the variables. Also add informative labels for your axes.\nggplot(, aes(x = , y = )) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"\", y = \"\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below\nggplot(data, aes(x = hau, y = imp)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Hazardous Alcohol Use\", y = \"Impulsivity\")\n\n\n\nQuestion 2a: What can you tell from the scatterplot about the direction of the relationship?\n\nStep 3. Conduct the correlation analysis.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nUse the cor.test()function in combination with tidy().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template of the code, make sure to add the data frame and the relevant variables names.\nresults &lt;- cor.test(DATA$X, \n                    DATA$Y, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\nresults\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nresults &lt;- cor.test(data$hau, \n                    data$imp, \n                    method = \"pearson\", \n                    alternative = \"two.sided\") %&gt;% \n  tidy()\n\nresults\n\n\n\nQuestion 3a: What is the correlation coefficient (Pearson’s r)?\nQuestion 3b: What is the p value?\nQuestion 3c: Is the correlation significant at the p &lt; .05 level?\nQuestion 3d: What are the degrees of freedom you need to report?\nQuestion 3e: How much variance in ‘impulsivity’ can be accounted for by ‘hazardous alcohol use’?\nQuestion 3f: Give three logically possible directions of causality, indicating for each direction whether it is a plausible explanation in light of the variables involved (and why). No, this is not a trick question —-I know that correlation does not infer causation, but think critically! New studies/ideas are constructed by thinking what the previous study doesn’t tell us about what could be happening with the variables of interest.\n\nStep 4. Write a few sentences in which you report this result, following APA guidelines.\n\nJob completed — Well done!"
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-lectures",
    "href": "PSYC122/Week11.html#sec-wk11-lectures",
    "title": "1. Week 11 - Correlation",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material comes in two parts.\n\nTheory(~30 minutes) Watch this part before you complete the reading and the pre-lab activities. The video has captions, in case you find that helpful. You can download the slides and a transcript from the links below the video. Finally, if you open the video in ‘eStream’ by clicking on the green ‘e’ in the bottom right, you can navigate to separate sections of the video by clicking on the ‘chapters’ pane. This might be particularly useful if you quickly want to revisit a particular section.\n\n\nSlides Transcript\n\nHow to(~13 minutes) Watch this part after you’ve completed the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript"
  },
  {
    "objectID": "PSYC122/data/week11/122_wk11_labActivities2_3.html",
    "href": "PSYC122/data/week11/122_wk11_labActivities2_3.html",
    "title": "122_wk11_labActivities2_3",
    "section": "",
    "text": "#1. Loading the relevant libraries\n\nlibrary(broom)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n#2. Read in the data\n\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\nRows: 25 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): Participant, Abil, IQ, Home, TV\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n#3. Construct a scatterplot of the relationship between ‘Home’ and ‘TV’. Also add a line of best fit.\n\nggplot(mh, aes(x = Home, y = TV)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Time spend reading at home\", y = \"Time spend watching TV at home\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-2---miller-and-haden-data",
    "href": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-2---miller-and-haden-data",
    "title": "122_wk11_labActivities2_3",
    "section": "",
    "text": "#1. Loading the relevant libraries\n\nlibrary(broom)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n#2. Read in the data\n\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\nRows: 25 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): Participant, Abil, IQ, Home, TV\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n#3. Construct a scatterplot of the relationship between ‘Home’ and ‘TV’. Also add a line of best fit.\n\nggplot(mh, aes(x = Home, y = TV)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  labs(x = \"Time spend reading at home\", y = \"Time spend watching TV at home\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "PSYC122/Week11.html#sec-wk11-prelab-activities",
    "href": "PSYC122/Week11.html#sec-wk11-prelab-activities",
    "title": "1. Week 11 - Correlation",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures on correlation and read the textbook sections you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualing correlations\nHave a look at this visualisation of correlations by Kristoffer Magnusson.\nAfter having read the relevant sections of Howell (2017) Chapter 9, use this visualisation page to visually replicate the scatterplots in Figures 9.1 and 9.2 - use a sample of 100. After that, visually replicate the scatterplots in Figure 9.3.\nEach time you change the correlation, pay attention to the shared variance (the overlap between the two variables) and see how this changes with the changing level of relationship between the two variables. The greater the shared variance, the stronger the relationship.\nAlso, try setting the correlation to r = .5 and then moving a single dot to see how one data point, a potential outlier, can change the stated correlation value between two variables.\n\n\nPre-lab activity 2: Guess the correlation\nNow that you are well versed in interpreting scatterplots (scattergrams) have a go at this online app on guessing the correlation.\nThis is a very basic app that allows you to see how good you are at recognising different correlation strengths from the scatterplots. We would recommend you click the “Track Performance” tab so you can keep an overview of your overall bias to underestimate or overestimate a correlation.\nIs this all just a bit of fun? Well, yes, because stats is actually fun, and no, because it serves a purpose of helping you determine if the correlations you see in your own data are real, and to help you see if correlations in published research match with what you are being told. As you will have seen from the above examples, one data point can lead to a misleading relationship and even what might be considered a medium to strong relationship may actually have only limited relevance in the real world. One only needs to mention Anscombe’s Quartet to be reminded of the importance of visualising your data, which leads us to the final pre-lab activity for this week.\n\n\nPre-lab activity 3: Anscombe’s quartet\nAnscombe (1973) showed that four sets of bivariate data (X, Y) that have the exact same means, medians, and relationships can look very different when plotted. You can read more about this here.\nAll in this is a clear example of why you should visualise your data and not to rely on just the numbers.\n\n\nPre-lab activity 4: Getting ready for the lab class\n\nRemind yourself of the basics of how to work with RStudio and get your files ready\nYou might want to re-visit the materials that John and Tom provided in PSYC121:\n\nBasics of working with RStudio\nCreate a folder for Week 11.\nDownload the 122_week11_forStudents.zip file and upload it into the new folder in RStudio Server you created at the previous step.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.\n\n\n\n\ndownload.file(\"https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week11/122_week11_forStudents/exams.csv?raw=true\", destfile = \"exams.csv\")"
  },
  {
    "objectID": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-3---hazardous-alcohol-use-and-impulsivity",
    "href": "PSYC122/data/week11/122_wk11_labActivities2_3.html#lab-activity-3---hazardous-alcohol-use-and-impulsivity",
    "title": "122_wk11_labActivities2_3",
    "section": "Lab activity 3 - Hazardous alcohol use and impulsivity",
    "text": "Lab activity 3 - Hazardous alcohol use and impulsivity"
  }
]