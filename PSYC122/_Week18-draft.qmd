---
title: 7. Week 18 -- Developing the linear model
subtitle: Written by Rob Davies
order: 7
---

::: callout-warning
This page is under construction: come back soon!
:::

```{r}
#| warning: false
#| echo: false
library(kableExtra)
library(tidyverse)
```

```{r}
#| warning: false
#| echo: false
study.one.gen <- read_csv("study-one-general-participants.csv")  
study.two.gen <- read_csv("study-two-general-participants.csv")
```

## Week 18: Introduction {#sec-wk18-introduction}

Welcome to your overview of our work together in **PSYC122 Week 18**.

::: callout-tip
*Putting it all together*

- We will complete four classes in **weeks 16-19**.
- These classes are designed to help you to revise and to put into practice some of the key ideas and skills you have been developing in the first year research methods modules *PSYC121, PSYC123 and PSYC124*.
- We will do this in the context of a live research project with potential real world impacts: the **Clearly Understood** project.
:::

### Our learning goals

In Week 18, we aim to further develop skills in *analyzing* and in *visualizing* psychological data.

We will do this in the context of the **Clearly Understood** project: our focus will be on what makes it easy or difficult for people to understand written health information.

In the Week 18 class, we will aim to answer two research questions:

1. What person attributes predict success in understanding?
2. Can people accurately evaluate whether they correctly understand written health information?

We will use linear models to estimate the association between predictors and outcomes.
What is **new**, here, is that we will explore the power and flexibility of the linear model analysis method in two important aspects.

::: callout-tip
1. We will fit linear models including *multiple* predictors, this is why this form of analysis is also often called *multiple regression*.
2 We will use linear models to estimate the effects of numeric and categorical or nominal predictor variables.
:::

When we do these analyses, we will need to adapt how we report the results:  

- we need to report information about **the model we specify**, identifying *all* predictors;
- we will need to decide **if the effects** of one or more predictors **are significant**;
- we will report the model **fit statistics** (`F, R-squared`) as well as coefficient estimates;
- and we need to learn to write texts **describing the impact** of predictors.

Usually, in describing the impacts of predictors, we are required to communicate:

- the **direction** of the effect -- do values of the outcome variable *increase* or *decrease* given increasing values of the predictor?
- the **size** of the effect -- *how much* do values of the outcome variable *increase* or *decrease* given increasing values of the predictor?

This task of description is enabled by producing plots of the predictions we can make:

- plots to show we expect the outcome to change, given different values of a predictor.

::: callout-tip
We will aim to build skills in producing professional-looking plots for our audiences.

- We can produce plots showing the effects of predictors
- As predictions of change in outcome, given different values of the predictor variables.
:::

## Lectures {#sec-wk18-lectures}

::: callout-tip
Before you go on to the activities in @sec-wk18-lab-activities, **watch** the lectures:
:::

The lecture for this week is presented in four short parts.
You can view video recordings of the lectures using Panopto, by clicking on the video images shown following.

- Anybody who has the link should be able to view the video.

1. **Overview** (19 minutes): What we are doing in Week 18 -- Exploring the power of linear models, extending their application to use multiple variables to predict people.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=7ae0e020-8dcc-436e-9d69-afb700ca1a52&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player"></iframe>
```

2. **Using linear models to predict people** (13 minutes): Coding, thinking about, and reporting linear models with multiple predictors.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=d2638334-4683-4543-8183-afb700cfbff0&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player"></iframe>
```

3. **Critical evaluation** (15 minutes): Critically evaluating the results of analyses involving linear models.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=68e5cba9-ea96-4788-9c21-afb700d3ba29&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player"></iframe>
```

4. **Everything is some kind of linear model** (13 minutes): Understanding just how general and powerful this method for understanding people can be.

```{=html}
<iframe src="https://lancaster.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=0f6ba49d-f54d-41d0-ab30-afb700d84744&autoplay=false&offerviewer=true&showtitle=true&showbrand=true&captions=false&interactivity=all" height="405" width="720" style="border: 1px solid #464646;" allowfullscreen allow="autoplay" aria-label="Panopto Embedded Video Player"></iframe>
```

::: callout-tip
The slides presented in the videos can be downloaded either as a web page or as a Word document.
:::

- [The slides](data/week18/122-linear-model-develop.html) exactly as presented (6 MB). 
- [The slides](data/week18/122-linear-model-develop-printable-edit.docx) converted to a Word .docx (1 MB). 

You can download the web page `.html` file and click on it to open it in any browser (e.g., Chrome, Edge or Safari). The slide images are high quality so the file is quite big and may take a few seconds to download.

You can download the `.docx` file and click on it to open it as a Word document that you can then edit. 
Converting the slides to a .docx distorts some images but the benefit of the conversion is that it makes it easier for you to add your notes.

### The lectures have three main areas of focus {#sec-wk18-lectures-focus}

**1. Working with the linear model with multiple predictors**

We focus in-depth on how you code linear models, how you identify critical information in the results summaries, and how you report the results: the language and the style you can use in your reports.

::: callout-tip
- A small change to `lm()` coding releases tremendous power and flexibility in how you use the analysis method.
:::

**2. Analyses are done in context so when we conduct analyses we *must* use contextual information**

The power and flexibility of the linear model presents challenges.
We must decide *which* predictor variables we specify in our model.
This specification requires us to think about our theoretical assumptions and what they require us to include to make sense of the behaviours or the individual differences we observe when we do things like investigating what makes health information easy or difficult to understand.

**3. Developing critical thinking**

As we develop conceptual understanding and practical skills, we must learn to *reflect critically* on our analyses, and learn to critically evaluate the analyses we read about when we read research reports in the scientific literature.

::: callout-tip
*Critical analysis* can develop by considering

- validity
- measurement
- generalizability
:::

We are always working in the broader context of uncertainty:

- uncertainty about the predictions we may make concerning outcomes of interest;
- uncertainty given the possibility that predicted effects may vary between individuals or groups;
- uncertainty given the influence of sources of randomness in how specific responses are produced.

::: callout-tip
To work with the recordings:

- Watch the video parts right through.
- Use the printable versions of the slides (provided on Moodle) to make notes.
- Try out the coding exercises in the how-to guide and the acitivity tasks or questions (@sec-wk18-lab-activities) to learn how to construct visualizations and do analyses.
:::

## Reading: Links to other classes

We do not provide further reading for this class but you will find it helpful to revise some of the key ideas you have been learning about PSYC122 and in other modules.

- The lectures in *PSYC123* on: the scientific method; reliability and validity; experimental design, especially between-subjects studies; hypothesis testing; and precise hypotheses.
- The lecture in *PSYC122* on correlations. 

## Pre-lab activities {#sec-wk18-prelab-activities}

### Pre-lab activity 1 {#sec-wk18-prelab-activities-1}

In weeks 16-19, we will be working together on a research project to investigate how people vary in their response to health advice.

Completing the project involves collecting responses from *PSYC122* students: **you**.

To enter your responses, we invite you to complete a short survey.

Complete the survey by clicking on the link [here](https://lancasteruni.eu.qualtrics.com/jfe/form/SV_0qdj8TOZc18LR0q)

::: callout-tip
In our week 19 class activity, we will analyze the data we collect here.
:::

The survey should take about 20 minutes to complete.

Taking part in the survey is **completely voluntary**.
You can stop at any time without completing the survey if you do not want to finish it.
If you do not want to do the survey, you can do an alternative activity (see below).

All responses will be recorded completely anonymously.

### Pre-lab activity alternative option {#sec-wk18-prelab-activities-2}

If you do not want to complete the survey, we invite you to read the pre-registered research plan for the *PSYC122 health advice* research project.

[Read the project pre-registration](https://osf.io/p6fsc/)

## Lab activities {#sec-wk18-lab-activities}

### Introduction {#sec-wk18-lab-activities-1-introduction}

We will do our practical lab work to develop your skills in the context of the **Clearly Understood** project.

- Our focus will be on what makes it easy or difficult for people to understand written health information.

::: callout-important
In these classes, we will complete a research project to answer the research questions:

1. What person attributes predict success in understanding health information?
2. Can people accurately evaluate whether they correctly understand written health information?
:::

### Get ready {#sec-wk18-prelab-activities-ready}

#### Download the data

Click on the link: [122-week18_for_students.zip](data/week18/122-week18_for_students.zip) to download the data files folder. Then upload the contents to the new folder you created in RStudio Server.

The downloadable .zip folder includes the data files:

- `study-one-general-participants.csv`
- `study-two-general-participants.csv`

and the R Markdown `.Rmd`:

- `2023-24-PSYC122-w18-how-to.Rmd`

If you can't upload these files to the server -- this affects some students -- you can use some code to get R to do it for you: uncover the code box below to reveal the code to do this.

:::{.callout-tip collapse="true"}
## Code
- You can use the code below to directly download the file you need in this lab activity to the server.
- Remember that you can copy the code to your clipboard by clicking on the 'clipboard' in the top right corner.

1. Get the `study-one-general-participants.csv` data

```{r eval=FALSE}
download.file("https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/study-one-general-participants.csv?raw=true", destfile = "study-one-general-participants.csv")
```

2. Get the `study-two-general-participants.csv` data

```{r eval=FALSE}
download.file("https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/study-two-general-participants.csv?raw=true", destfile = "study-two-general-participants.csv")
```

3. Get the `2023-24-PSYC122-w18-how-to.Rmd` how-to guide

```{r eval=FALSE}
download.file("https://github.com/lu-psy-r/statistics_for_psychologists/blob/main/PSYC122/data/week18/2023-24-PSYC122-w18-how-to.Rmd?raw=true", destfile = "2023-24-PSYC122-w18-how-to.Rmd")
```
:::

#### Check: What is in the data files? {#sec-wk18-data-summary}

Each of the data files we will work with has a similar structure, as you can see in this extract.

```{r}
#| label: headcheck-wide
#| echo: false
# head(behaviour.rt)
study.two.gen %>%
  filter(participant_ID == c('studytwo.1', 'studytwo.10', 'studytwo.100', 'studytwo.101')) %>%
  as.data.frame() %>%
  kable() %>%
  kable_styling()
```

You can use the *scroll bar* at the bottom of the data window to view different columns.

You can see the columns:

- `participant_ID` participant code;
- `mean.acc` average accuracy of response to questions testing understanding of health guidance (varies between 0-1);
- `mean.self` average self-rated accuracy of understanding of health guidance (varies between 1-9);
- `study` variable coding for what study the data were collected in
- `AGE` age in years;
- `HLVA` health literacy test score (varies between 1-16);
- `SHIPLEY` vocabulary knowledge test score (varies between 0-40);
- `FACTOR3` reading strategy survey score (varies between 0-80);
- `GENDER` gender code;
- `EDUCATION` education level code;
- `ETHNICITY` ethnicity (Office National Statistics categories) code.

::: callout-tip
It is always a good idea to view the dataset -- click on the name of the dataset in the R-Studio `Environment` window, and check out the columns, scroll through the rows -- to get a sense of what you are working with.
:::

### Lab activity 1: Work with the `How-to` guide {#sec-wk18-lab-activities-1}

The `how-to` guide comprises an .Rmd file:

- `2023-24-PSYC122-w18-how-to.Rmd`

It is full of advice and example code.

The code in the `how-to` guide was written to work with the data file:

- `study-one-general-participants.csv`.

::: callout-tip
We show you how to do everything you need to do in the lab activity (@sec-wk18-lab-activities-2, next) in the `how-to` guide.

- Start by looking at the `how-to` guide to understand what steps you need to follow in the lab activity.
:::

We will take things *step-by-step*.

We split .Rmd scripts by steps, tasks and questions:

- different steps for different phases of the analysis workflow;
- different tasks for different things you need to do;
- different questions to examine different ideas or coding challenges

::: callout-tip
- Make sure you start at the top of the `.Rmd` file and work your way, in order, through each task.
- Complete each task before you move on to the next task.
:::

In the activity @sec-wk18-lab-activities-2, we are going to work through a sequence of steps and tasks that mirrors the sequence you find in the `how-to` guide.

- There is a little bit of variation, comparing the later steps in the `how-to` guide and the steps in @sec-wk18-lab-activities-2, but that is designed to help you with your learning, in different places, when we think you will most need the support.

::: callout-tip
- Notice that we are gradually building up our skills: consolidating what we know; revising important learning; and extending ourselves to acquire new skills.
- Over time, we will refer less and less to what we have learned before.
:::

**Step 1: Set-up**

1. Empty the R environment -- using `rm(list=ls())`
2. Load relevant libraries -- using `library()`

**Step 2: Load the data**

3. Read in the data file -- using `read_csv()`
4. Inspect the data -- using `head()` and `summary()`

**Step 3: Use a linear model to to answer the research questions -- one predictor**

5. Use `lm()` to examine the relation between an outcome variable and one predictor variable

**Step 4: Use a linear model to to answer the research questions -- multiple predictors**

6. Use `lm()` to examine the relation between between an outcome variable and *multiple* predictors

**Step 5: Plot predictions from linear models with multiple predictors**

7. Use `ggpredict()` to plot linear model predictions for one of the predictors
8. Produce plots that show the predictions for all the predictor variables in a model

In @sec-wk18-lab-activities-2, you will see that we show you how you can understand what linear model estimates show by examining the predictions from one outcome-predictor relation.

**Step 6: Draw boxplots to examine associations between variables**

The `how-to` guide shows you how to produce boxplots. 
We do not include the task in the @sec-wk18-lab-activities-2 tasks sequence but you *will* find it useful to produce boxplots when you are examining the impact of categorical variables (next).

9. Create boxplots to examine the association between a continuous numeric outcome variable like `mean.acc` and a categorical variable like `ETHNICITY`

**Step 7: Estimate the effects of factors as well as numeric variables**

We refer to categorical or nominal variables like `ETHNICITY` as *factors* in data analysis.

10. Fit a linear model including both numeric variables and categorical variables as predictors
11. Fit a linear model including both numeric variables and categorical variables as predictors, and then plot the predicted effect of the factor (the categorical variable)

::: callout-tip
If you are unsure about what you need to do, look at the advice in `2023-24-PSYC122-w18-how-to.Rmd` on how to do the tasks, with examples on how to write the code.
:::

You will see that you can match a task in the activity @sec-wk18-lab-activities-2 to the same task in the `how-to` guide.
The `how-to` shows you what function you need and how you should write the function code.

This process of adapting demonstration code is a process critical to data literacy and to effective problem solving in modern psychological science.

::: callout-warning
Don't forget: You will need to change the names of the dataset or the variables to complete the tasks in @sec-wk18-lab-activities-2.
:::

### Lab activity 2 {#sec-wk18-lab-activities-2}

### OK: now let's do it!

In the following, we will guide you through the tasks and questions step by step.
You will learn more if you follow this advice:

::: callout-tip
1. We will hide the code to do some tasks behind a drop-down button. Try to write and run the code for yourself first.
2. We won't always give you the code required to do something: this gives you the chance to check what you have learned by trying out your code without the answer in front of you.
3. We will not *at first* give you the answers to questions about the data or about the results of analyses.
4. An answers version of the workbook will be provided after the last lab session (check the answers then in @sec-wk18-lab-activities-answers) so that you can check whether your independent work has been correct.
:::

#### Questions {#sec-wk18-lab-activities-1-questions}

#### Step 1: Set-up

To begin, we set up our environment in R.

##### Task 1 -- Run code to empty the R environment

```{r}
#| eval: false
rm(list=ls())
```

##### Task 2 -- Run code to load relevant libraries

```{r}
#| eval: false
library("tidyverse")
```

#### Step 2: Load the data

##### Task 3 -- Read in the data file we will be using

The data file for the *workbook* is called:

- `study-two-general-participants.csv`

Use the `read_csv()` function to read the data file into R.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
study.two.gen <- read_csv("study-two-general-participants.csv")
```
:::

When you code this, you can choose your own file name, but be sure to give the data object you create a distinct name e.g. `study.two.gen`.

##### Task 4 -- Inspect the data file

Use the `summary()` or `head()` functions to take a look

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
summary(study.two.gen)
```
:::

::: callout-tip
## Hint
Even though you have done this before, you will want to do it 
again, here.

- Pay attention to what you see, for the numeric variables, in the information about minimum (Min.) and maximum (Max.) values.
:::

#### Step 3: Use histograms to examine the distributions of variables

#### Revise: make sure you are confident about doing these things

##### Task 5 -- Draw histograms to examine the distributions of variables

:::{.callout-tip collapse="true"}
## Hint
Use `ggplot()` with `geom_histogram()`.

When we create a plot, we take things step-by-step.

Here's an example you have seen before: run the lines of code and see the result in the `Plots` window in `R-Studio`.

```{r}
ggplot(data = study.two.gen, aes(x = mean.acc)) + 
  geom_histogram()
```

These are the steps, set out one at a time:

1. `ggplot(...)` you tell R you want to make a plot using the `ggplot()` function
2. `ggplot(data = study.two.gen ...)` you tell R you want to make a plot with the
`study.two.gen` data
3. `ggplot(..., aes(x = mean.acc))` you tell R that you want to make a plot with 
the variable `mean.acc` -- here, you specify the aesthetic mapping, `x = mean.acc`
4. `ggplot(...) + geom_histogram()` you tell R you want to plot values of `mean.acc` 
as a histogram

Notice that the code works the same whether we have the different bits of code on the same
line or in a series of lines.
:::

##### Task 6 -- Practice editing the appearance of a histogram plot step-by-step

Start by constructing a basic histogram.

- Draw a histogram plot to visualize the distribution of whichever numeric variable from the `study.two.gen` dataset you please.

:::{.callout-tip collapse="true"}
## Hint
- Use the line-by-line format to break the plot code into steps.
- It will make it easier to read, and it will make it easier to add edit.
::: 

1. Pick numeric variable in the dataset.
2. Run the code to produce a histogram of the variable values.

Can you work out how to do it without looking at the code example?

Click on the button to see the code example: compare it to the code you wrote.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY)) + 
  geom_histogram()
```
:::

We are going to revise editing:

1. The appearance of the bars using `binwidth`;
2. The colour of the background using `theme_bw()`;
3. The appearance of the labels using `labs().

Then we are going to try some new moves:

4. Setting the x-axis limits to reflect the full range of possible scores 
on the x-axis variable;
5. Adding annotation -- here, a vertical line -- indicating the sample average 
for a variable.

>**Q.1.** Edit the appearance of the bars by specifying a `binwidth` value.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY)) + 
  geom_histogram(binwidth = 2)
```
:::

>**Q.2.** Then add an edit to the appearance of the background using `theme_bw()`.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY)) + 
  geom_histogram(binwidth = 2) +
  theme_bw()
```
:::

>**Q.3.** Then add an edit to the appearance of the labels using `labs()`.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY)) + 
  geom_histogram(binwidth = 2) +
  theme_bw() +
  labs(x = "SHIPLEY", y = "frequency count")
```
:::

#### Introduce: make some new moves

>**Q.4.** Now add an edit by setting the x-axis limits using `x.lim()`.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY)) + 
  geom_histogram(binwidth = 2) +
  theme_bw() +
  labs(x = "Vocabulary (SHIPLEY)", y = "frequency count") +
  xlim(0,40)
```
:::

>**Q.5.** Then add an edit to draw a vertical line to show the mean value of 
the variable you are plotting..

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY)) + 
  geom_histogram(binwidth = 2) +
  theme_bw() +
  labs(x = "Vocabulary (SHIPLEY)", y = "frequency count") +
  xlim(0,40) +
  geom_vline(xintercept = mean(study.two.gen$SHIPLEY), colour = "red", size = 1.5)
```
:::

>**Q.6.** Can you find information on how to define the limits on the x-axis 
and on the y-axis?

:::{.callout-tip collapse="true"}
## Hint
You can see the information in this week's `how-to` guide but try a search online for "ggplot reference xlim".
:::

<!-- - A.6. See ggplot reference information on setting limits here: -->

<!-- <https://ggplot2.tidyverse.org/reference/lims.html> -->

>**Q.7.** Can you find information on how to a reference line?

:::{.callout-tip collapse="true"}
## Hint
You can see the information in this week's how-to but try a search online for "ggplot reference vline".
:::

<!-- - A.7. See ggplot reference information on adding lines here: -->

<!-- <https://ggplot2.tidyverse.org/reference/geom_abline.html> -->

#### Step 4: Now draw scatterplots to examine associations between variables

#### Consolidation: should be no surprises here

But if you want to remind yourself how to do things, click on the box to reveal hint information.

:::{.callout-tip collapse="true"}
## Hint
- We are working with `geom_point()` and you need x and y aesthetic mappings.
- The outcome variable `mean.acc` has to be mapped to the y-axis using `...y = ...`

This is how the target scatterplot code works.

```{r}
#| eval: false
ggplot(data = data.set, aes(x = predictor.variable, y = outcome.variable)) +
  geom_point()
```

The plot code moves through the following steps:

1. `ggplot(...)` make a plot;
2. `ggplot(data = data.set, ...)` working with the `data.set`, using the name you gave the dataset you are working with;
3. `ggplot(...aes(x = predictor.variable, y = outcome.variable))` using two aesthetic mappings

- `x = predictor.variable` maps values of the `predictor.variable` (whatever it is called) to x-axis (horizontal, left to right) positions;
- `y = outcome.variable` maps values of the `outcome.variable`(whatever it is called) to y-axis (vertical, bottom to top) positions;

4. `geom_point()` show the mappings as points.
:::

##### Task 7 -- Create a scatterplot to examine the association between some variables

Create three scatterplots to visualize the relationship between (1.) the outcome `mean.acc` and (2.) each of three numeric potential predictor variables `SHIPLEY`, `HLVA` and `AGE`.

Check first if you can write the code you need to produce each scatterplot.
Click on the button to see the code example: compare it to the code you wrote.

- Notice that R will tolerate some variation in how code is written.
- This is like any language where we can ask for the same thing in different ways.

:::{.callout-tip collapse="true"}
## Code

Check out the example code for each of the scatterplots we are asking you to do.

- Notice what changes and what stays the same.

```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +
  geom_point()

ggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +
  geom_point()

ggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +
  geom_point()
```
:::

#### Revise: make sure you are confident about doing these things

##### Task 8 -- Edit the appearance of *each* plot step-by-step

1. You may want to use the same plot appearance choices for all plots.

- Producing plots with a consistent appearance will make it easier for 
your audience to read your plots.

2. You can find links to reference information on options in the how-to guide.

- Use the information to make the plots pleasing in appearance to you.

:::{.callout-tip collapse="true"}
## Hints
- Do not be afraid to select, copy then paste code to re-use it and *save yourself* the effort of typing out the code over and over again.
- But be careful to make sure that you change variable names, and that things like axis values are sensible for each variable.
:::

>**Q.8.** First, edit the appearance of the points using `alpha`, `size`, `shape`, and `colour`.

:::{.callout-tip collapse="true"}
## Code
Check out the example code for each of the scatterplots.

- Notice what changes and what stays the same.

```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')

ggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')

ggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')
```
:::

>**Q.9.** Then edit the colour of the background using `theme_bw()`.

:::{.callout-tip collapse="true"}
## Code
Check out the example code for each of the scatterplots.

- Notice what changes and what stays the same.

```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw()

ggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw()

ggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw()
```
:::

>**Q.10.** Then edit the appearance of the labels using `labs()`.

:::{.callout-tip collapse="true"}
## Code
Check out the example code for each of the scatterplots.

- Notice what changes and what stays the same.

```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw() +
  labs(x = "SHIPLEY", y = "mean accuracy")

ggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw() +
  labs(x = "HLVA", y = "mean accuracy")

ggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw() +
  labs(x = "Age (Years)", y = "mean accuracy")
```
:::

#### Introduce: make some new moves

>**Q.11.** Then set the x-axis and y-axis limits to the minimum-maximum ranges 
of the variables you are plotting.

You can set axis limits by adding the `xlim()` and `ylim()` function calls to
the chunk of code you have written to produce each plot.

- The task, here, is to work out *what* numeric values you should enter inside
`xlim()` or `ylim()`.
- The code works if you enter values like this: `xlim(minimum, maximum)` and `ylim(minimum, maximum)`.
- Where `minimum, maximum` are the numbers representing the smallest possible (minimum) and largest possible (maximum) value for each variable.

:::{.callout-tip collapse="true"}
## Hint
- For these plots the y-axis limits will be the same because the outcome stays the same.
- But the x-axis limits will be different for each different predictor variable.
- Check out the information in the `summary()` you got of the dataset.
- The minimum values for the variables will often (not always) be 0 e.g. if you are looking at data from ability tests and people who do the tests can get 0 (because none of their responses are correct). However, if you are looking at e.g. ratings data then the minimim value could be 1 (e.g. because people are asked to rate something on a scale from 1-9).
- The maximum values for the variables is not necessarily the largest value recorded for that variable in the sample data-set you are working with (e.g., because nobody in your sample got all test questions correct). Thus, you need to use information about measurement design, see @sec-wk18-data-summary.
:::

Check first if you can write the code you need to produce each scatterplot.
Click on the button to see the code example: compare it to the code you wrote.

:::{.callout-tip collapse="true"}
## Code
Check out the example code for each of the scatterplots.

- Notice what changes and what stays the same.

```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = SHIPLEY, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw() +
  labs(x = "SHIPLEY", y = "mean accuracy") +
  xlim(0, 40) + ylim(0, 1)

ggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw() +
  labs(x = "HLVA", y = "mean accuracy") +
  xlim(0, 16) + ylim(0, 1)

ggplot(data = study.two.gen, aes(x = AGE, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  theme_bw() +
  labs(x = "Age (Years)", y = "mean accuracy") +
  xlim(0, 80) + ylim(0, 1)
```
:::

#### Step 5: Use correlation to to answer the research questions

#### Revise: make sure you are confident about doing these things

One of our research questions is:

1. What person attributes predict success in understanding?

##### Task 9 -- Examine the correlations between the outcome variable and predictor variables

You need to run three separate correlations: 

1. between mean accuracy and `SHIPLEY`;
2. between mean accuracy and `HLVA`; 
3. between mean accuracy and `AGE`.

:::{.callout-tip collapse="true"}
## Hints
- Use `cor.test()` to do the correlation analysis.
- You can look at the `how-to` guide or review previous materials (e.g. @sec-wk12-labactivities or @sec-wk16-lab-activities-1-questions) for more advice.
:::

Check first if you can write the code you need to complete each correlation analysis.
Click on the button to see the code example: compare it to the code you wrote.

:::{.callout-tip collapse="true"}
## Code
Check out the example code for doing each of the correlation analyses.

- Notice what changes and what stays the same.

```{r}
#| eval: false
cor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = "pearson",  alternative = "two.sided")

cor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = "pearson",  alternative = "two.sided")

cor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = "pearson",  alternative = "two.sided")
```
:::

Now use the results from the correlations to answer the following questions.

>**Q.12.** What is `r`, the coefficient for the correlation between `mean.acc` and `SHIPLEY`?

<!-- - A.12. r = 0.4650537 -->

>**Q.13.** Is the correlation between `mean.acc` and `HLVA`  significant?

<!-- - A.13. -- r is significant, p < .05 -->

>**Q.14.** What are the values for t and p for the significance test for the correlation between `mean.acc` and `AGE`?

<!-- - A.14. t = 0.30121, p = 0.7636 -->

>**Q.15.** For which pair of outcome-predictor variables is the correlation the largest?

<!-- - A.15. -- The correlation is the largest between `mean.acc` and `HLVA`. -->

>**Q.16.** What is the sign or direction of each of the correlations?

<!-- - A.16. -- All the correlations are positive. -->

#### Step 6: Use a linear model to to answer the research questions

#### Introduce: Make some new moves

One of our research questions is:

1. What person attributes predict success in understanding?

##### Task 10 -- Examine the relation between outcome mean accuracy (`mean.acc`) and each of the predictors: `SHIPLEY`, `HLVA` and `AGE`

You need to run three separate `lm()` analyses:

1. with mean accuracy as the outcome and `SHIPLEY` as the predictor;
2. with mean accuracy as the outcome and `HLVA` as the predictor; 
3. with mean accuracy as the outcome and `AGE` as the predictor.

:::{.callout-tip collapse="true"}
## Hints
You need to use `lm()` to do the analyses.

1. Be careful to identify the outcome and predictor variables correctly.
2. Remember that analysis code is arranged like this:

```{r}
#| eval: false
lm(outcome.variable ~ predictor.variable, data = data.set)
```

With:

- `lm()` asking R to do the linear model analysis;
- `outcome.variable ~ ...` specified on the *left* of the `~`;
- the `predictor.variable ~ ...` specified on the *right* of the `~`;
- and `data.set` identifying to R what dataset you are working with.

Notice that R has a general formula syntax: 

`outcome ~ predictor *or* y ~ x`

- and uses the same format across a number of different functions;
- each time, the left of the tilde symbol `~` is some output or outcome;
- and the right of the tilde `~` is some input or predictor or set of predictors.
:::

Check first if you can write the code you need to complete each linear model analysis.
Click on the button to see the code example: compare it to the code you wrote.

:::{.callout-tip collapse="true"}
## Code
Check out the example code for each of the models.

- Notice what changes and what stays the same.

```{r}
#| eval: false
model.1 <- lm(mean.acc ~ SHIPLEY, data = study.two.gen)
summary(model.1)

model.2 <- lm(mean.acc ~ HLVA, data = study.two.gen)
summary(model.2)

model.3 <- lm(mean.acc ~ AGE, data = study.two.gen)
summary(model.3)
```
:::

If you look at the model summary you can answer the following questions.

>**Q.17.** What is the estimate for the coefficient of the effect of the predictor `HLVA` on `mean.acc`?

<!-- - A.17. 0.026207  -->

>**Q.18.** Is the effect significant?

<!-- - A.18. It is significant, p < .05 -->

>**Q.19.** What are the values for t and p for the significance test for the coefficient?

<!-- - A.19. t = 7.529, p = 2.87e-12 -->

>**Q.20.** How would you describe in words the shape or direction of the association between `HLVA` and `mean.acc`?

<!-- - A.20. The slope coefficient -- and a scatterplot (draw it) -- suggest that as HLVA scores increase so also do mean accuracy scores. -->

>**Q.21.** How how would you describe the relations apparent between the predictor and outcome in all three models?

<!-- - A.21. It is possible to see, given coefficient estimates, that the association between predictor and outcome is positive for each model: mean accuracy appears to increase for increasing values of SHIPLEY vocabulary, HLVA health literacy, and age. -->

#### Step 7: Use a linear model to generate predictions

#### Introduce: Make some new moves

One of our research questions is:

1. What person attributes predict success in understanding?

##### Task 11 -- We can use the model we have just fitted to plot the model predictions

We are going to draw a scatterplot and add a line.

- The line will show the model predictions, given the model intercept and effect 
coefficient estimates.

:::{.callout-tip collapse="true"}
## Hint
You can see reference information here:  

<https://ggplot2.tidyverse.org/reference/geom_abline.html>
:::

**First fit a model** and get the summary: model the relationship between `mean.acc` and `HLVA`.

Check first if you can write the code you need to complete the linear model analysis.
Click on the button to see the code example: compare it to the code you wrote.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
model <- lm(mean.acc ~ HLVA, data = study.two.gen)
summary(model)
```
:::

You will need to record some information from the model summary so you can use it next.

>**Q.22.** What is the coefficient estimate for the intercept?

<!-- - A.22. 0.522016 -->

>**Q.23.** What is the coefficient estimate for the slope of `HLVA` (see earlier)?

<!-- - A.23. 0.026207 -->

**Second, draw a prediction plot**, using the `geom_point()` to draw a scatterplot and using the `geom_abline()` function to draw the prediction line representing the association between this outcome and predictor.

Check first if you can write the code you need to produce the prediction plot.
Click on the button to see the code example: compare it to the code you wrote.

:::{.callout-tip collapse="true"}
## Code
```{r}
#| eval: false
ggplot(data = study.two.gen, aes(x = HLVA, y = mean.acc)) +
  geom_point(alpha = 0.5, size = 2, colour = "blue", shape = 'square')   +
  geom_abline(intercept = 0.522016, slope = 0.026207, 
              colour = "red", size = 1.5) +
  theme_bw() +
  labs(x = "HLVA", y = "mean accuracy") +
  xlim(0, 15) + ylim(0, 1)
```
:::

#### You have now completed the Week 18 questions.

::: callout-important
Predicting human behaviour is at the heart of:

- Psychological science, and our collective attempt to understand ourselves.
- Behavioural analytics, and the ways businesses work with what we know about people.

This is an important step in your developmental journey: **Well done!**

- We will continue to deepen and extend your skills and understanding but everything builds on the key lessons we have been learning here.
:::

## Answers {#sec-wk18-lab-activities-answers}

When you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week.

::: callout-tip
The `.Rmd` script containing all code and all answers for each task and each question will be made available after the final lab session has taken place.

<!-- - You can download the script [2023-24-PSYC122-w18-workbook-answers](data/week18/2023-24-PSYC122-w18-workbook-answers) when it is available. -->
:::

We set out answers information the Week 18 **Better understanding the linear model** questions, below.

- We focus on the **Lab activity 2** questions where we ask you to interpret something or say something.
- We do not show questions where we have given example or target code in the foregoing lab activity @sec-wk18-lab-activities-2.

<!-- You can see all the code and all the answers in `2023-24-PSYC122-w18-workbook-answers`. -->

<!-- ### Answers {#sec-wk18-lab-activities-answers-information}  -->

<!-- ::: callout-tip -->
<!-- Click on a box to reveal the answer. -->
<!-- ::: -->

<!-- #### Questions {#sec-wk18-lab-activities-2-questions-answers} -->

<!-- >**Q.6.** Can you find information on how to define the limits on the x-axis  -->
<!-- and on the y-axis? -->

<!-- :::{.callout-tip collapse="true"} -->
<!-- ## Hint -->
<!-- You can see the information in this week's `how-to` guide but try a search online for "ggplot reference xlim". -->
<!-- ::: -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.6. See ggplot reference information on setting limits here: -->

<!-- <https://ggplot2.tidyverse.org/reference/lims.html> -->
<!-- ::: -->

<!-- >**Q.7.** Can you find information on how to a reference line? -->

<!-- :::{.callout-tip collapse="true"} -->
<!-- ## Hint -->
<!-- You can see the information in this week's how-to but try a search online for "ggplot reference vline". -->
<!-- ::: -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.7. See ggplot reference information on adding lines here: -->

<!-- <https://ggplot2.tidyverse.org/reference/geom_abline.html> -->
<!-- ::: -->

<!-- One of our research questions is: -->

<!-- 1. What person attributes predict success in understanding? -->

<!-- Examine the correlations between the outcome variable and predictor variables. -->

<!-- You need to run three separate correlations:  -->

<!-- 1. between mean accuracy and `SHIPLEY`; -->
<!-- 2. between mean accuracy and `HLVA`;  -->
<!-- 3. between mean accuracy and `AGE`. -->

<!-- Check out the example code for doing each of the correlation analyses. -->

<!-- ```{r} -->
<!-- #| eval: false -->
<!-- cor.test(study.two.gen$SHIPLEY, study.two.gen$mean.acc, method = "pearson",  alternative = "two.sided") -->

<!-- cor.test(study.two.gen$HLVA, study.two.gen$mean.acc, method = "pearson",  alternative = "two.sided") -->

<!-- cor.test(study.two.gen$AGE, study.two.gen$mean.acc, method = "pearson",  alternative = "two.sided") -->
<!-- ``` -->

<!-- Now use the results from the correlations to answer the following questions. -->

<!-- >**Q.12.** What is `r`, the coefficient for the correlation between `mean.acc` and `SHIPLEY`? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.12. r = 0.4650537 -->
<!-- ::: -->

<!-- >**Q.13.** Is the correlation between `mean.acc` and `HLVA`  significant? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.13. -- r is significant, p < .05 -->
<!-- ::: -->

<!-- >**Q.14.** What are the values for t and p for the significance test for the correlation between `mean.acc` and `AGE`? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.14. t = 0.30121, p = 0.7636 -->
<!-- ::: -->

<!-- >**Q.15.** For which pair of outcome-predictor variables is the correlation the largest? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.15. -- The correlation is the largest between `mean.acc` and `HLVA`. -->
<!-- ::: -->

<!-- >**Q.16.** What is the sign or direction of each of the correlations? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.16. -- All the correlations are positive. -->
<!-- ::: -->

<!-- Examine the relation between outcome mean accuracy (`mean.acc`) and each of the predictors: `SHIPLEY`, `HLVA` and `AGE` -->

<!-- You need to run three separate `lm()` analyses: -->

<!-- 1. with mean accuracy as the outcome and `SHIPLEY` as the predictor; -->
<!-- 2. with mean accuracy as the outcome and `HLVA` as the predictor;  -->
<!-- 3. with mean accuracy as the outcome and `AGE` as the predictor. -->

<!-- Check out the example code for each of the models. -->

<!-- ```{r} -->
<!-- #| eval: false -->
<!-- model.1 <- lm(mean.acc ~ SHIPLEY, data = study.two.gen) -->
<!-- summary(model.1) -->

<!-- model.2 <- lm(mean.acc ~ HLVA, data = study.two.gen) -->
<!-- summary(model.2) -->

<!-- model.3 <- lm(mean.acc ~ AGE, data = study.two.gen) -->
<!-- summary(model.3) -->
<!-- ``` -->

<!-- If you look at the model summary you can answer the following questions. -->

<!-- >**Q.17.** What is the estimate for the coefficient of the effect of the predictor `HLVA` on `mean.acc`? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.17. 0.026207 -->
<!-- ::: -->

<!-- >**Q.18.** Is the effect significant? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.18. It is significant, p < .05 -->
<!-- ::: -->

<!-- >**Q.19.** What are the values for t and p for the significance test for the coefficient? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.19. t = 7.529, p = 2.87e-12 -->
<!-- ::: -->

<!-- >**Q.20.** How would you describe in words the shape or direction of the association between `HLVA` and `mean.acc`? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.20. The slope coefficient -- and a scatterplot (draw it) -- suggest that as HLVA scores increase so also do mean accuracy scores. -->
<!-- ::: -->

<!-- >**Q.21.** How how would you describe the relations apparent between the predictor and outcome in all three models? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.21. It is possible to see, given coefficient estimates, that the association between predictor and outcome is positive for each model: mean accuracy appears to increase for increasing values of SHIPLEY vocabulary, HLVA health literacy, and age. -->
<!-- ::: -->

<!-- We are going to draw a scatterplot and add a line. -->

<!-- - The line will show the model predictions, given the model intercept and effect  -->
<!-- coefficient estimates. -->

<!-- **First fit a model** and get the summary: model the relationship between `mean.acc` and `HLVA`. -->

<!-- You will need to record some information from the model summary so you can use it next. -->

<!-- >**Q.22.** What is the coefficient estimate for the intercept? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.22. 0.522016 -->
<!-- ::: -->

<!-- >**Q.23.** What is the coefficient estimate for the slope of `HLVA` (see earlier)? -->

<!-- ::: {.callout-note icon=false collapse="true"} -->
<!-- ## Answer -->
<!-- - A.23. 0.026207 -->
<!-- ::: -->

## Online Q&A {#sec-wk18-lab-Q-and-A}

You will find, below, a link to the video recording of the Week 18 online Q&A after it has been completed.

```{=html}
```
